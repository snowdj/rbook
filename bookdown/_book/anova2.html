<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 16 Factorial ANOVA | Learning statistics with R: A tutorial for psychology students and other beginners. (Version 0.6.1)</title>
  <meta name="description" content="Learning Statistics with R covers the contents of an introductory statistics class, as typically taught to undergraduate psychology students, focusing on the use of the R statistical software.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 16 Factorial ANOVA | Learning statistics with R: A tutorial for psychology students and other beginners. (Version 0.6.1)" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Learning Statistics with R covers the contents of an introductory statistics class, as typically taught to undergraduate psychology students, focusing on the use of the R statistical software." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 16 Factorial ANOVA | Learning statistics with R: A tutorial for psychology students and other beginners. (Version 0.6.1)" />
  
  <meta name="twitter:description" content="Learning Statistics with R covers the contents of an introductory statistics class, as typically taught to undergraduate psychology students, focusing on the use of the R statistical software." />
  

<meta name="author" content="Danielle Navarro (bookdown translation: Emily Kothe)">


<meta name="date" content="2019-01-11">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="regression.html">
<link rel="next" href="part-vi-endings-alternatives-and-prospects.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />








<!-- ###### start inserted header ##### -->

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-115940772-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-115940772-1');
</script>

<!-- add the twitter card and open graph tags -->
<meta name="twitter:card" content="summary">
<meta name="twitter:creator" content="@djnavarro">
<meta property="og:image" content="http://learningstatisticswithr.com/images/jasmine-faint.jpg">
<meta name="twitter:image" content="http://learningstatisticswithr.com/images/jasmine-faint.jpg">

<!-- ###### end inserted header ##### -->


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Learning Statistics with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Overview</a></li>
<li class="chapter" data-level="" data-path="licensing.html"><a href="licensing.html"><i class="fa fa-check"></i>Licensing</a></li>
<li class="chapter" data-level="" data-path="dedication.html"><a href="dedication.html"><i class="fa fa-check"></i>Dedication</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="preface.html"><a href="preface.html#preface-to-version-0.6.1"><i class="fa fa-check"></i><b>0.1</b> Preface to Version 0.6.1</a></li>
<li class="chapter" data-level="0.2" data-path="preface.html"><a href="preface.html#preface-to-version-0.6"><i class="fa fa-check"></i><b>0.2</b> Preface to Version 0.6</a></li>
<li class="chapter" data-level="0.3" data-path="preface.html"><a href="preface.html#preface-to-version-0.5"><i class="fa fa-check"></i><b>0.3</b> Preface to Version 0.5</a></li>
<li class="chapter" data-level="0.4" data-path="preface.html"><a href="preface.html#preface-to-version-0.4"><i class="fa fa-check"></i><b>0.4</b> Preface to Version 0.4</a></li>
<li class="chapter" data-level="0.5" data-path="preface.html"><a href="preface.html#preface-to-version-0.3"><i class="fa fa-check"></i><b>0.5</b> Preface to Version 0.3</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-i-background.html"><a href="part-i-background.html"><i class="fa fa-check"></i>Part I. Background</a></li>
<li class="chapter" data-level="1" data-path="why-do-we-learn-statistics.html"><a href="why-do-we-learn-statistics.html"><i class="fa fa-check"></i><b>1</b> Why do we learn statistics?</a><ul>
<li class="chapter" data-level="1.1" data-path="why-do-we-learn-statistics.html"><a href="why-do-we-learn-statistics.html#whywhywhy"><i class="fa fa-check"></i><b>1.1</b> On the psychology of statistics</a><ul>
<li class="chapter" data-level="1.1.1" data-path="why-do-we-learn-statistics.html"><a href="why-do-we-learn-statistics.html#the-curse-of-belief-bias"><i class="fa fa-check"></i><b>1.1.1</b> The curse of belief bias</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="why-do-we-learn-statistics.html"><a href="why-do-we-learn-statistics.html#the-cautionary-tale-of-simpsons-paradox"><i class="fa fa-check"></i><b>1.2</b> The cautionary tale of Simpson’s paradox</a></li>
<li class="chapter" data-level="1.3" data-path="why-do-we-learn-statistics.html"><a href="why-do-we-learn-statistics.html#statistics-in-psychology"><i class="fa fa-check"></i><b>1.3</b> Statistics in psychology</a></li>
<li class="chapter" data-level="1.4" data-path="why-do-we-learn-statistics.html"><a href="why-do-we-learn-statistics.html#statistics-in-everyday-life"><i class="fa fa-check"></i><b>1.4</b> Statistics in everyday life</a></li>
<li class="chapter" data-level="1.5" data-path="why-do-we-learn-statistics.html"><a href="why-do-we-learn-statistics.html#theres-more-to-research-methods-than-statistics"><i class="fa fa-check"></i><b>1.5</b> There’s more to research methods than statistics</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="studydesign.html"><a href="studydesign.html"><i class="fa fa-check"></i><b>2</b> A brief introduction to research design</a><ul>
<li class="chapter" data-level="2.1" data-path="studydesign.html"><a href="studydesign.html#measurement"><i class="fa fa-check"></i><b>2.1</b> Introduction to psychological measurement</a><ul>
<li class="chapter" data-level="2.1.1" data-path="studydesign.html"><a href="studydesign.html#some-thoughts-about-psychological-measurement"><i class="fa fa-check"></i><b>2.1.1</b> Some thoughts about psychological measurement</a></li>
<li class="chapter" data-level="2.1.2" data-path="studydesign.html"><a href="studydesign.html#operationalisation-defining-your-measurement"><i class="fa fa-check"></i><b>2.1.2</b> Operationalisation: defining your measurement</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="studydesign.html"><a href="studydesign.html#scales"><i class="fa fa-check"></i><b>2.2</b> Scales of measurement</a><ul>
<li class="chapter" data-level="2.2.1" data-path="studydesign.html"><a href="studydesign.html#nominal-scale"><i class="fa fa-check"></i><b>2.2.1</b> Nominal scale</a></li>
<li class="chapter" data-level="2.2.2" data-path="studydesign.html"><a href="studydesign.html#ordinal-scale"><i class="fa fa-check"></i><b>2.2.2</b> Ordinal scale</a></li>
<li class="chapter" data-level="2.2.3" data-path="studydesign.html"><a href="studydesign.html#interval-scale"><i class="fa fa-check"></i><b>2.2.3</b> Interval scale</a></li>
<li class="chapter" data-level="2.2.4" data-path="studydesign.html"><a href="studydesign.html#ratio-scale"><i class="fa fa-check"></i><b>2.2.4</b> Ratio scale</a></li>
<li class="chapter" data-level="2.2.5" data-path="studydesign.html"><a href="studydesign.html#continuousdiscrete"><i class="fa fa-check"></i><b>2.2.5</b> Continuous versus discrete variables</a></li>
<li class="chapter" data-level="2.2.6" data-path="studydesign.html"><a href="studydesign.html#some-complexities"><i class="fa fa-check"></i><b>2.2.6</b> Some complexities</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="studydesign.html"><a href="studydesign.html#reliability"><i class="fa fa-check"></i><b>2.3</b> Assessing the reliability of a measurement</a></li>
<li class="chapter" data-level="2.4" data-path="studydesign.html"><a href="studydesign.html#ivdv"><i class="fa fa-check"></i><b>2.4</b> The “role” of variables: predictors and outcomes</a></li>
<li class="chapter" data-level="2.5" data-path="studydesign.html"><a href="studydesign.html#researchdesigns"><i class="fa fa-check"></i><b>2.5</b> Experimental and non-experimental research</a><ul>
<li class="chapter" data-level="2.5.1" data-path="studydesign.html"><a href="studydesign.html#experimental-research"><i class="fa fa-check"></i><b>2.5.1</b> Experimental research</a></li>
<li class="chapter" data-level="2.5.2" data-path="studydesign.html"><a href="studydesign.html#non-experimental-research"><i class="fa fa-check"></i><b>2.5.2</b> Non-experimental research</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="studydesign.html"><a href="studydesign.html#validity"><i class="fa fa-check"></i><b>2.6</b> Assessing the validity of a study</a><ul>
<li class="chapter" data-level="2.6.1" data-path="studydesign.html"><a href="studydesign.html#internal-validity"><i class="fa fa-check"></i><b>2.6.1</b> Internal validity</a></li>
<li class="chapter" data-level="2.6.2" data-path="studydesign.html"><a href="studydesign.html#external-validity"><i class="fa fa-check"></i><b>2.6.2</b> External validity</a></li>
<li class="chapter" data-level="2.6.3" data-path="studydesign.html"><a href="studydesign.html#construct-validity"><i class="fa fa-check"></i><b>2.6.3</b> Construct validity</a></li>
<li class="chapter" data-level="2.6.4" data-path="studydesign.html"><a href="studydesign.html#face-validity"><i class="fa fa-check"></i><b>2.6.4</b> Face validity</a></li>
<li class="chapter" data-level="2.6.5" data-path="studydesign.html"><a href="studydesign.html#ecological-validity"><i class="fa fa-check"></i><b>2.6.5</b> Ecological validity</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="studydesign.html"><a href="studydesign.html#confounds-artifacts-and-other-threats-to-validity"><i class="fa fa-check"></i><b>2.7</b> Confounds, artifacts and other threats to validity</a><ul>
<li class="chapter" data-level="2.7.1" data-path="studydesign.html"><a href="studydesign.html#history-effects"><i class="fa fa-check"></i><b>2.7.1</b> History effects</a></li>
<li class="chapter" data-level="2.7.2" data-path="studydesign.html"><a href="studydesign.html#maturation-effects"><i class="fa fa-check"></i><b>2.7.2</b> Maturation effects</a></li>
<li class="chapter" data-level="2.7.3" data-path="studydesign.html"><a href="studydesign.html#repeated-testing-effects"><i class="fa fa-check"></i><b>2.7.3</b> Repeated testing effects</a></li>
<li class="chapter" data-level="2.7.4" data-path="studydesign.html"><a href="studydesign.html#selection-bias"><i class="fa fa-check"></i><b>2.7.4</b> Selection bias</a></li>
<li class="chapter" data-level="2.7.5" data-path="studydesign.html"><a href="studydesign.html#differentialattrition"><i class="fa fa-check"></i><b>2.7.5</b> Differential attrition</a></li>
<li class="chapter" data-level="2.7.6" data-path="studydesign.html"><a href="studydesign.html#non-response-bias"><i class="fa fa-check"></i><b>2.7.6</b> Non-response bias</a></li>
<li class="chapter" data-level="2.7.7" data-path="studydesign.html"><a href="studydesign.html#regression-to-the-mean"><i class="fa fa-check"></i><b>2.7.7</b> Regression to the mean</a></li>
<li class="chapter" data-level="2.7.8" data-path="studydesign.html"><a href="studydesign.html#experimenter-bias"><i class="fa fa-check"></i><b>2.7.8</b> Experimenter bias</a></li>
<li class="chapter" data-level="2.7.9" data-path="studydesign.html"><a href="studydesign.html#demand-effects-and-reactivity"><i class="fa fa-check"></i><b>2.7.9</b> Demand effects and reactivity</a></li>
<li class="chapter" data-level="2.7.10" data-path="studydesign.html"><a href="studydesign.html#placebo-effects"><i class="fa fa-check"></i><b>2.7.10</b> Placebo effects</a></li>
<li class="chapter" data-level="2.7.11" data-path="studydesign.html"><a href="studydesign.html#situation-measurement-and-subpopulation-effects"><i class="fa fa-check"></i><b>2.7.11</b> Situation, measurement and subpopulation effects</a></li>
<li class="chapter" data-level="2.7.12" data-path="studydesign.html"><a href="studydesign.html#fraud-deception-and-self-deception"><i class="fa fa-check"></i><b>2.7.12</b> Fraud, deception and self-deception</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="studydesign.html"><a href="studydesign.html#summary"><i class="fa fa-check"></i><b>2.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-ii-an-introduction-to-r.html"><a href="part-ii-an-introduction-to-r.html"><i class="fa fa-check"></i>Part II. An introduction to R</a></li>
<li class="chapter" data-level="3" data-path="introR.html"><a href="introR.html"><i class="fa fa-check"></i><b>3</b> Getting started with R</a><ul>
<li class="chapter" data-level="3.1" data-path="introR.html"><a href="introR.html#gettingR"><i class="fa fa-check"></i><b>3.1</b> Installing R</a><ul>
<li class="chapter" data-level="3.1.1" data-path="introR.html"><a href="introR.html#installing-r-on-a-windows-computer"><i class="fa fa-check"></i><b>3.1.1</b> Installing R on a Windows computer</a></li>
<li class="chapter" data-level="3.1.2" data-path="introR.html"><a href="introR.html#installing-r-on-a-mac"><i class="fa fa-check"></i><b>3.1.2</b> Installing R on a Mac</a></li>
<li class="chapter" data-level="3.1.3" data-path="introR.html"><a href="introR.html#installing-r-on-a-linux-computer"><i class="fa fa-check"></i><b>3.1.3</b> Installing R on a Linux computer</a></li>
<li class="chapter" data-level="3.1.4" data-path="introR.html"><a href="introR.html#installingrstudio"><i class="fa fa-check"></i><b>3.1.4</b> Downloading and installing RStudio</a></li>
<li class="chapter" data-level="3.1.5" data-path="introR.html"><a href="introR.html#startingR"><i class="fa fa-check"></i><b>3.1.5</b> Starting up R</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="introR.html"><a href="introR.html#firstcommand"><i class="fa fa-check"></i><b>3.2</b> Typing commands at the R console</a><ul>
<li class="chapter" data-level="3.2.1" data-path="introR.html"><a href="introR.html#an-important-digression-about-formatting"><i class="fa fa-check"></i><b>3.2.1</b> An important digression about formatting</a></li>
<li class="chapter" data-level="3.2.2" data-path="introR.html"><a href="introR.html#be-very-careful-to-avoid-typos"><i class="fa fa-check"></i><b>3.2.2</b> Be very careful to avoid typos</a></li>
<li class="chapter" data-level="3.2.3" data-path="introR.html"><a href="introR.html#r-is-a-bit-flexible-with-spacing"><i class="fa fa-check"></i><b>3.2.3</b> R is (a bit) flexible with spacing</a></li>
<li class="chapter" data-level="3.2.4" data-path="introR.html"><a href="introR.html#r-can-sometimes-tell-that-youre-not-finished-yet-but-not-often"><i class="fa fa-check"></i><b>3.2.4</b> R can sometimes tell that you’re not finished yet (but not often)</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="introR.html"><a href="introR.html#arithmetic"><i class="fa fa-check"></i><b>3.3</b> Doing simple calculations with R</a><ul>
<li class="chapter" data-level="3.3.1" data-path="introR.html"><a href="introR.html#adding-subtracting-multiplying-and-dividing"><i class="fa fa-check"></i><b>3.3.1</b> Adding, subtracting, multiplying and dividing</a></li>
<li class="chapter" data-level="3.3.2" data-path="introR.html"><a href="introR.html#taking-powers"><i class="fa fa-check"></i><b>3.3.2</b> Taking powers</a></li>
<li class="chapter" data-level="3.3.3" data-path="introR.html"><a href="introR.html#bedmas"><i class="fa fa-check"></i><b>3.3.3</b> Doing calculations in the right order</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="introR.html"><a href="introR.html#assign"><i class="fa fa-check"></i><b>3.4</b> Storing a number as a variable</a><ul>
<li class="chapter" data-level="3.4.1" data-path="introR.html"><a href="introR.html#variable-assignment-using---and--"><i class="fa fa-check"></i><b>3.4.1</b> Variable assignment using <code>&lt;-</code> and <code>-&gt;</code></a></li>
<li class="chapter" data-level="3.4.2" data-path="introR.html"><a href="introR.html#doing-calculations-using-variables"><i class="fa fa-check"></i><b>3.4.2</b> Doing calculations using variables</a></li>
<li class="chapter" data-level="3.4.3" data-path="introR.html"><a href="introR.html#rules-and-conventions-for-naming-variables"><i class="fa fa-check"></i><b>3.4.3</b> Rules and conventions for naming variables</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="introR.html"><a href="introR.html#usingfunctions"><i class="fa fa-check"></i><b>3.5</b> Using functions to do calculations</a><ul>
<li class="chapter" data-level="3.5.1" data-path="introR.html"><a href="introR.html#functionarguments"><i class="fa fa-check"></i><b>3.5.1</b> Function arguments, their names and their defaults</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="introR.html"><a href="introR.html#RStudio1"><i class="fa fa-check"></i><b>3.6</b> Letting RStudio help you with your commands</a><ul>
<li class="chapter" data-level="3.6.1" data-path="introR.html"><a href="introR.html#autocomplete-using-tab"><i class="fa fa-check"></i><b>3.6.1</b> Autocomplete using “tab”</a></li>
<li class="chapter" data-level="3.6.2" data-path="introR.html"><a href="introR.html#browsing-your-command-history"><i class="fa fa-check"></i><b>3.6.2</b> Browsing your command history</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="introR.html"><a href="introR.html#vectors"><i class="fa fa-check"></i><b>3.7</b> Storing many numbers as a vector</a><ul>
<li class="chapter" data-level="3.7.1" data-path="introR.html"><a href="introR.html#creating-a-vector"><i class="fa fa-check"></i><b>3.7.1</b> Creating a vector</a></li>
<li class="chapter" data-level="3.7.2" data-path="introR.html"><a href="introR.html#a-handy-digression"><i class="fa fa-check"></i><b>3.7.2</b> A handy digression</a></li>
<li class="chapter" data-level="3.7.3" data-path="introR.html"><a href="introR.html#vectorsubset"><i class="fa fa-check"></i><b>3.7.3</b> Getting information out of vectors</a></li>
<li class="chapter" data-level="3.7.4" data-path="introR.html"><a href="introR.html#altering-the-elements-of-a-vector"><i class="fa fa-check"></i><b>3.7.4</b> Altering the elements of a vector</a></li>
<li class="chapter" data-level="3.7.5" data-path="introR.html"><a href="introR.html#veclength"><i class="fa fa-check"></i><b>3.7.5</b> Useful things to know about vectors</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="introR.html"><a href="introR.html#text"><i class="fa fa-check"></i><b>3.8</b> Storing text data</a><ul>
<li class="chapter" data-level="3.8.1" data-path="introR.html"><a href="introR.html#simpletext"><i class="fa fa-check"></i><b>3.8.1</b> Working with text</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="introR.html"><a href="introR.html#logicals"><i class="fa fa-check"></i><b>3.9</b> Storing “true or false” data</a><ul>
<li class="chapter" data-level="3.9.1" data-path="introR.html"><a href="introR.html#assessing-mathematical-truths"><i class="fa fa-check"></i><b>3.9.1</b> Assessing mathematical truths</a></li>
<li class="chapter" data-level="3.9.2" data-path="introR.html"><a href="introR.html#logical-operations"><i class="fa fa-check"></i><b>3.9.2</b> Logical operations</a></li>
<li class="chapter" data-level="3.9.3" data-path="introR.html"><a href="introR.html#storing-and-using-logical-data"><i class="fa fa-check"></i><b>3.9.3</b> Storing and using logical data</a></li>
<li class="chapter" data-level="3.9.4" data-path="introR.html"><a href="introR.html#vectors-of-logicals"><i class="fa fa-check"></i><b>3.9.4</b> Vectors of logicals</a></li>
<li class="chapter" data-level="3.9.5" data-path="introR.html"><a href="introR.html#logictext"><i class="fa fa-check"></i><b>3.9.5</b> Applying logical operation to text</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="introR.html"><a href="introR.html#indexing"><i class="fa fa-check"></i><b>3.10</b> Indexing vectors</a><ul>
<li class="chapter" data-level="3.10.1" data-path="introR.html"><a href="introR.html#extracting-multiple-elements"><i class="fa fa-check"></i><b>3.10.1</b> Extracting multiple elements</a></li>
<li class="chapter" data-level="3.10.2" data-path="introR.html"><a href="introR.html#logical-indexing"><i class="fa fa-check"></i><b>3.10.2</b> Logical indexing</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="introR.html"><a href="introR.html#quitting-r"><i class="fa fa-check"></i><b>3.11</b> Quitting R</a></li>
<li class="chapter" data-level="3.12" data-path="introR.html"><a href="introR.html#summary-1"><i class="fa fa-check"></i><b>3.12</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="mechanics.html"><a href="mechanics.html"><i class="fa fa-check"></i><b>4</b> Additional R concepts</a><ul>
<li class="chapter" data-level="4.1" data-path="mechanics.html"><a href="mechanics.html#comments"><i class="fa fa-check"></i><b>4.1</b> Using comments</a></li>
<li class="chapter" data-level="4.2" data-path="mechanics.html"><a href="mechanics.html#packageinstall"><i class="fa fa-check"></i><b>4.2</b> Installing and loading packages</a><ul>
<li class="chapter" data-level="4.2.1" data-path="mechanics.html"><a href="mechanics.html#the-package-panel-in-rstudio"><i class="fa fa-check"></i><b>4.2.1</b> The package panel in RStudio</a></li>
<li class="chapter" data-level="4.2.2" data-path="mechanics.html"><a href="mechanics.html#packageload"><i class="fa fa-check"></i><b>4.2.2</b> Loading a package</a></li>
<li class="chapter" data-level="4.2.3" data-path="mechanics.html"><a href="mechanics.html#packageunload"><i class="fa fa-check"></i><b>4.2.3</b> Unloading a package</a></li>
<li class="chapter" data-level="4.2.4" data-path="mechanics.html"><a href="mechanics.html#a-few-extra-comments"><i class="fa fa-check"></i><b>4.2.4</b> A few extra comments</a></li>
<li class="chapter" data-level="4.2.5" data-path="mechanics.html"><a href="mechanics.html#downloading-new-packages"><i class="fa fa-check"></i><b>4.2.5</b> Downloading new packages</a></li>
<li class="chapter" data-level="4.2.6" data-path="mechanics.html"><a href="mechanics.html#updating-r-and-r-packages"><i class="fa fa-check"></i><b>4.2.6</b> Updating R and R packages</a></li>
<li class="chapter" data-level="4.2.7" data-path="mechanics.html"><a href="mechanics.html#what-packages-does-this-book-use"><i class="fa fa-check"></i><b>4.2.7</b> What packages does this book use?</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="mechanics.html"><a href="mechanics.html#workspace"><i class="fa fa-check"></i><b>4.3</b> Managing the workspace</a><ul>
<li class="chapter" data-level="4.3.1" data-path="mechanics.html"><a href="mechanics.html#listing-the-contents-of-the-workspace"><i class="fa fa-check"></i><b>4.3.1</b> Listing the contents of the workspace</a></li>
<li class="chapter" data-level="4.3.2" data-path="mechanics.html"><a href="mechanics.html#removing-variables-from-the-workspace"><i class="fa fa-check"></i><b>4.3.2</b> Removing variables from the workspace</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="mechanics.html"><a href="mechanics.html#navigation"><i class="fa fa-check"></i><b>4.4</b> Navigating the file system</a><ul>
<li class="chapter" data-level="4.4.1" data-path="mechanics.html"><a href="mechanics.html#filesystem"><i class="fa fa-check"></i><b>4.4.1</b> The file system itself</a></li>
<li class="chapter" data-level="4.4.2" data-path="mechanics.html"><a href="mechanics.html#navigationR"><i class="fa fa-check"></i><b>4.4.2</b> Navigating the file system using the R console</a></li>
<li class="chapter" data-level="4.4.3" data-path="mechanics.html"><a href="mechanics.html#why-do-the-windows-paths-use-the-wrong-slash"><i class="fa fa-check"></i><b>4.4.3</b> Why do the Windows paths use the wrong slash?</a></li>
<li class="chapter" data-level="4.4.4" data-path="mechanics.html"><a href="mechanics.html#nav3"><i class="fa fa-check"></i><b>4.4.4</b> Navigating the file system using the RStudio file panel</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="mechanics.html"><a href="mechanics.html#load"><i class="fa fa-check"></i><b>4.5</b> Loading and saving data</a><ul>
<li class="chapter" data-level="4.5.1" data-path="mechanics.html"><a href="mechanics.html#loading-workspace-files-using-r"><i class="fa fa-check"></i><b>4.5.1</b> Loading workspace files using R</a></li>
<li class="chapter" data-level="4.5.2" data-path="mechanics.html"><a href="mechanics.html#loading-workspace-files-using-rstudio"><i class="fa fa-check"></i><b>4.5.2</b> Loading workspace files using RStudio</a></li>
<li class="chapter" data-level="4.5.3" data-path="mechanics.html"><a href="mechanics.html#loadingcsv"><i class="fa fa-check"></i><b>4.5.3</b> Importing data from CSV files using loadingcsv</a></li>
<li class="chapter" data-level="4.5.4" data-path="mechanics.html"><a href="mechanics.html#importing-data-from-csv-files-using-rstudio"><i class="fa fa-check"></i><b>4.5.4</b> Importing data from CSV files using RStudio</a></li>
<li class="chapter" data-level="4.5.5" data-path="mechanics.html"><a href="mechanics.html#saving-a-workspace-file-using-save"><i class="fa fa-check"></i><b>4.5.5</b> Saving a workspace file using <code>save</code></a></li>
<li class="chapter" data-level="4.5.6" data-path="mechanics.html"><a href="mechanics.html#save1"><i class="fa fa-check"></i><b>4.5.6</b> Saving a workspace file using RStudio</a></li>
<li class="chapter" data-level="4.5.7" data-path="mechanics.html"><a href="mechanics.html#other-things-you-might-want-to-save"><i class="fa fa-check"></i><b>4.5.7</b> Other things you might want to save</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="mechanics.html"><a href="mechanics.html#useful"><i class="fa fa-check"></i><b>4.6</b> Useful things to know about variables</a><ul>
<li class="chapter" data-level="4.6.1" data-path="mechanics.html"><a href="mechanics.html#specials"><i class="fa fa-check"></i><b>4.6.1</b> Special values</a></li>
<li class="chapter" data-level="4.6.2" data-path="mechanics.html"><a href="mechanics.html#names"><i class="fa fa-check"></i><b>4.6.2</b> Assigning names to vector elements</a></li>
<li class="chapter" data-level="4.6.3" data-path="mechanics.html"><a href="mechanics.html#variable-classes"><i class="fa fa-check"></i><b>4.6.3</b> Variable classes</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="mechanics.html"><a href="mechanics.html#factors"><i class="fa fa-check"></i><b>4.7</b> Factors</a><ul>
<li class="chapter" data-level="4.7.1" data-path="mechanics.html"><a href="mechanics.html#introducing-factors"><i class="fa fa-check"></i><b>4.7.1</b> Introducing factors</a></li>
<li class="chapter" data-level="4.7.2" data-path="mechanics.html"><a href="mechanics.html#labelling-the-factor-levels"><i class="fa fa-check"></i><b>4.7.2</b> Labelling the factor levels</a></li>
<li class="chapter" data-level="4.7.3" data-path="mechanics.html"><a href="mechanics.html#moving-on"><i class="fa fa-check"></i><b>4.7.3</b> Moving on…</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="mechanics.html"><a href="mechanics.html#dataframes"><i class="fa fa-check"></i><b>4.8</b> Data frames</a><ul>
<li class="chapter" data-level="4.8.1" data-path="mechanics.html"><a href="mechanics.html#introducing-data-frames"><i class="fa fa-check"></i><b>4.8.1</b> Introducing data frames</a></li>
<li class="chapter" data-level="4.8.2" data-path="mechanics.html"><a href="mechanics.html#pulling-out-the-contents-of-the-data-frame-using"><i class="fa fa-check"></i><b>4.8.2</b> Pulling out the contents of the data frame using <code>$</code></a></li>
<li class="chapter" data-level="4.8.3" data-path="mechanics.html"><a href="mechanics.html#getting-information-about-a-data-frame"><i class="fa fa-check"></i><b>4.8.3</b> Getting information about a data frame</a></li>
<li class="chapter" data-level="4.8.4" data-path="mechanics.html"><a href="mechanics.html#looking-for-more-on-data-frames"><i class="fa fa-check"></i><b>4.8.4</b> Looking for more on data frames?</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="mechanics.html"><a href="mechanics.html#lists"><i class="fa fa-check"></i><b>4.9</b> Lists</a></li>
<li class="chapter" data-level="4.10" data-path="mechanics.html"><a href="mechanics.html#formulas"><i class="fa fa-check"></i><b>4.10</b> Formulas</a></li>
<li class="chapter" data-level="4.11" data-path="mechanics.html"><a href="mechanics.html#generics"><i class="fa fa-check"></i><b>4.11</b> Generic functions</a></li>
<li class="chapter" data-level="4.12" data-path="mechanics.html"><a href="mechanics.html#help"><i class="fa fa-check"></i><b>4.12</b> Getting help</a><ul>
<li class="chapter" data-level="4.12.1" data-path="mechanics.html"><a href="mechanics.html#how-to-read-the-help-documentation"><i class="fa fa-check"></i><b>4.12.1</b> How to read the help documentation</a></li>
<li class="chapter" data-level="4.12.2" data-path="mechanics.html"><a href="mechanics.html#other-resources"><i class="fa fa-check"></i><b>4.12.2</b> Other resources</a></li>
</ul></li>
<li class="chapter" data-level="4.13" data-path="mechanics.html"><a href="mechanics.html#summary-2"><i class="fa fa-check"></i><b>4.13</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-iii-working-with-data.html"><a href="part-iii-working-with-data.html"><i class="fa fa-check"></i>Part III. Working with data</a></li>
<li class="chapter" data-level="5" data-path="descriptives.html"><a href="descriptives.html"><i class="fa fa-check"></i><b>5</b> Descriptive statistics</a><ul>
<li class="chapter" data-level="5.1" data-path="descriptives.html"><a href="descriptives.html#centraltendency"><i class="fa fa-check"></i><b>5.1</b> Measures of central tendency</a><ul>
<li class="chapter" data-level="5.1.1" data-path="descriptives.html"><a href="descriptives.html#mean"><i class="fa fa-check"></i><b>5.1.1</b> The mean</a></li>
<li class="chapter" data-level="5.1.2" data-path="descriptives.html"><a href="descriptives.html#calculating-the-mean-in-r"><i class="fa fa-check"></i><b>5.1.2</b> Calculating the mean in R</a></li>
<li class="chapter" data-level="5.1.3" data-path="descriptives.html"><a href="descriptives.html#median"><i class="fa fa-check"></i><b>5.1.3</b> The median</a></li>
<li class="chapter" data-level="5.1.4" data-path="descriptives.html"><a href="descriptives.html#mean-or-median-whats-the-difference"><i class="fa fa-check"></i><b>5.1.4</b> Mean or median? What’s the difference?</a></li>
<li class="chapter" data-level="5.1.5" data-path="descriptives.html"><a href="descriptives.html#housingpriceexample"><i class="fa fa-check"></i><b>5.1.5</b> A real life example</a></li>
<li class="chapter" data-level="5.1.6" data-path="descriptives.html"><a href="descriptives.html#trimmedmean"><i class="fa fa-check"></i><b>5.1.6</b> Trimmed mean</a></li>
<li class="chapter" data-level="5.1.7" data-path="descriptives.html"><a href="descriptives.html#mode"><i class="fa fa-check"></i><b>5.1.7</b> Mode</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="descriptives.html"><a href="descriptives.html#var"><i class="fa fa-check"></i><b>5.2</b> Measures of variability</a><ul>
<li class="chapter" data-level="5.2.1" data-path="descriptives.html"><a href="descriptives.html#range"><i class="fa fa-check"></i><b>5.2.1</b> Range</a></li>
<li class="chapter" data-level="5.2.2" data-path="descriptives.html"><a href="descriptives.html#interquartile-range"><i class="fa fa-check"></i><b>5.2.2</b> Interquartile range</a></li>
<li class="chapter" data-level="5.2.3" data-path="descriptives.html"><a href="descriptives.html#aad"><i class="fa fa-check"></i><b>5.2.3</b> Mean absolute deviation</a></li>
<li class="chapter" data-level="5.2.4" data-path="descriptives.html"><a href="descriptives.html#variance"><i class="fa fa-check"></i><b>5.2.4</b> Variance</a></li>
<li class="chapter" data-level="5.2.5" data-path="descriptives.html"><a href="descriptives.html#sd"><i class="fa fa-check"></i><b>5.2.5</b> Standard deviation</a></li>
<li class="chapter" data-level="5.2.6" data-path="descriptives.html"><a href="descriptives.html#mad"><i class="fa fa-check"></i><b>5.2.6</b> Median absolute deviation</a></li>
<li class="chapter" data-level="5.2.7" data-path="descriptives.html"><a href="descriptives.html#which-measure-to-use"><i class="fa fa-check"></i><b>5.2.7</b> Which measure to use?</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="descriptives.html"><a href="descriptives.html#skewandkurtosis"><i class="fa fa-check"></i><b>5.3</b> Skew and kurtosis</a></li>
<li class="chapter" data-level="5.4" data-path="studydesign.html"><a href="studydesign.html#summary"><i class="fa fa-check"></i><b>5.4</b> Getting an overall summary of a variable</a><ul>
<li class="chapter" data-level="5.4.1" data-path="descriptives.html"><a href="descriptives.html#summarising-a-variable"><i class="fa fa-check"></i><b>5.4.1</b> “Summarising” a variable</a></li>
<li class="chapter" data-level="5.4.2" data-path="descriptives.html"><a href="descriptives.html#summarising-a-data-frame"><i class="fa fa-check"></i><b>5.4.2</b> “Summarising” a data frame</a></li>
<li class="chapter" data-level="5.4.3" data-path="descriptives.html"><a href="descriptives.html#describing-a-data-frame"><i class="fa fa-check"></i><b>5.4.3</b> “Describing” a data frame</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="descriptives.html"><a href="descriptives.html#groupdescriptives"><i class="fa fa-check"></i><b>5.5</b> Descriptive statistics separately for each group</a></li>
<li class="chapter" data-level="5.6" data-path="descriptives.html"><a href="descriptives.html#zscore"><i class="fa fa-check"></i><b>5.6</b> Standard scores</a></li>
<li class="chapter" data-level="5.7" data-path="descriptives.html"><a href="descriptives.html#correl"><i class="fa fa-check"></i><b>5.7</b> Correlations</a><ul>
<li class="chapter" data-level="5.7.1" data-path="descriptives.html"><a href="descriptives.html#the-data"><i class="fa fa-check"></i><b>5.7.1</b> The data</a></li>
<li class="chapter" data-level="5.7.2" data-path="descriptives.html"><a href="descriptives.html#the-strength-and-direction-of-a-relationship"><i class="fa fa-check"></i><b>5.7.2</b> The strength and direction of a relationship</a></li>
<li class="chapter" data-level="5.7.3" data-path="descriptives.html"><a href="descriptives.html#the-correlation-coefficient"><i class="fa fa-check"></i><b>5.7.3</b> The correlation coefficient</a></li>
<li class="chapter" data-level="5.7.4" data-path="descriptives.html"><a href="descriptives.html#calculating-correlations-in-r"><i class="fa fa-check"></i><b>5.7.4</b> Calculating correlations in R</a></li>
<li class="chapter" data-level="5.7.5" data-path="descriptives.html"><a href="descriptives.html#interpretingcorrelations"><i class="fa fa-check"></i><b>5.7.5</b> Interpreting a correlation</a></li>
<li class="chapter" data-level="5.7.6" data-path="descriptives.html"><a href="descriptives.html#spearmans-rank-correlations"><i class="fa fa-check"></i><b>5.7.6</b> Spearman’s rank correlations</a></li>
<li class="chapter" data-level="5.7.7" data-path="descriptives.html"><a href="descriptives.html#the-correlate-function"><i class="fa fa-check"></i><b>5.7.7</b> The <code>correlate()</code> function</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="descriptives.html"><a href="descriptives.html#missing"><i class="fa fa-check"></i><b>5.8</b> Handling missing values</a><ul>
<li class="chapter" data-level="5.8.1" data-path="descriptives.html"><a href="descriptives.html#the-single-variable-case"><i class="fa fa-check"></i><b>5.8.1</b> The single variable case</a></li>
<li class="chapter" data-level="5.8.2" data-path="descriptives.html"><a href="descriptives.html#missing-values-in-pairwise-calculations"><i class="fa fa-check"></i><b>5.8.2</b> Missing values in pairwise calculations</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="descriptives.html"><a href="descriptives.html#summary-3"><i class="fa fa-check"></i><b>5.9</b> Summary</a></li>
<li class="chapter" data-level="5.10" data-path="descriptives.html"><a href="descriptives.html#epilogue-good-descriptive-statistics-are-descriptive"><i class="fa fa-check"></i><b>5.10</b> Epilogue: Good descriptive statistics are descriptive!</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="graphics.html"><a href="graphics.html"><i class="fa fa-check"></i><b>6</b> Drawing graphs</a><ul>
<li class="chapter" data-level="6.1" data-path="graphics.html"><a href="graphics.html#rgraphics"><i class="fa fa-check"></i><b>6.1</b> An overview of R graphics</a></li>
<li class="chapter" data-level="6.2" data-path="graphics.html"><a href="graphics.html#introplotting"><i class="fa fa-check"></i><b>6.2</b> An introduction to plotting</a><ul>
<li class="chapter" data-level="6.2.1" data-path="graphics.html"><a href="graphics.html#a-tedious-digression"><i class="fa fa-check"></i><b>6.2.1</b> A tedious digression</a></li>
<li class="chapter" data-level="6.2.2" data-path="graphics.html"><a href="graphics.html#figtitles"><i class="fa fa-check"></i><b>6.2.2</b> Customising the title and the axis labels</a></li>
<li class="chapter" data-level="6.2.3" data-path="graphics.html"><a href="graphics.html#changing-the-plot-type"><i class="fa fa-check"></i><b>6.2.3</b> Changing the plot type</a></li>
<li class="chapter" data-level="6.2.4" data-path="graphics.html"><a href="graphics.html#changing-other-features-of-the-plot"><i class="fa fa-check"></i><b>6.2.4</b> Changing other features of the plot</a></li>
<li class="chapter" data-level="6.2.5" data-path="graphics.html"><a href="graphics.html#changing-the-appearance-of-the-axes"><i class="fa fa-check"></i><b>6.2.5</b> Changing the appearance of the axes</a></li>
<li class="chapter" data-level="6.2.6" data-path="graphics.html"><a href="graphics.html#dont-panic"><i class="fa fa-check"></i><b>6.2.6</b> Don’t panic</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="graphics.html"><a href="graphics.html#hist"><i class="fa fa-check"></i><b>6.3</b> Histograms</a><ul>
<li class="chapter" data-level="6.3.1" data-path="graphics.html"><a href="graphics.html#visual-style-of-your-histogram"><i class="fa fa-check"></i><b>6.3.1</b> Visual style of your histogram</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="graphics.html"><a href="graphics.html#stem"><i class="fa fa-check"></i><b>6.4</b> Stem and leaf plots</a></li>
<li class="chapter" data-level="6.5" data-path="graphics.html"><a href="graphics.html#boxplots"><i class="fa fa-check"></i><b>6.5</b> Boxplots</a><ul>
<li class="chapter" data-level="6.5.1" data-path="graphics.html"><a href="graphics.html#visual-style-of-your-boxplot"><i class="fa fa-check"></i><b>6.5.1</b> Visual style of your boxplot</a></li>
<li class="chapter" data-level="6.5.2" data-path="graphics.html"><a href="graphics.html#boxplotoutliers"><i class="fa fa-check"></i><b>6.5.2</b> Using box plots to detect outliers</a></li>
<li class="chapter" data-level="6.5.3" data-path="graphics.html"><a href="graphics.html#multipleboxplots"><i class="fa fa-check"></i><b>6.5.3</b> Drawing multiple boxplots</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="graphics.html"><a href="graphics.html#scatterplots"><i class="fa fa-check"></i><b>6.6</b> Scatterplots</a><ul>
<li class="chapter" data-level="6.6.1" data-path="graphics.html"><a href="graphics.html#more-elaborate-options"><i class="fa fa-check"></i><b>6.6.1</b> More elaborate options</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="graphics.html"><a href="graphics.html#bargraph"><i class="fa fa-check"></i><b>6.7</b> Bar graphs</a><ul>
<li class="chapter" data-level="6.7.1" data-path="graphics.html"><a href="graphics.html#par"><i class="fa fa-check"></i><b>6.7.1</b> Changing global settings using par()</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="graphics.html"><a href="graphics.html#saveimage"><i class="fa fa-check"></i><b>6.8</b> Saving image files using R and Rstudio</a><ul>
<li class="chapter" data-level="6.8.1" data-path="graphics.html"><a href="graphics.html#the-ugly-details-advanced"><i class="fa fa-check"></i><b>6.8.1</b> The ugly details (advanced)</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="graphics.html"><a href="graphics.html#summary-4"><i class="fa fa-check"></i><b>6.9</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="datahandling.html"><a href="datahandling.html"><i class="fa fa-check"></i><b>7</b> Pragmatic matters</a><ul>
<li class="chapter" data-level="7.1" data-path="datahandling.html"><a href="datahandling.html#freqtables"><i class="fa fa-check"></i><b>7.1</b> Tabulating and cross-tabulating data</a><ul>
<li class="chapter" data-level="7.1.1" data-path="datahandling.html"><a href="datahandling.html#creating-tables-from-vectors"><i class="fa fa-check"></i><b>7.1.1</b> Creating tables from vectors</a></li>
<li class="chapter" data-level="7.1.2" data-path="datahandling.html"><a href="datahandling.html#creating-tables-from-data-frames"><i class="fa fa-check"></i><b>7.1.2</b> Creating tables from data frames</a></li>
<li class="chapter" data-level="7.1.3" data-path="datahandling.html"><a href="datahandling.html#converting-a-table-of-counts-to-a-table-of-proportions"><i class="fa fa-check"></i><b>7.1.3</b> Converting a table of counts to a table of proportions</a></li>
<li class="chapter" data-level="7.1.4" data-path="datahandling.html"><a href="datahandling.html#low-level-tabulation"><i class="fa fa-check"></i><b>7.1.4</b> Low level tabulation</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="datahandling.html"><a href="datahandling.html#transform"><i class="fa fa-check"></i><b>7.2</b> Transforming and recoding a variable</a><ul>
<li class="chapter" data-level="7.2.1" data-path="datahandling.html"><a href="datahandling.html#creating-a-transformed-variable"><i class="fa fa-check"></i><b>7.2.1</b> Creating a transformed variable</a></li>
<li class="chapter" data-level="7.2.2" data-path="datahandling.html"><a href="datahandling.html#cutting-a-numeric-variable-into-categories"><i class="fa fa-check"></i><b>7.2.2</b> Cutting a numeric variable into categories</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="datahandling.html"><a href="datahandling.html#mathfunc"><i class="fa fa-check"></i><b>7.3</b> A few more mathematical functions and operations</a><ul>
<li class="chapter" data-level="7.3.1" data-path="datahandling.html"><a href="datahandling.html#rounding-a-number"><i class="fa fa-check"></i><b>7.3.1</b> Rounding a number</a></li>
<li class="chapter" data-level="7.3.2" data-path="datahandling.html"><a href="datahandling.html#modulus-and-integer-division"><i class="fa fa-check"></i><b>7.3.2</b> Modulus and integer division</a></li>
<li class="chapter" data-level="7.3.3" data-path="datahandling.html"><a href="datahandling.html#logarithms-and-exponentials"><i class="fa fa-check"></i><b>7.3.3</b> Logarithms and exponentials</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="datahandling.html"><a href="datahandling.html#subset"><i class="fa fa-check"></i><b>7.4</b> Extracting a subset of a vector</a><ul>
<li class="chapter" data-level="7.4.1" data-path="datahandling.html"><a href="datahandling.html#refresher"><i class="fa fa-check"></i><b>7.4.1</b> Refresher</a></li>
<li class="chapter" data-level="7.4.2" data-path="datahandling.html"><a href="datahandling.html#using-in-to-match-multiple-cases"><i class="fa fa-check"></i><b>7.4.2</b> Using <code>%in%</code> to match multiple cases</a></li>
<li class="chapter" data-level="7.4.3" data-path="datahandling.html"><a href="datahandling.html#using-negative-indices-to-drop-elements"><i class="fa fa-check"></i><b>7.4.3</b> Using negative indices to drop elements</a></li>
<li class="chapter" data-level="7.4.4" data-path="datahandling.html"><a href="datahandling.html#splitting-a-vector-by-group"><i class="fa fa-check"></i><b>7.4.4</b> Splitting a vector by group</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="datahandling.html"><a href="datahandling.html#subsetdataframe"><i class="fa fa-check"></i><b>7.5</b> Extracting a subset of a data frame</a><ul>
<li class="chapter" data-level="7.5.1" data-path="datahandling.html"><a href="datahandling.html#using-the-subset-function"><i class="fa fa-check"></i><b>7.5.1</b> Using the <code>subset()</code> function</a></li>
<li class="chapter" data-level="7.5.2" data-path="datahandling.html"><a href="datahandling.html#using-square-brackets-i.-rows-and-columns"><i class="fa fa-check"></i><b>7.5.2</b> Using square brackets: I. Rows and columns</a></li>
<li class="chapter" data-level="7.5.3" data-path="datahandling.html"><a href="datahandling.html#using-square-brackets-ii.-some-elaborations"><i class="fa fa-check"></i><b>7.5.3</b> Using square brackets: II. Some elaborations</a></li>
<li class="chapter" data-level="7.5.4" data-path="datahandling.html"><a href="datahandling.html#dropping"><i class="fa fa-check"></i><b>7.5.4</b> Using square brackets: III. Understanding “dropping”</a></li>
<li class="chapter" data-level="7.5.5" data-path="datahandling.html"><a href="datahandling.html#using-square-brackets-iv.-columns-only"><i class="fa fa-check"></i><b>7.5.5</b> Using square brackets: IV. Columns only</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="datahandling.html"><a href="datahandling.html#sort"><i class="fa fa-check"></i><b>7.6</b> Sorting, flipping and merging data</a><ul>
<li class="chapter" data-level="7.6.1" data-path="datahandling.html"><a href="datahandling.html#sorting-a-numeric-or-character-vector"><i class="fa fa-check"></i><b>7.6.1</b> Sorting a numeric or character vector</a></li>
<li class="chapter" data-level="7.6.2" data-path="datahandling.html"><a href="datahandling.html#sorting-a-factor"><i class="fa fa-check"></i><b>7.6.2</b> Sorting a factor</a></li>
<li class="chapter" data-level="7.6.3" data-path="datahandling.html"><a href="datahandling.html#sortframe"><i class="fa fa-check"></i><b>7.6.3</b> Sorting a data frame</a></li>
<li class="chapter" data-level="7.6.4" data-path="datahandling.html"><a href="datahandling.html#binding-vectors-together"><i class="fa fa-check"></i><b>7.6.4</b> Binding vectors together</a></li>
<li class="chapter" data-level="7.6.5" data-path="datahandling.html"><a href="datahandling.html#binding-multiple-copies-of-the-same-vector-together"><i class="fa fa-check"></i><b>7.6.5</b> Binding multiple copies of the same vector together</a></li>
<li class="chapter" data-level="7.6.6" data-path="datahandling.html"><a href="datahandling.html#transposing-a-matrix-or-data-frame"><i class="fa fa-check"></i><b>7.6.6</b> Transposing a matrix or data frame</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="datahandling.html"><a href="datahandling.html#reshape"><i class="fa fa-check"></i><b>7.7</b> Reshaping a data frame</a><ul>
<li class="chapter" data-level="7.7.1" data-path="datahandling.html"><a href="datahandling.html#long-form-and-wide-form-data"><i class="fa fa-check"></i><b>7.7.1</b> Long form and wide form data</a></li>
<li class="chapter" data-level="7.7.2" data-path="datahandling.html"><a href="datahandling.html#reshaping-data-using-widetolong"><i class="fa fa-check"></i><b>7.7.2</b> Reshaping data using <code>wideToLong()</code></a></li>
<li class="chapter" data-level="7.7.3" data-path="datahandling.html"><a href="datahandling.html#reshaping-data-using-longtowide"><i class="fa fa-check"></i><b>7.7.3</b> Reshaping data using <code>longToWide()</code></a></li>
<li class="chapter" data-level="7.7.4" data-path="datahandling.html"><a href="datahandling.html#reshaping-with-multiple-within-subject-factors"><i class="fa fa-check"></i><b>7.7.4</b> Reshaping with multiple within-subject factors</a></li>
<li class="chapter" data-level="7.7.5" data-path="datahandling.html"><a href="datahandling.html#what-other-options-are-there"><i class="fa fa-check"></i><b>7.7.5</b> What other options are there?</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="datahandling.html"><a href="datahandling.html#textprocessing"><i class="fa fa-check"></i><b>7.8</b> Working with text</a><ul>
<li class="chapter" data-level="7.8.1" data-path="datahandling.html"><a href="datahandling.html#shortening-a-string"><i class="fa fa-check"></i><b>7.8.1</b> Shortening a string</a></li>
<li class="chapter" data-level="7.8.2" data-path="datahandling.html"><a href="datahandling.html#pasting-strings-together"><i class="fa fa-check"></i><b>7.8.2</b> Pasting strings together</a></li>
<li class="chapter" data-level="7.8.3" data-path="datahandling.html"><a href="datahandling.html#splitting-strings"><i class="fa fa-check"></i><b>7.8.3</b> Splitting strings</a></li>
<li class="chapter" data-level="7.8.4" data-path="datahandling.html"><a href="datahandling.html#making-simple-conversions"><i class="fa fa-check"></i><b>7.8.4</b> Making simple conversions</a></li>
<li class="chapter" data-level="7.8.5" data-path="datahandling.html"><a href="datahandling.html#logictext2"><i class="fa fa-check"></i><b>7.8.5</b> Applying logical operations to text</a></li>
<li class="chapter" data-level="7.8.6" data-path="datahandling.html"><a href="datahandling.html#concatenating-and-printing-with-cat"><i class="fa fa-check"></i><b>7.8.6</b> Concatenating and printing with <code>cat()</code></a></li>
<li class="chapter" data-level="7.8.7" data-path="datahandling.html"><a href="datahandling.html#escapechars"><i class="fa fa-check"></i><b>7.8.7</b> Using escape characters in text</a></li>
<li class="chapter" data-level="7.8.8" data-path="datahandling.html"><a href="datahandling.html#matching-and-substituting-text"><i class="fa fa-check"></i><b>7.8.8</b> Matching and substituting text</a></li>
<li class="chapter" data-level="7.8.9" data-path="datahandling.html"><a href="datahandling.html#regex"><i class="fa fa-check"></i><b>7.8.9</b> Regular expressions (not really)</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="datahandling.html"><a href="datahandling.html#importing"><i class="fa fa-check"></i><b>7.9</b> Reading unusual data files</a><ul>
<li class="chapter" data-level="7.9.1" data-path="datahandling.html"><a href="datahandling.html#loading-data-from-text-files"><i class="fa fa-check"></i><b>7.9.1</b> Loading data from text files</a></li>
<li class="chapter" data-level="7.9.2" data-path="datahandling.html"><a href="datahandling.html#loading-data-from-spss-and-other-statistics-packages"><i class="fa fa-check"></i><b>7.9.2</b> Loading data from SPSS (and other statistics packages)</a></li>
<li class="chapter" data-level="7.9.3" data-path="datahandling.html"><a href="datahandling.html#loading-excel-files"><i class="fa fa-check"></i><b>7.9.3</b> Loading Excel files</a></li>
<li class="chapter" data-level="7.9.4" data-path="datahandling.html"><a href="datahandling.html#loading-matlab-octave-files"><i class="fa fa-check"></i><b>7.9.4</b> Loading Matlab (&amp; Octave) files</a></li>
<li class="chapter" data-level="7.9.5" data-path="datahandling.html"><a href="datahandling.html#saving-other-kinds-of-data"><i class="fa fa-check"></i><b>7.9.5</b> Saving other kinds of data</a></li>
<li class="chapter" data-level="7.9.6" data-path="datahandling.html"><a href="datahandling.html#are-we-done-yet"><i class="fa fa-check"></i><b>7.9.6</b> Are we done yet?</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="datahandling.html"><a href="datahandling.html#coercion"><i class="fa fa-check"></i><b>7.10</b> Coercing data from one class to another</a></li>
<li class="chapter" data-level="7.11" data-path="datahandling.html"><a href="datahandling.html#datastructures"><i class="fa fa-check"></i><b>7.11</b> Other useful data structures</a><ul>
<li class="chapter" data-level="7.11.1" data-path="datahandling.html"><a href="datahandling.html#matrix"><i class="fa fa-check"></i><b>7.11.1</b> Matrices</a></li>
<li class="chapter" data-level="7.11.2" data-path="datahandling.html"><a href="datahandling.html#orderedfactors"><i class="fa fa-check"></i><b>7.11.2</b> Ordered factors</a></li>
<li class="chapter" data-level="7.11.3" data-path="datahandling.html"><a href="datahandling.html#dates"><i class="fa fa-check"></i><b>7.11.3</b> Dates and times</a></li>
</ul></li>
<li class="chapter" data-level="7.12" data-path="datahandling.html"><a href="datahandling.html#miscdatahandling"><i class="fa fa-check"></i><b>7.12</b> Miscellaneous topics</a><ul>
<li class="chapter" data-level="7.12.1" data-path="datahandling.html"><a href="datahandling.html#the-problems-with-floating-point-arithmetic"><i class="fa fa-check"></i><b>7.12.1</b> The problems with floating point arithmetic</a></li>
<li class="chapter" data-level="7.12.2" data-path="datahandling.html"><a href="datahandling.html#recycling"><i class="fa fa-check"></i><b>7.12.2</b> The recycling rule</a></li>
<li class="chapter" data-level="7.12.3" data-path="datahandling.html"><a href="datahandling.html#environments"><i class="fa fa-check"></i><b>7.12.3</b> An introduction to environments</a></li>
<li class="chapter" data-level="7.12.4" data-path="datahandling.html"><a href="datahandling.html#attaching-a-data-frame"><i class="fa fa-check"></i><b>7.12.4</b> Attaching a data frame</a></li>
</ul></li>
<li class="chapter" data-level="7.13" data-path="datahandling.html"><a href="datahandling.html#summary-5"><i class="fa fa-check"></i><b>7.13</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="scripting.html"><a href="scripting.html"><i class="fa fa-check"></i><b>8</b> Basic programming</a><ul>
<li class="chapter" data-level="8.1" data-path="scripting.html"><a href="scripting.html#scripts"><i class="fa fa-check"></i><b>8.1</b> Scripts</a><ul>
<li class="chapter" data-level="8.1.1" data-path="scripting.html"><a href="scripting.html#why-use-scripts"><i class="fa fa-check"></i><b>8.1.1</b> Why use scripts?</a></li>
<li class="chapter" data-level="8.1.2" data-path="scripting.html"><a href="scripting.html#our-first-script"><i class="fa fa-check"></i><b>8.1.2</b> Our first script</a></li>
<li class="chapter" data-level="8.1.3" data-path="scripting.html"><a href="scripting.html#using-rstudio-to-write-scripts"><i class="fa fa-check"></i><b>8.1.3</b> Using Rstudio to write scripts</a></li>
<li class="chapter" data-level="8.1.4" data-path="scripting.html"><a href="scripting.html#commenting-your-script"><i class="fa fa-check"></i><b>8.1.4</b> Commenting your script</a></li>
<li class="chapter" data-level="8.1.5" data-path="scripting.html"><a href="scripting.html#differences-between-scripts-and-the-command-line"><i class="fa fa-check"></i><b>8.1.5</b> Differences between scripts and the command line</a></li>
<li class="chapter" data-level="8.1.6" data-path="scripting.html"><a href="scripting.html#done"><i class="fa fa-check"></i><b>8.1.6</b> Done!</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="scripting.html"><a href="scripting.html#loops"><i class="fa fa-check"></i><b>8.2</b> Loops</a><ul>
<li class="chapter" data-level="8.2.1" data-path="scripting.html"><a href="scripting.html#the-while-loop"><i class="fa fa-check"></i><b>8.2.1</b> The <code>while</code> loop</a></li>
<li class="chapter" data-level="8.2.2" data-path="scripting.html"><a href="scripting.html#for"><i class="fa fa-check"></i><b>8.2.2</b> The <code>for</code> loop</a></li>
<li class="chapter" data-level="8.2.3" data-path="scripting.html"><a href="scripting.html#a-more-realistic-example-of-a-loop"><i class="fa fa-check"></i><b>8.2.3</b> A more realistic example of a loop</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="scripting.html"><a href="scripting.html#if"><i class="fa fa-check"></i><b>8.3</b> Conditional statements</a></li>
<li class="chapter" data-level="8.4" data-path="scripting.html"><a href="scripting.html#functions"><i class="fa fa-check"></i><b>8.4</b> Writing functions</a><ul>
<li class="chapter" data-level="8.4.1" data-path="scripting.html"><a href="scripting.html#dotsargument"><i class="fa fa-check"></i><b>8.4.1</b> Function arguments revisited</a></li>
<li class="chapter" data-level="8.4.2" data-path="scripting.html"><a href="scripting.html#theres-more-to-functions-than-this"><i class="fa fa-check"></i><b>8.4.2</b> There’s more to functions than this</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="scripting.html"><a href="scripting.html#vectorised"><i class="fa fa-check"></i><b>8.5</b> Implicit loops</a></li>
<li class="chapter" data-level="8.6" data-path="scripting.html"><a href="scripting.html#summary-6"><i class="fa fa-check"></i><b>8.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-iv-statistical-theory.html"><a href="part-iv-statistical-theory.html"><i class="fa fa-check"></i>Part IV. Statistical theory</a><ul>
<li class="chapter" data-level="" data-path="part-iv-statistical-theory.html"><a href="part-iv-statistical-theory.html#on-the-limits-of-logical-reasoning"><i class="fa fa-check"></i>On the limits of logical reasoning</a></li>
<li class="chapter" data-level="" data-path="part-iv-statistical-theory.html"><a href="part-iv-statistical-theory.html#learning-without-making-assumptions-is-a-myth"><i class="fa fa-check"></i>Learning without making assumptions is a myth</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>9</b> Introduction to probability</a><ul>
<li class="chapter" data-level="9.1" data-path="probability.html"><a href="probability.html#probstats"><i class="fa fa-check"></i><b>9.1</b> How are probability and statistics different?</a></li>
<li class="chapter" data-level="9.2" data-path="probability.html"><a href="probability.html#probmeaning"><i class="fa fa-check"></i><b>9.2</b> What does probability mean?</a><ul>
<li class="chapter" data-level="9.2.1" data-path="probability.html"><a href="probability.html#the-frequentist-view"><i class="fa fa-check"></i><b>9.2.1</b> The frequentist view</a></li>
<li class="chapter" data-level="9.2.2" data-path="probability.html"><a href="probability.html#the-bayesian-view"><i class="fa fa-check"></i><b>9.2.2</b> The Bayesian view</a></li>
<li class="chapter" data-level="9.2.3" data-path="probability.html"><a href="probability.html#whats-the-difference-and-who-is-right"><i class="fa fa-check"></i><b>9.2.3</b> What’s the difference? And who is right?</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="probability.html"><a href="probability.html#basicprobability"><i class="fa fa-check"></i><b>9.3</b> Basic probability theory</a><ul>
<li class="chapter" data-level="9.3.1" data-path="probability.html"><a href="probability.html#introducing-probability-distributions"><i class="fa fa-check"></i><b>9.3.1</b> Introducing probability distributions</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="probability.html"><a href="probability.html#binomial"><i class="fa fa-check"></i><b>9.4</b> The binomial distribution</a><ul>
<li class="chapter" data-level="9.4.1" data-path="probability.html"><a href="probability.html#introducing-the-binomial"><i class="fa fa-check"></i><b>9.4.1</b> Introducing the binomial</a></li>
<li class="chapter" data-level="9.4.2" data-path="probability.html"><a href="probability.html#working-with-the-binomial-distribution-in-r"><i class="fa fa-check"></i><b>9.4.2</b> Working with the binomial distribution in R</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="probability.html"><a href="probability.html#normal"><i class="fa fa-check"></i><b>9.5</b> The normal distribution</a><ul>
<li class="chapter" data-level="9.5.1" data-path="probability.html"><a href="probability.html#density"><i class="fa fa-check"></i><b>9.5.1</b> Probability density</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="probability.html"><a href="probability.html#otherdists"><i class="fa fa-check"></i><b>9.6</b> Other useful distributions</a></li>
<li class="chapter" data-level="9.7" data-path="probability.html"><a href="probability.html#summary-7"><i class="fa fa-check"></i><b>9.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>10</b> Estimating unknown quantities from a sample</a><ul>
<li class="chapter" data-level="10.1" data-path="estimation.html"><a href="estimation.html#srs"><i class="fa fa-check"></i><b>10.1</b> Samples, populations and sampling</a><ul>
<li class="chapter" data-level="10.1.1" data-path="estimation.html"><a href="estimation.html#pop"><i class="fa fa-check"></i><b>10.1.1</b> Defining a population</a></li>
<li class="chapter" data-level="10.1.2" data-path="estimation.html"><a href="estimation.html#simple-random-samples"><i class="fa fa-check"></i><b>10.1.2</b> Simple random samples</a></li>
<li class="chapter" data-level="10.1.3" data-path="estimation.html"><a href="estimation.html#most-samples-are-not-simple-random-samples"><i class="fa fa-check"></i><b>10.1.3</b> Most samples are not simple random samples</a></li>
<li class="chapter" data-level="10.1.4" data-path="estimation.html"><a href="estimation.html#how-much-does-it-matter-if-you-dont-have-a-simple-random-sample"><i class="fa fa-check"></i><b>10.1.4</b> How much does it matter if you don’t have a simple random sample?</a></li>
<li class="chapter" data-level="10.1.5" data-path="estimation.html"><a href="estimation.html#population-parameters-and-sample-statistics"><i class="fa fa-check"></i><b>10.1.5</b> Population parameters and sample statistics</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="estimation.html"><a href="estimation.html#lawlargenumbers"><i class="fa fa-check"></i><b>10.2</b> The law of large numbers</a></li>
<li class="chapter" data-level="10.3" data-path="estimation.html"><a href="estimation.html#samplesandclt"><i class="fa fa-check"></i><b>10.3</b> Sampling distributions and the central limit theorem</a><ul>
<li class="chapter" data-level="10.3.1" data-path="estimation.html"><a href="estimation.html#samplingdists"><i class="fa fa-check"></i><b>10.3.1</b> Sampling distribution of the mean</a></li>
<li class="chapter" data-level="10.3.2" data-path="estimation.html"><a href="estimation.html#sampling-distributions-exist-for-any-sample-statistic"><i class="fa fa-check"></i><b>10.3.2</b> Sampling distributions exist for any sample statistic!</a></li>
<li class="chapter" data-level="10.3.3" data-path="estimation.html"><a href="estimation.html#clt"><i class="fa fa-check"></i><b>10.3.3</b> The central limit theorem</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="estimation.html"><a href="estimation.html#pointestimates"><i class="fa fa-check"></i><b>10.4</b> Estimating population parameters</a><ul>
<li class="chapter" data-level="10.4.1" data-path="estimation.html"><a href="estimation.html#estimating-the-population-mean"><i class="fa fa-check"></i><b>10.4.1</b> Estimating the population mean</a></li>
<li class="chapter" data-level="10.4.2" data-path="estimation.html"><a href="estimation.html#estimating-the-population-standard-deviation"><i class="fa fa-check"></i><b>10.4.2</b> Estimating the population standard deviation</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="estimation.html"><a href="estimation.html#ci"><i class="fa fa-check"></i><b>10.5</b> Estimating a confidence interval</a><ul>
<li class="chapter" data-level="10.5.1" data-path="estimation.html"><a href="estimation.html#a-slight-mistake-in-the-formula"><i class="fa fa-check"></i><b>10.5.1</b> A slight mistake in the formula</a></li>
<li class="chapter" data-level="10.5.2" data-path="estimation.html"><a href="estimation.html#interpreting-a-confidence-interval"><i class="fa fa-check"></i><b>10.5.2</b> Interpreting a confidence interval</a></li>
<li class="chapter" data-level="10.5.3" data-path="estimation.html"><a href="estimation.html#calculating-confidence-intervals-in-r"><i class="fa fa-check"></i><b>10.5.3</b> Calculating confidence intervals in R</a></li>
<li class="chapter" data-level="10.5.4" data-path="estimation.html"><a href="estimation.html#ciplots"><i class="fa fa-check"></i><b>10.5.4</b> Plotting confidence intervals in R</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="estimation.html"><a href="estimation.html#summary-8"><i class="fa fa-check"></i><b>10.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="hypothesistesting.html"><a href="hypothesistesting.html"><i class="fa fa-check"></i><b>11</b> Hypothesis testing</a><ul>
<li class="chapter" data-level="11.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#hypotheses"><i class="fa fa-check"></i><b>11.1</b> A menagerie of hypotheses</a><ul>
<li class="chapter" data-level="11.1.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#research-hypotheses-versus-statistical-hypotheses"><i class="fa fa-check"></i><b>11.1.1</b> Research hypotheses versus statistical hypotheses</a></li>
<li class="chapter" data-level="11.1.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#null-hypotheses-and-alternative-hypotheses"><i class="fa fa-check"></i><b>11.1.2</b> Null hypotheses and alternative hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#errortypes"><i class="fa fa-check"></i><b>11.2</b> Two types of errors</a></li>
<li class="chapter" data-level="11.3" data-path="hypothesistesting.html"><a href="hypothesistesting.html#teststatistics"><i class="fa fa-check"></i><b>11.3</b> Test statistics and sampling distributions</a></li>
<li class="chapter" data-level="11.4" data-path="hypothesistesting.html"><a href="hypothesistesting.html#decisionmaking"><i class="fa fa-check"></i><b>11.4</b> Making decisions</a><ul>
<li class="chapter" data-level="11.4.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#critical-regions-and-critical-values"><i class="fa fa-check"></i><b>11.4.1</b> Critical regions and critical values</a></li>
<li class="chapter" data-level="11.4.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#a-note-on-statistical-significance"><i class="fa fa-check"></i><b>11.4.2</b> A note on statistical “significance”</a></li>
<li class="chapter" data-level="11.4.3" data-path="hypothesistesting.html"><a href="hypothesistesting.html#onesidedtests"><i class="fa fa-check"></i><b>11.4.3</b> The difference between one sided and two sided tests</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="hypothesistesting.html"><a href="hypothesistesting.html#pvalue"><i class="fa fa-check"></i><b>11.5</b> The <span class="math inline">\(p\)</span> value of a test</a><ul>
<li class="chapter" data-level="11.5.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#a-softer-view-of-decision-making"><i class="fa fa-check"></i><b>11.5.1</b> A softer view of decision making</a></li>
<li class="chapter" data-level="11.5.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#the-probability-of-extreme-data"><i class="fa fa-check"></i><b>11.5.2</b> The probability of extreme data</a></li>
<li class="chapter" data-level="11.5.3" data-path="hypothesistesting.html"><a href="hypothesistesting.html#a-common-mistake"><i class="fa fa-check"></i><b>11.5.3</b> A common mistake</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="hypothesistesting.html"><a href="hypothesistesting.html#writeup"><i class="fa fa-check"></i><b>11.6</b> Reporting the results of a hypothesis test</a><ul>
<li class="chapter" data-level="11.6.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#the-issue"><i class="fa fa-check"></i><b>11.6.1</b> The issue</a></li>
<li class="chapter" data-level="11.6.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#two-proposed-solutions"><i class="fa fa-check"></i><b>11.6.2</b> Two proposed solutions</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="hypothesistesting.html"><a href="hypothesistesting.html#running-the-hypothesis-test-in-practice"><i class="fa fa-check"></i><b>11.7</b> Running the hypothesis test in practice</a></li>
<li class="chapter" data-level="11.8" data-path="hypothesistesting.html"><a href="hypothesistesting.html#effectsize"><i class="fa fa-check"></i><b>11.8</b> Effect size, sample size and power</a><ul>
<li class="chapter" data-level="11.8.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#the-power-function"><i class="fa fa-check"></i><b>11.8.1</b> The power function</a></li>
<li class="chapter" data-level="11.8.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#effect-size"><i class="fa fa-check"></i><b>11.8.2</b> Effect size</a></li>
<li class="chapter" data-level="11.8.3" data-path="hypothesistesting.html"><a href="hypothesistesting.html#increasing-the-power-of-your-study"><i class="fa fa-check"></i><b>11.8.3</b> Increasing the power of your study</a></li>
</ul></li>
<li class="chapter" data-level="11.9" data-path="hypothesistesting.html"><a href="hypothesistesting.html#nhstmess"><i class="fa fa-check"></i><b>11.9</b> Some issues to consider</a><ul>
<li class="chapter" data-level="11.9.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#neyman-versus-fisher"><i class="fa fa-check"></i><b>11.9.1</b> Neyman versus Fisher</a></li>
<li class="chapter" data-level="11.9.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#bayesians-versus-frequentists"><i class="fa fa-check"></i><b>11.9.2</b> Bayesians versus frequentists</a></li>
<li class="chapter" data-level="11.9.3" data-path="hypothesistesting.html"><a href="hypothesistesting.html#traps"><i class="fa fa-check"></i><b>11.9.3</b> Traps</a></li>
</ul></li>
<li class="chapter" data-level="11.10" data-path="hypothesistesting.html"><a href="hypothesistesting.html#summary-9"><i class="fa fa-check"></i><b>11.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-v-statistical-tools.html"><a href="part-v-statistical-tools.html"><i class="fa fa-check"></i>Part V. Statistical tools</a></li>
<li class="chapter" data-level="12" data-path="chisquare.html"><a href="chisquare.html"><i class="fa fa-check"></i><b>12</b> Categorical data analysis</a><ul>
<li class="chapter" data-level="12.1" data-path="chisquare.html"><a href="chisquare.html#goftest"><i class="fa fa-check"></i><b>12.1</b> The <span class="math inline">\(\chi^2\)</span> goodness-of-fit test</a><ul>
<li class="chapter" data-level="12.1.1" data-path="chisquare.html"><a href="chisquare.html#the-cards-data"><i class="fa fa-check"></i><b>12.1.1</b> The cards data</a></li>
<li class="chapter" data-level="12.1.2" data-path="chisquare.html"><a href="chisquare.html#the-null-hypothesis-and-the-alternative-hypothesis"><i class="fa fa-check"></i><b>12.1.2</b> The null hypothesis and the alternative hypothesis</a></li>
<li class="chapter" data-level="12.1.3" data-path="chisquare.html"><a href="chisquare.html#the-goodness-of-fit-test-statistic"><i class="fa fa-check"></i><b>12.1.3</b> The “goodness of fit” test statistic</a></li>
<li class="chapter" data-level="12.1.4" data-path="chisquare.html"><a href="chisquare.html#the-sampling-distribution-of-the-gof-statistic-advanced"><i class="fa fa-check"></i><b>12.1.4</b> The sampling distribution of the GOF statistic (advanced)</a></li>
<li class="chapter" data-level="12.1.5" data-path="chisquare.html"><a href="chisquare.html#degrees-of-freedom"><i class="fa fa-check"></i><b>12.1.5</b> Degrees of freedom</a></li>
<li class="chapter" data-level="12.1.6" data-path="chisquare.html"><a href="chisquare.html#testing-the-null-hypothesis"><i class="fa fa-check"></i><b>12.1.6</b> Testing the null hypothesis</a></li>
<li class="chapter" data-level="12.1.7" data-path="chisquare.html"><a href="chisquare.html#gofTestInR"><i class="fa fa-check"></i><b>12.1.7</b> Doing the test in R</a></li>
<li class="chapter" data-level="12.1.8" data-path="chisquare.html"><a href="chisquare.html#specifying-a-different-null-hypothesis"><i class="fa fa-check"></i><b>12.1.8</b> Specifying a different null hypothesis</a></li>
<li class="chapter" data-level="12.1.9" data-path="chisquare.html"><a href="chisquare.html#chisqreport"><i class="fa fa-check"></i><b>12.1.9</b> How to report the results of the test</a></li>
<li class="chapter" data-level="12.1.10" data-path="chisquare.html"><a href="chisquare.html#a-comment-on-statistical-notation-advanced"><i class="fa fa-check"></i><b>12.1.10</b> A comment on statistical notation (advanced)</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="chisquare.html"><a href="chisquare.html#chisqindependence"><i class="fa fa-check"></i><b>12.2</b> The <span class="math inline">\(\chi^2\)</span> test of independence (or association)</a><ul>
<li class="chapter" data-level="12.2.1" data-path="chisquare.html"><a href="chisquare.html#constructing-our-hypothesis-test"><i class="fa fa-check"></i><b>12.2.1</b> Constructing our hypothesis test</a></li>
<li class="chapter" data-level="12.2.2" data-path="chisquare.html"><a href="chisquare.html#AssocTestInR"><i class="fa fa-check"></i><b>12.2.2</b> Doing the test in R</a></li>
<li class="chapter" data-level="12.2.3" data-path="chisquare.html"><a href="chisquare.html#postscript"><i class="fa fa-check"></i><b>12.2.3</b> Postscript</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="chisquare.html"><a href="chisquare.html#yates"><i class="fa fa-check"></i><b>12.3</b> The continuity correction</a></li>
<li class="chapter" data-level="12.4" data-path="chisquare.html"><a href="chisquare.html#chisqeffectsize"><i class="fa fa-check"></i><b>12.4</b> Effect size</a></li>
<li class="chapter" data-level="12.5" data-path="chisquare.html"><a href="chisquare.html#chisqassumptions"><i class="fa fa-check"></i><b>12.5</b> Assumptions of the test(s)</a></li>
<li class="chapter" data-level="12.6" data-path="chisquare.html"><a href="chisquare.html#chisq.test"><i class="fa fa-check"></i><b>12.6</b> The most typical way to do chi-square tests in R</a></li>
<li class="chapter" data-level="12.7" data-path="chisquare.html"><a href="chisquare.html#fisherexacttest"><i class="fa fa-check"></i><b>12.7</b> The Fisher exact test</a></li>
<li class="chapter" data-level="12.8" data-path="chisquare.html"><a href="chisquare.html#mcnemar"><i class="fa fa-check"></i><b>12.8</b> The McNemar test</a><ul>
<li class="chapter" data-level="12.8.1" data-path="chisquare.html"><a href="chisquare.html#doing-the-mcnemar-test-in-r"><i class="fa fa-check"></i><b>12.8.1</b> Doing the McNemar test in R</a></li>
</ul></li>
<li class="chapter" data-level="12.9" data-path="chisquare.html"><a href="chisquare.html#whats-the-difference-between-mcnemar-and-independence"><i class="fa fa-check"></i><b>12.9</b> What’s the difference between McNemar and independence?</a></li>
<li class="chapter" data-level="12.10" data-path="chisquare.html"><a href="chisquare.html#summary-10"><i class="fa fa-check"></i><b>12.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="ttest.html"><a href="ttest.html"><i class="fa fa-check"></i><b>13</b> Comparing two means</a><ul>
<li class="chapter" data-level="13.1" data-path="ttest.html"><a href="ttest.html#the-one-sample-z-test"><i class="fa fa-check"></i><b>13.1</b> The one-sample <span class="math inline">\(z\)</span>-test</a><ul>
<li class="chapter" data-level="13.1.1" data-path="ttest.html"><a href="ttest.html#the-inference-problem-that-the-test-addresses"><i class="fa fa-check"></i><b>13.1.1</b> The inference problem that the test addresses</a></li>
<li class="chapter" data-level="13.1.2" data-path="ttest.html"><a href="ttest.html#constructing-the-hypothesis-test"><i class="fa fa-check"></i><b>13.1.2</b> Constructing the hypothesis test</a></li>
<li class="chapter" data-level="13.1.3" data-path="ttest.html"><a href="ttest.html#a-worked-example-using-r"><i class="fa fa-check"></i><b>13.1.3</b> A worked example using R</a></li>
<li class="chapter" data-level="13.1.4" data-path="ttest.html"><a href="ttest.html#zassumptions"><i class="fa fa-check"></i><b>13.1.4</b> Assumptions of the <span class="math inline">\(z\)</span>-test</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="ttest.html"><a href="ttest.html#onesamplettest"><i class="fa fa-check"></i><b>13.2</b> The one-sample <span class="math inline">\(t\)</span>-test</a><ul>
<li class="chapter" data-level="13.2.1" data-path="ttest.html"><a href="ttest.html#introducing-the-t-test"><i class="fa fa-check"></i><b>13.2.1</b> Introducing the <span class="math inline">\(t\)</span>-test</a></li>
<li class="chapter" data-level="13.2.2" data-path="ttest.html"><a href="ttest.html#doing-the-test-in-r"><i class="fa fa-check"></i><b>13.2.2</b> Doing the test in R</a></li>
<li class="chapter" data-level="13.2.3" data-path="ttest.html"><a href="ttest.html#ttestoneassumptions"><i class="fa fa-check"></i><b>13.2.3</b> Assumptions of the one sample <span class="math inline">\(t\)</span>-test</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="ttest.html"><a href="ttest.html#studentttest"><i class="fa fa-check"></i><b>13.3</b> The independent samples <span class="math inline">\(t\)</span>-test (Student test)</a><ul>
<li class="chapter" data-level="13.3.1" data-path="ttest.html"><a href="ttest.html#the-data-1"><i class="fa fa-check"></i><b>13.3.1</b> The data</a></li>
<li class="chapter" data-level="13.3.2" data-path="ttest.html"><a href="ttest.html#introducing-the-test"><i class="fa fa-check"></i><b>13.3.2</b> Introducing the test</a></li>
<li class="chapter" data-level="13.3.3" data-path="ttest.html"><a href="ttest.html#a-pooled-estimate-of-the-standard-deviation"><i class="fa fa-check"></i><b>13.3.3</b> A “pooled estimate” of the standard deviation</a></li>
<li class="chapter" data-level="13.3.4" data-path="ttest.html"><a href="ttest.html#the-same-pooled-estimate-described-differently"><i class="fa fa-check"></i><b>13.3.4</b> The same pooled estimate, described differently</a></li>
<li class="chapter" data-level="13.3.5" data-path="ttest.html"><a href="ttest.html#completing-the-test"><i class="fa fa-check"></i><b>13.3.5</b> Completing the test</a></li>
<li class="chapter" data-level="13.3.6" data-path="ttest.html"><a href="ttest.html#doing-the-test-in-r-1"><i class="fa fa-check"></i><b>13.3.6</b> Doing the test in R</a></li>
<li class="chapter" data-level="13.3.7" data-path="ttest.html"><a href="ttest.html#positive-and-negative-t-values"><i class="fa fa-check"></i><b>13.3.7</b> Positive and negative <span class="math inline">\(t\)</span> values</a></li>
<li class="chapter" data-level="13.3.8" data-path="ttest.html"><a href="ttest.html#studentassumptions"><i class="fa fa-check"></i><b>13.3.8</b> Assumptions of the test</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="ttest.html"><a href="ttest.html#welchttest"><i class="fa fa-check"></i><b>13.4</b> The independent samples <span class="math inline">\(t\)</span>-test (Welch test)</a><ul>
<li class="chapter" data-level="13.4.1" data-path="ttest.html"><a href="ttest.html#doing-the-test-in-r-2"><i class="fa fa-check"></i><b>13.4.1</b> Doing the test in R</a></li>
<li class="chapter" data-level="13.4.2" data-path="ttest.html"><a href="ttest.html#assumptions-of-the-test"><i class="fa fa-check"></i><b>13.4.2</b> Assumptions of the test</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="ttest.html"><a href="ttest.html#pairedsamplesttest"><i class="fa fa-check"></i><b>13.5</b> The paired-samples <span class="math inline">\(t\)</span>-test</a><ul>
<li class="chapter" data-level="13.5.1" data-path="ttest.html"><a href="ttest.html#the-data-2"><i class="fa fa-check"></i><b>13.5.1</b> The data</a></li>
<li class="chapter" data-level="13.5.2" data-path="ttest.html"><a href="ttest.html#what-is-the-paired-samples-t-test"><i class="fa fa-check"></i><b>13.5.2</b> What is the paired samples <span class="math inline">\(t\)</span>-test?</a></li>
<li class="chapter" data-level="13.5.3" data-path="ttest.html"><a href="ttest.html#doing-the-test-in-r-part-1"><i class="fa fa-check"></i><b>13.5.3</b> Doing the test in R, part 1</a></li>
<li class="chapter" data-level="13.5.4" data-path="ttest.html"><a href="ttest.html#doing-the-test-in-r-part-2"><i class="fa fa-check"></i><b>13.5.4</b> Doing the test in R, part 2</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="ttest.html"><a href="ttest.html#one-sided-tests"><i class="fa fa-check"></i><b>13.6</b> One sided tests</a></li>
<li class="chapter" data-level="13.7" data-path="ttest.html"><a href="ttest.html#ttestfunction"><i class="fa fa-check"></i><b>13.7</b> Using the t.test() function</a></li>
<li class="chapter" data-level="13.8" data-path="ttest.html"><a href="ttest.html#cohensd"><i class="fa fa-check"></i><b>13.8</b> Effect size</a><ul>
<li class="chapter" data-level="13.8.1" data-path="ttest.html"><a href="ttest.html#cohens-d-from-one-sample"><i class="fa fa-check"></i><b>13.8.1</b> Cohen’s <span class="math inline">\(d\)</span> from one sample</a></li>
<li class="chapter" data-level="13.8.2" data-path="ttest.html"><a href="ttest.html#cohens-d-from-a-student-t-test"><i class="fa fa-check"></i><b>13.8.2</b> Cohen’s <span class="math inline">\(d\)</span> from a Student <span class="math inline">\(t\)</span> test</a></li>
<li class="chapter" data-level="13.8.3" data-path="ttest.html"><a href="ttest.html#cohens-d-from-a-welch-test"><i class="fa fa-check"></i><b>13.8.3</b> Cohen’s <span class="math inline">\(d\)</span> from a Welch test</a></li>
<li class="chapter" data-level="13.8.4" data-path="ttest.html"><a href="ttest.html#cohens-d-from-a-paired-samples-test"><i class="fa fa-check"></i><b>13.8.4</b> Cohen’s <span class="math inline">\(d\)</span> from a paired-samples test</a></li>
</ul></li>
<li class="chapter" data-level="13.9" data-path="ttest.html"><a href="ttest.html#shapiro"><i class="fa fa-check"></i><b>13.9</b> Checking the normality of a sample</a><ul>
<li class="chapter" data-level="13.9.1" data-path="ttest.html"><a href="ttest.html#qq-plots"><i class="fa fa-check"></i><b>13.9.1</b> QQ plots</a></li>
<li class="chapter" data-level="13.9.2" data-path="ttest.html"><a href="ttest.html#shapiro-wilk-tests"><i class="fa fa-check"></i><b>13.9.2</b> Shapiro-Wilk tests</a></li>
</ul></li>
<li class="chapter" data-level="13.10" data-path="ttest.html"><a href="ttest.html#wilcox"><i class="fa fa-check"></i><b>13.10</b> Testing non-normal data with Wilcoxon tests</a><ul>
<li class="chapter" data-level="13.10.1" data-path="ttest.html"><a href="ttest.html#two-sample-wilcoxon-test"><i class="fa fa-check"></i><b>13.10.1</b> Two sample Wilcoxon test</a></li>
<li class="chapter" data-level="13.10.2" data-path="ttest.html"><a href="ttest.html#one-sample-wilcoxon-test"><i class="fa fa-check"></i><b>13.10.2</b> One sample Wilcoxon test</a></li>
</ul></li>
<li class="chapter" data-level="13.11" data-path="ttest.html"><a href="ttest.html#summary-11"><i class="fa fa-check"></i><b>13.11</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="anova.html"><a href="anova.html"><i class="fa fa-check"></i><b>14</b> Comparing several means (one-way ANOVA)</a><ul>
<li class="chapter" data-level="14.1" data-path="anova.html"><a href="anova.html#anxifree"><i class="fa fa-check"></i><b>14.1</b> An illustrative data set</a></li>
<li class="chapter" data-level="14.2" data-path="anova.html"><a href="anova.html#anovaintro"><i class="fa fa-check"></i><b>14.2</b> How ANOVA works</a><ul>
<li class="chapter" data-level="14.2.1" data-path="anova.html"><a href="anova.html#two-formulas-for-the-variance-of-y"><i class="fa fa-check"></i><b>14.2.1</b> Two formulas for the variance of <span class="math inline">\(Y\)</span></a></li>
<li class="chapter" data-level="14.2.2" data-path="anova.html"><a href="anova.html#from-variances-to-sums-of-squares"><i class="fa fa-check"></i><b>14.2.2</b> From variances to sums of squares</a></li>
<li class="chapter" data-level="14.2.3" data-path="anova.html"><a href="anova.html#from-sums-of-squares-to-the-f-test"><i class="fa fa-check"></i><b>14.2.3</b> From sums of squares to the <span class="math inline">\(F\)</span>-test</a></li>
<li class="chapter" data-level="14.2.4" data-path="anova.html"><a href="anova.html#anovamodel"><i class="fa fa-check"></i><b>14.2.4</b> The model for the data and the meaning of <span class="math inline">\(F\)</span> (advanced)</a></li>
<li class="chapter" data-level="14.2.5" data-path="anova.html"><a href="anova.html#anovacalc"><i class="fa fa-check"></i><b>14.2.5</b> A worked example</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="anova.html"><a href="anova.html#introduceaov"><i class="fa fa-check"></i><b>14.3</b> Running an ANOVA in R</a><ul>
<li class="chapter" data-level="14.3.1" data-path="anova.html"><a href="anova.html#using-the-aov-function-to-specify-your-anova"><i class="fa fa-check"></i><b>14.3.1</b> Using the <code>aov()</code> function to specify your ANOVA</a></li>
<li class="chapter" data-level="14.3.2" data-path="anova.html"><a href="anova.html#aovobjects"><i class="fa fa-check"></i><b>14.3.2</b> Understanding what the <code>aov()</code> function produces</a></li>
<li class="chapter" data-level="14.3.3" data-path="anova.html"><a href="anova.html#running-the-hypothesis-tests-for-the-anova"><i class="fa fa-check"></i><b>14.3.3</b> Running the hypothesis tests for the ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="anova.html"><a href="anova.html#etasquared"><i class="fa fa-check"></i><b>14.4</b> Effect size</a></li>
<li class="chapter" data-level="14.5" data-path="anova.html"><a href="anova.html#posthoc"><i class="fa fa-check"></i><b>14.5</b> Multiple comparisons and post hoc tests</a><ul>
<li class="chapter" data-level="14.5.1" data-path="anova.html"><a href="anova.html#running-pairwise-t-tests"><i class="fa fa-check"></i><b>14.5.1</b> Running “pairwise” <span class="math inline">\(t\)</span>-tests</a></li>
<li class="chapter" data-level="14.5.2" data-path="anova.html"><a href="anova.html#corrections-for-multiple-testing"><i class="fa fa-check"></i><b>14.5.2</b> Corrections for multiple testing</a></li>
<li class="chapter" data-level="14.5.3" data-path="anova.html"><a href="anova.html#bonferroni-corrections"><i class="fa fa-check"></i><b>14.5.3</b> Bonferroni corrections</a></li>
<li class="chapter" data-level="14.5.4" data-path="anova.html"><a href="anova.html#holm-corrections"><i class="fa fa-check"></i><b>14.5.4</b> Holm corrections</a></li>
<li class="chapter" data-level="14.5.5" data-path="anova.html"><a href="anova.html#writing-up-the-post-hoc-test"><i class="fa fa-check"></i><b>14.5.5</b> Writing up the post hoc test</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="anova.html"><a href="anova.html#anovaassumptions"><i class="fa fa-check"></i><b>14.6</b> Assumptions of one-way ANOVA</a><ul>
<li class="chapter" data-level="14.6.1" data-path="anova.html"><a href="anova.html#how-robust-is-anova"><i class="fa fa-check"></i><b>14.6.1</b> How robust is ANOVA?</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="anova.html"><a href="anova.html#levene"><i class="fa fa-check"></i><b>14.7</b> Checking the homogeneity of variance assumption</a><ul>
<li class="chapter" data-level="14.7.1" data-path="anova.html"><a href="anova.html#running-the-levenes-test-in-r"><i class="fa fa-check"></i><b>14.7.1</b> Running the Levene’s test in R</a></li>
<li class="chapter" data-level="14.7.2" data-path="anova.html"><a href="anova.html#additional-comments"><i class="fa fa-check"></i><b>14.7.2</b> Additional comments</a></li>
</ul></li>
<li class="chapter" data-level="14.8" data-path="anova.html"><a href="anova.html#welchoneway"><i class="fa fa-check"></i><b>14.8</b> Removing the homogeneity of variance assumption</a></li>
<li class="chapter" data-level="14.9" data-path="anova.html"><a href="anova.html#anovanormality"><i class="fa fa-check"></i><b>14.9</b> Checking the normality assumption</a></li>
<li class="chapter" data-level="14.10" data-path="anova.html"><a href="anova.html#kruskalwallis"><i class="fa fa-check"></i><b>14.10</b> Removing the normality assumption</a><ul>
<li class="chapter" data-level="14.10.1" data-path="anova.html"><a href="anova.html#the-logic-behind-the-kruskal-wallis-test"><i class="fa fa-check"></i><b>14.10.1</b> The logic behind the Kruskal-Wallis test</a></li>
<li class="chapter" data-level="14.10.2" data-path="anova.html"><a href="anova.html#additional-details"><i class="fa fa-check"></i><b>14.10.2</b> Additional details</a></li>
<li class="chapter" data-level="14.10.3" data-path="anova.html"><a href="anova.html#how-to-run-the-kruskal-wallis-test-in-r"><i class="fa fa-check"></i><b>14.10.3</b> How to run the Kruskal-Wallis test in R</a></li>
</ul></li>
<li class="chapter" data-level="14.11" data-path="anova.html"><a href="anova.html#anovaandt"><i class="fa fa-check"></i><b>14.11</b> On the relationship between ANOVA and the Student <span class="math inline">\(t\)</span> test</a></li>
<li class="chapter" data-level="14.12" data-path="anova.html"><a href="anova.html#summary-12"><i class="fa fa-check"></i><b>14.12</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>15</b> Linear regression</a><ul>
<li class="chapter" data-level="15.1" data-path="regression.html"><a href="regression.html#introregression"><i class="fa fa-check"></i><b>15.1</b> What is a linear regression model?</a></li>
<li class="chapter" data-level="15.2" data-path="regression.html"><a href="regression.html#regressionestimation"><i class="fa fa-check"></i><b>15.2</b> Estimating a linear regression model</a><ul>
<li class="chapter" data-level="15.2.1" data-path="regression.html"><a href="regression.html#lm"><i class="fa fa-check"></i><b>15.2.1</b> Using the <code>lm()</code> function</a></li>
<li class="chapter" data-level="15.2.2" data-path="regression.html"><a href="regression.html#interpreting-the-estimated-model"><i class="fa fa-check"></i><b>15.2.2</b> Interpreting the estimated model</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="regression.html"><a href="regression.html#multipleregression"><i class="fa fa-check"></i><b>15.3</b> Multiple linear regression</a><ul>
<li class="chapter" data-level="15.3.1" data-path="regression.html"><a href="regression.html#doing-it-in-r"><i class="fa fa-check"></i><b>15.3.1</b> Doing it in R</a></li>
<li class="chapter" data-level="15.3.2" data-path="regression.html"><a href="regression.html#formula-for-the-general-case"><i class="fa fa-check"></i><b>15.3.2</b> Formula for the general case</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="regression.html"><a href="regression.html#r2"><i class="fa fa-check"></i><b>15.4</b> Quantifying the fit of the regression model</a><ul>
<li class="chapter" data-level="15.4.1" data-path="regression.html"><a href="regression.html#the-r2-value"><i class="fa fa-check"></i><b>15.4.1</b> The <span class="math inline">\(R^2\)</span> value</a></li>
<li class="chapter" data-level="15.4.2" data-path="regression.html"><a href="regression.html#the-relationship-between-regression-and-correlation"><i class="fa fa-check"></i><b>15.4.2</b> The relationship between regression and correlation</a></li>
<li class="chapter" data-level="15.4.3" data-path="regression.html"><a href="regression.html#the-adjusted-r2-value"><i class="fa fa-check"></i><b>15.4.3</b> The adjusted <span class="math inline">\(R^2\)</span> value</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="regression.html"><a href="regression.html#regressiontests"><i class="fa fa-check"></i><b>15.5</b> Hypothesis tests for regression models</a><ul>
<li class="chapter" data-level="15.5.1" data-path="regression.html"><a href="regression.html#testing-the-model-as-a-whole"><i class="fa fa-check"></i><b>15.5.1</b> Testing the model as a whole</a></li>
<li class="chapter" data-level="15.5.2" data-path="regression.html"><a href="regression.html#tests-for-individual-coefficients"><i class="fa fa-check"></i><b>15.5.2</b> Tests for individual coefficients</a></li>
<li class="chapter" data-level="15.5.3" data-path="regression.html"><a href="regression.html#regressionsummary"><i class="fa fa-check"></i><b>15.5.3</b> Running the hypothesis tests in R</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="regression.html"><a href="regression.html#corrhyp"><i class="fa fa-check"></i><b>15.6</b> Testing the significance of a correlation</a><ul>
<li class="chapter" data-level="15.6.1" data-path="regression.html"><a href="regression.html#hypothesis-tests-for-a-single-correlation"><i class="fa fa-check"></i><b>15.6.1</b> Hypothesis tests for a single correlation</a></li>
<li class="chapter" data-level="15.6.2" data-path="regression.html"><a href="regression.html#corrhyp2"><i class="fa fa-check"></i><b>15.6.2</b> Hypothesis tests for all pairwise correlations</a></li>
</ul></li>
<li class="chapter" data-level="15.7" data-path="regression.html"><a href="regression.html#regressioncoefs"><i class="fa fa-check"></i><b>15.7</b> Regarding regression coefficients</a><ul>
<li class="chapter" data-level="15.7.1" data-path="regression.html"><a href="regression.html#confidence-intervals-for-the-coefficients"><i class="fa fa-check"></i><b>15.7.1</b> Confidence intervals for the coefficients</a></li>
<li class="chapter" data-level="15.7.2" data-path="regression.html"><a href="regression.html#calculating-standardised-regression-coefficients"><i class="fa fa-check"></i><b>15.7.2</b> Calculating standardised regression coefficients</a></li>
</ul></li>
<li class="chapter" data-level="15.8" data-path="regression.html"><a href="regression.html#regressionassumptions"><i class="fa fa-check"></i><b>15.8</b> Assumptions of regression</a></li>
<li class="chapter" data-level="15.9" data-path="regression.html"><a href="regression.html#regressiondiagnostics"><i class="fa fa-check"></i><b>15.9</b> Model checking</a><ul>
<li class="chapter" data-level="15.9.1" data-path="regression.html"><a href="regression.html#three-kinds-of-residuals"><i class="fa fa-check"></i><b>15.9.1</b> Three kinds of residuals</a></li>
<li class="chapter" data-level="15.9.2" data-path="regression.html"><a href="regression.html#regressionoutliers"><i class="fa fa-check"></i><b>15.9.2</b> Three kinds of anomalous data</a></li>
<li class="chapter" data-level="15.9.3" data-path="regression.html"><a href="regression.html#regressionnormality"><i class="fa fa-check"></i><b>15.9.3</b> Checking the normality of the residuals</a></li>
<li class="chapter" data-level="15.9.4" data-path="regression.html"><a href="regression.html#regressionlinearity"><i class="fa fa-check"></i><b>15.9.4</b> Checking the linearity of the relationship</a></li>
<li class="chapter" data-level="15.9.5" data-path="regression.html"><a href="regression.html#regressionhomogeneity"><i class="fa fa-check"></i><b>15.9.5</b> Checking the homogeneity of variance</a></li>
<li class="chapter" data-level="15.9.6" data-path="regression.html"><a href="regression.html#regressioncollinearity"><i class="fa fa-check"></i><b>15.9.6</b> Checking for collinearity</a></li>
</ul></li>
<li class="chapter" data-level="15.10" data-path="regression.html"><a href="regression.html#modelselreg"><i class="fa fa-check"></i><b>15.10</b> Model selection</a><ul>
<li class="chapter" data-level="15.10.1" data-path="regression.html"><a href="regression.html#backward-elimination"><i class="fa fa-check"></i><b>15.10.1</b> Backward elimination</a></li>
<li class="chapter" data-level="15.10.2" data-path="regression.html"><a href="regression.html#forward-selection"><i class="fa fa-check"></i><b>15.10.2</b> Forward selection</a></li>
<li class="chapter" data-level="15.10.3" data-path="regression.html"><a href="regression.html#a-caveat"><i class="fa fa-check"></i><b>15.10.3</b> A caveat</a></li>
<li class="chapter" data-level="15.10.4" data-path="regression.html"><a href="regression.html#comparing-two-regression-models"><i class="fa fa-check"></i><b>15.10.4</b> Comparing two regression models</a></li>
</ul></li>
<li class="chapter" data-level="15.11" data-path="regression.html"><a href="regression.html#summary-13"><i class="fa fa-check"></i><b>15.11</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="anova2.html"><a href="anova2.html"><i class="fa fa-check"></i><b>16</b> Factorial ANOVA</a><ul>
<li class="chapter" data-level="16.1" data-path="anova2.html"><a href="anova2.html#factorialanovasimple"><i class="fa fa-check"></i><b>16.1</b> Factorial ANOVA 1: balanced designs, no interactions</a><ul>
<li class="chapter" data-level="16.1.1" data-path="anova2.html"><a href="anova2.html#factanovahyp"><i class="fa fa-check"></i><b>16.1.1</b> What hypotheses are we testing?</a></li>
<li class="chapter" data-level="16.1.2" data-path="anova2.html"><a href="anova2.html#running-the-analysis-in-r"><i class="fa fa-check"></i><b>16.1.2</b> Running the analysis in R</a></li>
<li class="chapter" data-level="16.1.3" data-path="anova2.html"><a href="anova2.html#how-are-the-sum-of-squares-calculated"><i class="fa fa-check"></i><b>16.1.3</b> How are the sum of squares calculated?</a></li>
<li class="chapter" data-level="16.1.4" data-path="anova2.html"><a href="anova2.html#what-are-our-degrees-of-freedom"><i class="fa fa-check"></i><b>16.1.4</b> What are our degrees of freedom?</a></li>
<li class="chapter" data-level="16.1.5" data-path="anova2.html"><a href="anova2.html#factorial-anova-versus-one-way-anovas"><i class="fa fa-check"></i><b>16.1.5</b> Factorial ANOVA versus one-way ANOVAs</a></li>
<li class="chapter" data-level="16.1.6" data-path="anova2.html"><a href="anova2.html#what-kinds-of-outcomes-does-this-analysis-capture"><i class="fa fa-check"></i><b>16.1.6</b> What kinds of outcomes does this analysis capture?</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="anova2.html"><a href="anova2.html#interactions"><i class="fa fa-check"></i><b>16.2</b> Factorial ANOVA 2: balanced designs, interactions allowed</a><ul>
<li class="chapter" data-level="16.2.1" data-path="anova2.html"><a href="anova2.html#what-exactly-is-an-interaction-effect"><i class="fa fa-check"></i><b>16.2.1</b> What exactly <em>is an interaction effect?</em></a></li>
<li class="chapter" data-level="16.2.2" data-path="anova2.html"><a href="anova2.html#calculating-sums-of-squares-for-the-interaction"><i class="fa fa-check"></i><b>16.2.2</b> Calculating sums of squares for the interaction</a></li>
<li class="chapter" data-level="16.2.3" data-path="anova2.html"><a href="anova2.html#degrees-of-freedom-for-the-interaction"><i class="fa fa-check"></i><b>16.2.3</b> Degrees of freedom for the interaction</a></li>
<li class="chapter" data-level="16.2.4" data-path="anova2.html"><a href="anova2.html#running-the-anova-in-r"><i class="fa fa-check"></i><b>16.2.4</b> Running the ANOVA in R</a></li>
<li class="chapter" data-level="16.2.5" data-path="anova2.html"><a href="anova2.html#interpreting-the-results"><i class="fa fa-check"></i><b>16.2.5</b> Interpreting the results</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="anova2.html"><a href="anova2.html#effectsizefactorialanova"><i class="fa fa-check"></i><b>16.3</b> Effect size, estimated means, and confidence intervals</a><ul>
<li class="chapter" data-level="16.3.1" data-path="anova2.html"><a href="anova2.html#effect-sizes"><i class="fa fa-check"></i><b>16.3.1</b> Effect sizes</a></li>
<li class="chapter" data-level="16.3.2" data-path="anova2.html"><a href="anova2.html#estimated-group-means"><i class="fa fa-check"></i><b>16.3.2</b> Estimated group means</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="anova2.html"><a href="anova2.html#factorialanovaassumptions"><i class="fa fa-check"></i><b>16.4</b> Assumption checking</a><ul>
<li class="chapter" data-level="16.4.1" data-path="anova2.html"><a href="anova2.html#levene-test-for-homogeneity-of-variance"><i class="fa fa-check"></i><b>16.4.1</b> Levene test for homogeneity of variance</a></li>
<li class="chapter" data-level="16.4.2" data-path="anova2.html"><a href="anova2.html#normality-of-residuals"><i class="fa fa-check"></i><b>16.4.2</b> Normality of residuals</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="anova2.html"><a href="anova2.html#omnibusF"><i class="fa fa-check"></i><b>16.5</b> The <span class="math inline">\(F\)</span> test as a model comparison</a><ul>
<li class="chapter" data-level="16.5.1" data-path="anova2.html"><a href="anova2.html#the-f-test-comparing-two-models"><i class="fa fa-check"></i><b>16.5.1</b> The <span class="math inline">\(F\)</span> test comparing two models</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="anova2.html"><a href="anova2.html#anovalm"><i class="fa fa-check"></i><b>16.6</b> ANOVA as a linear model</a><ul>
<li class="chapter" data-level="16.6.1" data-path="anova2.html"><a href="anova2.html#some-data"><i class="fa fa-check"></i><b>16.6.1</b> Some data</a></li>
<li class="chapter" data-level="16.6.2" data-path="anova2.html"><a href="anova2.html#anova-with-binary-factors-as-a-regression-model"><i class="fa fa-check"></i><b>16.6.2</b> ANOVA with binary factors as a regression model</a></li>
<li class="chapter" data-level="16.6.3" data-path="anova2.html"><a href="anova2.html#changingbaseline"><i class="fa fa-check"></i><b>16.6.3</b> Changing the baseline category</a></li>
<li class="chapter" data-level="16.6.4" data-path="anova2.html"><a href="anova2.html#how-to-encode-non-binary-factors-as-contrasts"><i class="fa fa-check"></i><b>16.6.4</b> How to encode non binary factors as contrasts</a></li>
<li class="chapter" data-level="16.6.5" data-path="anova2.html"><a href="anova2.html#the-equivalence-between-anova-and-regression-for-non-binary-factors"><i class="fa fa-check"></i><b>16.6.5</b> The equivalence between ANOVA and regression for non-binary factors</a></li>
<li class="chapter" data-level="16.6.6" data-path="anova2.html"><a href="anova2.html#degrees-of-freedom-as-parameter-counting"><i class="fa fa-check"></i><b>16.6.6</b> Degrees of freedom as parameter counting!</a></li>
<li class="chapter" data-level="16.6.7" data-path="anova2.html"><a href="anova2.html#a-postscript"><i class="fa fa-check"></i><b>16.6.7</b> A postscript</a></li>
</ul></li>
<li class="chapter" data-level="16.7" data-path="anova2.html"><a href="anova2.html#contrasts"><i class="fa fa-check"></i><b>16.7</b> Different ways to specify contrasts</a><ul>
<li class="chapter" data-level="16.7.1" data-path="anova2.html"><a href="anova2.html#treatment-contrasts"><i class="fa fa-check"></i><b>16.7.1</b> Treatment contrasts</a></li>
<li class="chapter" data-level="16.7.2" data-path="anova2.html"><a href="anova2.html#helmert-contrasts"><i class="fa fa-check"></i><b>16.7.2</b> Helmert contrasts</a></li>
<li class="chapter" data-level="16.7.3" data-path="anova2.html"><a href="anova2.html#sum-to-zero-contrasts"><i class="fa fa-check"></i><b>16.7.3</b> Sum to zero contrasts</a></li>
<li class="chapter" data-level="16.7.4" data-path="anova2.html"><a href="anova2.html#viewing-and-setting-the-default-contrasts-in-r"><i class="fa fa-check"></i><b>16.7.4</b> Viewing and setting the default contrasts in R</a></li>
<li class="chapter" data-level="16.7.5" data-path="anova2.html"><a href="anova2.html#setting-the-contrasts-for-a-single-factor"><i class="fa fa-check"></i><b>16.7.5</b> Setting the contrasts for a single factor</a></li>
<li class="chapter" data-level="16.7.6" data-path="anova2.html"><a href="anova2.html#setting-the-contrasts-for-a-single-analysis"><i class="fa fa-check"></i><b>16.7.6</b> Setting the contrasts for a single analysis</a></li>
</ul></li>
<li class="chapter" data-level="16.8" data-path="anova2.html"><a href="anova2.html#posthoc2"><i class="fa fa-check"></i><b>16.8</b> Post hoc tests</a></li>
<li class="chapter" data-level="16.9" data-path="anova2.html"><a href="anova2.html#plannedcomparisons"><i class="fa fa-check"></i><b>16.9</b> The method of planned comparisons</a></li>
<li class="chapter" data-level="16.10" data-path="anova2.html"><a href="anova2.html#unbalancedanova"><i class="fa fa-check"></i><b>16.10</b> Factorial ANOVA 3: unbalanced designs</a><ul>
<li class="chapter" data-level="16.10.1" data-path="anova2.html"><a href="anova2.html#the-coffee-data"><i class="fa fa-check"></i><b>16.10.1</b> The coffee data</a></li>
<li class="chapter" data-level="16.10.2" data-path="anova2.html"><a href="anova2.html#standard-anova-does-not-exist-for-unbalanced-designs"><i class="fa fa-check"></i><b>16.10.2</b> “Standard ANOVA” does not exist for unbalanced designs</a></li>
<li class="chapter" data-level="16.10.3" data-path="anova2.html"><a href="anova2.html#type-i-sum-of-squares"><i class="fa fa-check"></i><b>16.10.3</b> Type I sum of squares</a></li>
<li class="chapter" data-level="16.10.4" data-path="anova2.html"><a href="anova2.html#type-iii-sum-of-squares"><i class="fa fa-check"></i><b>16.10.4</b> Type III sum of squares</a></li>
<li class="chapter" data-level="16.10.5" data-path="anova2.html"><a href="anova2.html#type-ii-sum-of-squares"><i class="fa fa-check"></i><b>16.10.5</b> Type II sum of squares</a></li>
<li class="chapter" data-level="16.10.6" data-path="anova2.html"><a href="anova2.html#effect-sizes-and-non-additive-sums-of-squares"><i class="fa fa-check"></i><b>16.10.6</b> Effect sizes (and non-additive sums of squares)</a></li>
</ul></li>
<li class="chapter" data-level="16.11" data-path="anova2.html"><a href="anova2.html#summary-14"><i class="fa fa-check"></i><b>16.11</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="part-vi-endings-alternatives-and-prospects.html"><a href="part-vi-endings-alternatives-and-prospects.html"><i class="fa fa-check"></i>Part VI. Endings, alternatives and prospects</a></li>
<li class="chapter" data-level="17" data-path="bayes.html"><a href="bayes.html"><i class="fa fa-check"></i><b>17</b> Bayesian statistics</a><ul>
<li class="chapter" data-level="17.1" data-path="bayes.html"><a href="bayes.html#basicbayes"><i class="fa fa-check"></i><b>17.1</b> Probabilistic reasoning by rational agents</a><ul>
<li class="chapter" data-level="17.1.1" data-path="bayes.html"><a href="bayes.html#priors-what-you-believed-before"><i class="fa fa-check"></i><b>17.1.1</b> Priors: what you believed before</a></li>
<li class="chapter" data-level="17.1.2" data-path="bayes.html"><a href="bayes.html#likelihoods-theories-about-the-data"><i class="fa fa-check"></i><b>17.1.2</b> Likelihoods: theories about the data</a></li>
<li class="chapter" data-level="17.1.3" data-path="bayes.html"><a href="bayes.html#the-joint-probability-of-data-and-hypothesis"><i class="fa fa-check"></i><b>17.1.3</b> The joint probability of data and hypothesis</a></li>
<li class="chapter" data-level="17.1.4" data-path="bayes.html"><a href="bayes.html#updating-beliefs-using-bayes-rule"><i class="fa fa-check"></i><b>17.1.4</b> Updating beliefs using Bayes’ rule</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="bayes.html"><a href="bayes.html#bayesianhypothesistests"><i class="fa fa-check"></i><b>17.2</b> Bayesian hypothesis tests</a><ul>
<li class="chapter" data-level="17.2.1" data-path="bayes.html"><a href="bayes.html#the-bayes-factor"><i class="fa fa-check"></i><b>17.2.1</b> The Bayes factor</a></li>
<li class="chapter" data-level="17.2.2" data-path="bayes.html"><a href="bayes.html#interpreting-bayes-factors"><i class="fa fa-check"></i><b>17.2.2</b> Interpreting Bayes factors</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="bayes.html"><a href="bayes.html#whybayes"><i class="fa fa-check"></i><b>17.3</b> Why be a Bayesian?</a><ul>
<li class="chapter" data-level="17.3.1" data-path="bayes.html"><a href="bayes.html#statistics-that-mean-what-you-think-they-mean"><i class="fa fa-check"></i><b>17.3.1</b> Statistics that mean what you think they mean</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="bayes.html"><a href="bayes.html#evidentiary-standards-you-can-believe"><i class="fa fa-check"></i><b>17.4</b> Evidentiary standards you can believe</a></li>
<li class="chapter" data-level="17.5" data-path="bayes.html"><a href="bayes.html#the-p-value-is-a-lie."><i class="fa fa-check"></i><b>17.5</b> The <span class="math inline">\(p\)</span>-value is a lie.</a><ul>
<li class="chapter" data-level="17.5.1" data-path="bayes.html"><a href="bayes.html#is-it-really-this-bad"><i class="fa fa-check"></i><b>17.5.1</b> Is it really this bad?</a></li>
</ul></li>
<li class="chapter" data-level="17.6" data-path="bayes.html"><a href="bayes.html#bayescontingency"><i class="fa fa-check"></i><b>17.6</b> Bayesian analysis of contingency tables</a><ul>
<li class="chapter" data-level="17.6.1" data-path="bayes.html"><a href="bayes.html#the-orthodox-text"><i class="fa fa-check"></i><b>17.6.1</b> The orthodox text</a></li>
<li class="chapter" data-level="17.6.2" data-path="bayes.html"><a href="bayes.html#the-bayesian-test"><i class="fa fa-check"></i><b>17.6.2</b> The Bayesian test</a></li>
<li class="chapter" data-level="17.6.3" data-path="bayes.html"><a href="bayes.html#writing-up-the-results"><i class="fa fa-check"></i><b>17.6.3</b> Writing up the results</a></li>
<li class="chapter" data-level="17.6.4" data-path="bayes.html"><a href="bayes.html#other-sampling-plans"><i class="fa fa-check"></i><b>17.6.4</b> Other sampling plans</a></li>
</ul></li>
<li class="chapter" data-level="17.7" data-path="bayes.html"><a href="bayes.html#ttestbf"><i class="fa fa-check"></i><b>17.7</b> Bayesian <span class="math inline">\(t\)</span>-tests</a><ul>
<li class="chapter" data-level="17.7.1" data-path="bayes.html"><a href="bayes.html#independent-samples-t-test"><i class="fa fa-check"></i><b>17.7.1</b> Independent samples <span class="math inline">\(t\)</span>-test</a></li>
<li class="chapter" data-level="17.7.2" data-path="bayes.html"><a href="bayes.html#paired-samples-t-test"><i class="fa fa-check"></i><b>17.7.2</b> Paired samples <span class="math inline">\(t\)</span>-test</a></li>
</ul></li>
<li class="chapter" data-level="17.8" data-path="bayes.html"><a href="bayes.html#bayesregression"><i class="fa fa-check"></i><b>17.8</b> Bayesian regression</a><ul>
<li class="chapter" data-level="17.8.1" data-path="bayes.html"><a href="bayes.html#a-quick-refresher"><i class="fa fa-check"></i><b>17.8.1</b> A quick refresher</a></li>
<li class="chapter" data-level="17.8.2" data-path="bayes.html"><a href="bayes.html#the-bayesian-version"><i class="fa fa-check"></i><b>17.8.2</b> The Bayesian version</a></li>
<li class="chapter" data-level="17.8.3" data-path="bayes.html"><a href="bayes.html#finding-the-best-model"><i class="fa fa-check"></i><b>17.8.3</b> Finding the best model</a></li>
<li class="chapter" data-level="17.8.4" data-path="bayes.html"><a href="bayes.html#extracting-bayes-factors-for-all-included-terms"><i class="fa fa-check"></i><b>17.8.4</b> Extracting Bayes factors for all included terms</a></li>
</ul></li>
<li class="chapter" data-level="17.9" data-path="bayes.html"><a href="bayes.html#bayesanova"><i class="fa fa-check"></i><b>17.9</b> Bayesian ANOVA</a><ul>
<li class="chapter" data-level="17.9.1" data-path="bayes.html"><a href="bayes.html#a-quick-refresher-1"><i class="fa fa-check"></i><b>17.9.1</b> A quick refresher</a></li>
<li class="chapter" data-level="17.9.2" data-path="bayes.html"><a href="bayes.html#the-bayesian-version-1"><i class="fa fa-check"></i><b>17.9.2</b> The Bayesian version</a></li>
<li class="chapter" data-level="17.9.3" data-path="bayes.html"><a href="bayes.html#constructing-bayesian-type-ii-tests"><i class="fa fa-check"></i><b>17.9.3</b> Constructing Bayesian Type II tests</a></li>
</ul></li>
<li class="chapter" data-level="17.10" data-path="bayes.html"><a href="bayes.html#summary-15"><i class="fa fa-check"></i><b>17.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="epilogue.html"><a href="epilogue.html"><i class="fa fa-check"></i>Epilogue</a><ul>
<li class="chapter" data-level="" data-path="epilogue.html"><a href="epilogue.html#the-undiscovered-statistics"><i class="fa fa-check"></i>The undiscovered statistics</a><ul>
<li class="chapter" data-level="" data-path="epilogue.html"><a href="epilogue.html#omissions-within-the-topics-covered"><i class="fa fa-check"></i>Omissions within the topics covered</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="epilogue.html"><a href="epilogue.html#statistical-models-missing-from-the-book"><i class="fa fa-check"></i>Statistical models missing from the book</a></li>
<li class="chapter" data-level="" data-path="epilogue.html"><a href="epilogue.html#other-ways-of-doing-inference"><i class="fa fa-check"></i>Other ways of doing inference</a><ul>
<li class="chapter" data-level="" data-path="epilogue.html"><a href="epilogue.html#miscellaneous-topics"><i class="fa fa-check"></i>Miscellaneous topics</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="epilogue.html"><a href="epilogue.html#learning-the-basics-and-learning-them-in-r"><i class="fa fa-check"></i>Learning the basics, and learning them in R</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://learningstatisticswithr.com/book/" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Learning statistics with R: A tutorial for psychology students and other beginners. (Version 0.6.1)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="anova2" class="section level1">
<h1><span class="header-section-number">Chapter 16</span> Factorial ANOVA</h1>
<p>Over the course of the last few chapters you can probably detect a general trend. We started out looking at tools that you can use to compare two groups to one another, most notably the <span class="math inline">\(t\)</span>-test (Chapter <a href="ttest.html#ttest">13</a>). Then, we introduced analysis of variance (ANOVA) as a method for comparing more than two groups (Chapter <a href="anova.html#anova">14</a>). The chapter on regression (Chapter <a href="regression.html#regression">15</a>) covered a somewhat different topic, but in doing so it introduced a powerful new idea: building statistical models that have <em>multiple</em> predictor variables used to explain a single outcome variable. For instance, a regression model could be used to predict the number of errors a student makes in a reading comprehension test based on the number of hours they studied for the test, and their score on a standardised IQ test. The goal in this chapter is to import this idea into the ANOVA framework. For instance, suppose we were interested in using the reading comprehension test to measure student achievements in three different schools, and we suspect that girls and boys are developing at different rates (and so would be expected to have different performance on average). Each student is classified in two different ways: on the basis of their gender, and on the basis of their school. What we’d like to do is analyse the reading comprehension scores in terms of <em>both</em> of these grouping variables. The tool for doing so is generically referred to as <strong><em>factorial ANOVA</em></strong>. However, since we have two grouping variables, we sometimes refer to the analysis as a two-way ANOVA, in contrast to the one-way ANOVAs that we ran in Chapter <a href="anova.html#anova">14</a>.</p>
<div id="factorialanovasimple" class="section level2">
<h2><span class="header-section-number">16.1</span> Factorial ANOVA 1: balanced designs, no interactions</h2>
<p>When we discussed analysis of variance in Chapter <a href="anova.html#anova">14</a>, we assumed a fairly simple experimental design: each person falls into one of several groups, and we want to know whether these groups have different means on some outcome variable. In this section, I’ll discuss a broader class of experimental designs, known as <strong><em>factorial designs</em></strong>, in we have more than one grouping variable. I gave one example of how this kind of design might arise above. Another example appears in Chapter <a href="anova.html#anova">14</a>, in which we were looking at the effect of different drugs on the <code>mood.gain</code> experienced by each person. In that chapter we did find a significant effect of drug, but at the end of the chapter we also ran an analysis to see if there was an effect of therapy. We didn’t find one, but there’s something a bit worrying about trying to run two <em>separate</em> analyses trying to predict the same outcome. Maybe there actually <em>is</em> an effect of therapy on mood gain, but we couldn’t find it because it was being “hidden” by the effect of drug? In other words, we’re going to want to run a <em>single</em> analysis that includes <em>both</em> <code>drug</code> and <code>therapy</code> as predictors. For this analysis each person is cross-classified by the drug they were given (a factor with 3 levels) and what therapy they received (a factor with 2 levels). We refer to this as a <span class="math inline">\(3 \times 2\)</span> factorial design. If we cross-tabulate <code>drug</code> by <code>therapy</code>, using the <code>xtabs()</code> function (see Section <a href="datahandling.html#freqtables">7.1</a>), we get the following table:<a href="#fn231" class="footnoteRef" id="fnref231"><sup>231</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">load</span>(<span class="kw">file.path</span>(projecthome, <span class="st">&quot;data&quot;</span>,<span class="st">&quot;clinicaltrial.Rdata&quot;</span>))
<span class="kw">xtabs</span>( <span class="op">~</span><span class="st"> </span>drug <span class="op">+</span><span class="st"> </span>therapy, clin.trial )</code></pre></div>
<pre><code>##           therapy
## drug       no.therapy CBT
##   placebo           3   3
##   anxifree          3   3
##   joyzepam          3   3</code></pre>
<p>As you can see, not only do we have participants corresponding to all possible combinations of the two factors, indicating that our design is <strong><em>completely crossed</em></strong>, it turns out that there are an equal number of people in each group. In other words, we have a <strong><em>balanced</em></strong> design. In this section I’ll talk about how to analyse data from balanced designs, since this is the simplest case. The story for unbalanced designs is quite tedious, so we’ll put it to one side for the moment.</p>
<div id="factanovahyp" class="section level3">
<h3><span class="header-section-number">16.1.1</span> What hypotheses are we testing?</h3>
<p>Like one-way ANOVA, factorial ANOVA is a tool for testing certain types of hypotheses about population means. So a sensible place to start would be to be explicit about what our hypotheses actually are. However, before we can even get to that point, it’s really useful to have some clean and simple notation to describe the population means. Because of the fact that observations are cross-classified in terms of two different factors, there are quite a lot of different means that one might be interested. To see this, let’s start by thinking about all the different sample means that we can calculate for this kind of design. Firstly, there’s the obvious idea that we might be interested in this table of group means:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">aggregate</span>( mood.gain <span class="op">~</span><span class="st"> </span>drug <span class="op">+</span><span class="st"> </span>therapy, clin.trial, mean )</code></pre></div>
<pre><code>##       drug    therapy mood.gain
## 1  placebo no.therapy  0.300000
## 2 anxifree no.therapy  0.400000
## 3 joyzepam no.therapy  1.466667
## 4  placebo        CBT  0.600000
## 5 anxifree        CBT  1.033333
## 6 joyzepam        CBT  1.500000</code></pre>
<p>Now, this output shows a cross-tabulation of the group means for all possible combinations of the two factors (e.g., people who received the placebo and no therapy, people who received the placebo while getting CBT, etc). However, we can also construct tables that ignore one of the two factors. That gives us output that looks like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">aggregate</span>( mood.gain <span class="op">~</span><span class="st"> </span>drug, clin.trial, mean )</code></pre></div>
<pre><code>##       drug mood.gain
## 1  placebo 0.4500000
## 2 anxifree 0.7166667
## 3 joyzepam 1.4833333</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">aggregate</span>( mood.gain <span class="op">~</span><span class="st"> </span>therapy, clin.trial, mean )</code></pre></div>
<pre><code>##      therapy mood.gain
## 1 no.therapy 0.7222222
## 2        CBT 1.0444444</code></pre>
<p>But of course, if we can ignore one factor we can certainly ignore both. That is, we might also be interested in calculating the average mood gain across all 18 participants, regardless of what drug or psychological therapy they were given:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>( clin.trial<span class="op">$</span>mood.gain )</code></pre></div>
<pre><code>## [1] 0.8833333</code></pre>
<p>At this point we have 12 different sample means to keep track of! It is helpful to organise all these numbers into a single table, which would look like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
         <span class="op">~</span>V1,          <span class="op">~</span>V2,    <span class="op">~</span>V3,     <span class="op">~</span>V4,
          <span class="ot">NA</span>, <span class="st">&quot;no therapy&quot;</span>,  <span class="st">&quot;CBT&quot;</span>, <span class="st">&quot;total&quot;</span>,
   <span class="st">&quot;placebo&quot;</span>,       <span class="st">&quot;0.30&quot;</span>, <span class="st">&quot;0.60&quot;</span>,  <span class="st">&quot;0.45&quot;</span>,
  <span class="st">&quot;anxifree&quot;</span>,       <span class="st">&quot;0.40&quot;</span>, <span class="st">&quot;1.03&quot;</span>,  <span class="st">&quot;0.72&quot;</span>,
  <span class="st">&quot;joyzepam&quot;</span>,       <span class="st">&quot;1.47&quot;</span>, <span class="st">&quot;1.50&quot;</span>,  <span class="st">&quot;1.48&quot;</span>,
     <span class="st">&quot;total&quot;</span>,       <span class="st">&quot;0.72&quot;</span>, <span class="st">&quot;1.04&quot;</span>,  <span class="st">&quot;0.88&quot;</span>
  ), <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;&quot;</span>, <span class="st">&quot;no therapy&quot;</span>,  <span class="st">&quot;CBT&quot;</span>, <span class="st">&quot;total&quot;</span>))</code></pre></div>
<table>
<thead>
<tr class="header">
<th></th>
<th align="left">no therapy</th>
<th align="left">CBT</th>
<th align="left">total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>NA</td>
<td align="left">no therapy</td>
<td align="left">CBT</td>
<td align="left">total</td>
</tr>
<tr class="even">
<td>placebo</td>
<td align="left">0.30</td>
<td align="left">0.60</td>
<td align="left">0.45</td>
</tr>
<tr class="odd">
<td>anxifree</td>
<td align="left">0.40</td>
<td align="left">1.03</td>
<td align="left">0.72</td>
</tr>
<tr class="even">
<td>joyzepam</td>
<td align="left">1.47</td>
<td align="left">1.50</td>
<td align="left">1.48</td>
</tr>
<tr class="odd">
<td>total</td>
<td align="left">0.72</td>
<td align="left">1.04</td>
<td align="left">0.88</td>
</tr>
</tbody>
</table>
<p>Now, each of these different means is of course a sample statistic: it’s a quantity that pertains to the specific observations that we’ve made during our study. What we want to make inferences about are the corresponding population parameters: that is, the true means as they exist within some broader population. Those population means can also be organised into a similar table, but we’ll need a little mathematical notation to do so. As usual, I’ll use the symbol <span class="math inline">\(\mu\)</span> to denote a population mean. However, because there are lots of different means, I’ll need to use subscripts to distinguish between them.</p>
<p>Here’s how the notation works. Our table is defined in terms of two factors: each row corresponds to a different level of Factor A (in this case <code>drug</code>), and each column corresponds to a different level of Factor B (in this case <code>therapy</code>). If we let <span class="math inline">\(R\)</span> denote the number of rows in the table, and <span class="math inline">\(C\)</span> denote the number of columns, we can refer to this as an <span class="math inline">\(R \times C\)</span> factorial ANOVA. In this case <span class="math inline">\(R=3\)</span> and <span class="math inline">\(C=2\)</span>. We’ll use lowercase letters to refer to specific rows and columns, so <span class="math inline">\(\mu_{rc}\)</span> refers to the population mean associated with the <span class="math inline">\(r\)</span>th level of Factor A (i.e. row number <span class="math inline">\(r\)</span>) and the <span class="math inline">\(c\)</span>th level of Factor B (column number <span class="math inline">\(c\)</span>).<a href="#fn232" class="footnoteRef" id="fnref232"><sup>232</sup></a> So the population means are now written like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
         <span class="op">~</span>V1,           <span class="op">~</span>V2,           <span class="op">~</span>V3,     <span class="op">~</span>V4,

   <span class="st">&quot;placebo&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">mu_{11}$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">mu_{12}$&quot;</span>,      <span class="st">&quot;&quot;</span>,
  <span class="st">&quot;anxifree&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">mu_{21}$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">mu_{22}$&quot;</span>,      <span class="st">&quot;&quot;</span>,
  <span class="st">&quot;joyzepam&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">mu_{31}$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">mu_{32}$&quot;</span>,      <span class="st">&quot;&quot;</span>,
     <span class="st">&quot;total&quot;</span>,            <span class="st">&quot;&quot;</span>,            <span class="st">&quot;&quot;</span>,      <span class="st">&quot;&quot;</span>
  ), <span class="dt">col.names =</span> <span class="kw">c</span>(          <span class="st">&quot;&quot;</span>,  <span class="st">&quot;no therapy&quot;</span>,         <span class="st">&quot;CBT&quot;</span>, <span class="st">&quot;total&quot;</span>))</code></pre></div>
<table>
<thead>
<tr class="header">
<th></th>
<th align="left">no therapy</th>
<th align="left">CBT</th>
<th align="left">total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>placebo</td>
<td align="left"><span class="math inline">\(\mu_{11}\)</span></td>
<td align="left"><span class="math inline">\(\mu_{12}\)</span></td>
<td align="left"></td>
</tr>
<tr class="even">
<td>anxifree</td>
<td align="left"><span class="math inline">\(\mu_{21}\)</span></td>
<td align="left"><span class="math inline">\(\mu_{22}\)</span></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td>joyzepam</td>
<td align="left"><span class="math inline">\(\mu_{31}\)</span></td>
<td align="left"><span class="math inline">\(\mu_{32}\)</span></td>
<td align="left"></td>
</tr>
<tr class="even">
<td>total</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody>
</table>
<p>Okay, what about the remaining entries? For instance, how should we describe the average mood gain across the entire (hypothetical) population of people who might be given Joyzepam in an experiment like this, regardless of whether they were in CBT? We use the “dot” notation to express this. In the case of Joyzepam, notice that we’re talking about the mean associated with the third row in the table. That is, we’re averaging across two cell means (i.e., <span class="math inline">\(\mu_{31}\)</span> and <span class="math inline">\(\mu_{32}\)</span>). The result of this averaging is referred to as a <strong><em>marginal mean</em></strong>, and would be denoted <span class="math inline">\(\mu_{3.}\)</span> in this case. The marginal mean for CBT corresponds to the population mean associated with the second column in the table, so we use the notation <span class="math inline">\(\mu_{.2}\)</span> to describe it. The grand mean is denoted <span class="math inline">\(\mu_{..}\)</span> because it is the mean obtained by averaging (marginalising<a href="#fn233" class="footnoteRef" id="fnref233"><sup>233</sup></a>) over both. So our full table of population means can be written down like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
         <span class="op">~</span>V1,           <span class="op">~</span>V2,           <span class="op">~</span>V3,           <span class="op">~</span>V4,

   <span class="st">&quot;placebo&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">mu_{11}$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">mu_{12}$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">mu_{1.}$&quot;</span>,
  <span class="st">&quot;anxifree&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">mu_{21}$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">mu_{22}$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">mu_{2.}$&quot;</span>,
  <span class="st">&quot;joyzepam&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">mu_{31}$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">mu_{32}$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">mu_{3.}$&quot;</span>,
     <span class="st">&quot;total&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">mu_{.1}$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">mu_{.2}$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">mu_{..}$&quot;</span>
  ), <span class="dt">col.names=</span><span class="kw">c</span>(          <span class="ot">NA</span>,  <span class="st">&quot;no therapy&quot;</span>,         <span class="st">&quot;CBT&quot;</span>,       <span class="st">&quot;total&quot;</span>))</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">NA</th>
<th align="left">no therapy</th>
<th align="left">CBT</th>
<th align="left">total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">placebo</td>
<td align="left"><span class="math inline">\(\mu_{11}\)</span></td>
<td align="left"><span class="math inline">\(\mu_{12}\)</span></td>
<td align="left"><span class="math inline">\(\mu_{1.}\)</span></td>
</tr>
<tr class="even">
<td align="left">anxifree</td>
<td align="left"><span class="math inline">\(\mu_{21}\)</span></td>
<td align="left"><span class="math inline">\(\mu_{22}\)</span></td>
<td align="left"><span class="math inline">\(\mu_{2.}\)</span></td>
</tr>
<tr class="odd">
<td align="left">joyzepam</td>
<td align="left"><span class="math inline">\(\mu_{31}\)</span></td>
<td align="left"><span class="math inline">\(\mu_{32}\)</span></td>
<td align="left"><span class="math inline">\(\mu_{3.}\)</span></td>
</tr>
<tr class="even">
<td align="left">total</td>
<td align="left"><span class="math inline">\(\mu_{.1}\)</span></td>
<td align="left"><span class="math inline">\(\mu_{.2}\)</span></td>
<td align="left"><span class="math inline">\(\mu_{..}\)</span></td>
</tr>
</tbody>
</table>
<p>Now that we have this notation, it is straightforward to formulate and express some hypotheses. Let’s suppose that the goal is to find out two things: firstly, does the choice of drug have any effect on mood, and secondly, does CBT have any effect on mood? These aren’t the only hypotheses that we could formulate of course, and we’ll see a really important example of a different kind of hypothesis in Section <a href="anova2.html#interactions">16.2</a>, but these are the two simplest hypotheses to test, and so we’ll start there. Consider the first test. If drug has no effect, then we would expect all of the row means to be identical, right? So that’s our null hypothesis. On the other hand, if the drug does matter then we should expect these row means to be different. Formally, we write down our null and alternative hypotheses in terms of the <em>equality of marginal means</em>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
                              <span class="op">~</span>V1,                                                               <span class="op">~</span>V2,
         <span class="st">&quot;Null hypothesis $H_0$:&quot;</span>, <span class="st">&quot;row means are the same i.e. $</span><span class="ch">\\</span><span class="st">mu_{1.} = </span><span class="ch">\\</span><span class="st">mu_{2.} = </span><span class="ch">\\</span><span class="st">mu_{3.}$&quot;</span>,
  <span class="st">&quot;Alternative hypothesis $H_1$:&quot;</span>,                             <span class="st">&quot;at least one row mean is different.&quot;</span>
  ), <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>))</code></pre></div>
<table>
<tbody>
<tr class="odd">
<td align="left">Null hypothesis <span class="math inline">\(H_0\)</span>:</td>
<td align="left">row means are the same i.e. <span class="math inline">\(\mu_{1.} = \mu_{2.} = \mu_{3.}\)</span></td>
</tr>
<tr class="even">
<td align="left">Alternative hypothesis <span class="math inline">\(H_1\)</span>:</td>
<td align="left">at least one row mean is different.</td>
</tr>
</tbody>
</table>
<p>It’s worth noting that these are <em>exactly</em> the same statistical hypotheses that we formed when we ran a one-way ANOVA on these data back in Chapter <a href="anova.html#anova">14</a>. Back then I used the notation <span class="math inline">\(\mu_P\)</span> to refer to the mean mood gain for the placebo group, with <span class="math inline">\(\mu_A\)</span> and <span class="math inline">\(\mu_J\)</span> corresponding to the group means for the two drugs, and the null hypothesis was <span class="math inline">\(\mu_P = \mu_A = \mu_J\)</span>. So we’re actually talking about the same hypothesis: it’s just that the more complicated ANOVA requires more careful notation due to the presence of multiple grouping variables, so we’re now referring to this hypothesis as <span class="math inline">\(\mu_{1.} = \mu_{2.} = \mu_{3.}\)</span>. However, as we’ll see shortly, although the hypothesis is identical, the test of that hypothesis is subtly different due to the fact that we’re now acknowledging the existence of the second grouping variable.</p>
<p>Speaking of the other grouping variable, you won’t be surprised to discover that our second hypothesis test is formulated the same way. However, since we’re talking about the psychological therapy rather than drugs, our null hypothesis now corresponds to the equality of the column means:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
                              <span class="op">~</span>V1,                                                               <span class="op">~</span>V2,
         <span class="st">&quot;Null hypothesis $H_0$:&quot;</span>, <span class="st">&quot;column means are the same, i.e., $</span><span class="ch">\\</span><span class="st">mu_{.1} = </span><span class="ch">\\</span><span class="st">mu_{.2}$&quot;</span>,
  <span class="st">&quot;Alternative hypothesis $H_1$:&quot;</span>,  <span class="st">&quot;column means are different, i.e., $</span><span class="ch">\\</span><span class="st">mu_{.1} </span><span class="ch">\\</span><span class="st">neq </span><span class="ch">\\</span><span class="st">mu_{.2}&quot;</span>
  ), <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>))</code></pre></div>
<table>
<tbody>
<tr class="odd">
<td align="left">Null hypothesis <span class="math inline">\(H_0\)</span>:</td>
<td align="left">column means are the same, i.e., <span class="math inline">\(\mu_{.1} = \mu_{.2}\)</span></td>
</tr>
<tr class="even">
<td align="left">Alternative hypothesis <span class="math inline">\(H_1\)</span>:</td>
<td align="left">column means are different, i.e., $<em>{.1} </em>{.2}</td>
</tr>
</tbody>
</table>
</div>
<div id="running-the-analysis-in-r" class="section level3">
<h3><span class="header-section-number">16.1.2</span> Running the analysis in R</h3>
<p>The null and alternative hypotheses that I described in the last section should seem awfully familiar: they’re basically the same as the hypotheses that we were testing in our simpler one-way ANOVAs in Chapter <a href="anova.html#anova">14</a>. So you’re probably expecting that the hypothesis <em>tests</em> that are used in factorial ANOVA will be essentially the same as the <span class="math inline">\(F\)</span>-test from Chapter <a href="anova.html#anova">14</a>. You’re expecting to see references to sums of squares (SS), mean squares (MS), degrees of freedom (df), and finally an <span class="math inline">\(F\)</span>-statistic that we can convert into a <span class="math inline">\(p\)</span>-value, right? Well, you’re absolutely and completely right. So much so that I’m going to depart from my usual approach. Throughout this book, I’ve generally taken the approach of describing the logic (and to an extent the mathematics) that underpins a particular analysis first; and only then introducing the R commands that you’d use to produce the analysis. This time I’m going to do it the other way around, and show you the R commands first. The reason for doing this is that I want to highlight the similarities between the simple one-way ANOVA tool that we discussed in Chapter <a href="anova.html#anova">14</a>, and the more complicated tools that we’re going to use in this chapter.</p>
<p>If the data you’re trying to analyse correspond to a balanced factorial design, then running your analysis of variance is easy. To see how easy it is, let’s start by reproducing the original analysis from Chapter <a href="anova.html#anova">14</a>. In case you’ve forgotten, for that analysis we were using only a single factor (i.e., <code>drug</code>) to predict our outcome variable (i.e., <code>mood.gain</code>), and so this was what we did:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model.<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">aov</span>( mood.gain <span class="op">~</span><span class="st"> </span>drug, clin.trial )  
<span class="kw">summary</span>( model.<span class="dv">1</span> )  </code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## drug         2  3.453  1.7267   18.61 8.65e-05 ***
## Residuals   15  1.392  0.0928                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Note that this time around I’ve used the name <code>model.1</code> as the label for my <code>aov</code> object, since I’m planning on creating quite a few other models too. To start with, suppose I’m also curious to find out if <code>therapy</code> has a relationship to <code>mood.gain</code>. In light of what we’ve seen from our discussion of multiple regression in Chapter <a href="regression.html#regression">15</a>, you probably won’t be surprised that all we have to do is extend the formula: in other words, if we specify <code>mood.gain ~ drug + therapy</code> as our model, we’ll probably get what we’re after:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model.<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">aov</span>( mood.gain <span class="op">~</span><span class="st"> </span>drug <span class="op">+</span><span class="st"> </span>therapy, clin.trial )  </code></pre></div>
<p>This output is pretty simple to read too: the first row of the table reports a between-group sum of squares (SS) value associated with the <code>drug</code> factor, along with a corresponding between-group <span class="math inline">\(df\)</span> value. It also calculates a mean square value (MS), and <span class="math inline">\(F\)</span>-statistic and a <span class="math inline">\(p\)</span>-value. There is also a row corresponding to the <code>therapy</code> factor, and a row corresponding to the residuals (i.e., the within groups variation).</p>
<p>Not only are all of the individual quantities pretty familiar, the relationships between these different quantities has remained unchanged: just like we saw with the original one-way ANOVA, note that the mean square value is calculated by dividing SS by the corresponding <span class="math inline">\(df\)</span>. That is, it’s still true that <span class="math display">\[
\mbox{MS} = \frac{\mbox{SS}}{df}
\]</span> regardless of whether we’re talking about <code>drug</code>, <code>therapy</code> or the residuals. To see this, let’s not worry about how the sums of squares values are calculated: instead, let’s take it on faith that R has calculated the SS values correctly, and try to verify that all the rest of the numbers make sense. First, note that for the <code>drug</code> factor, we divide <span class="math inline">\(3.45\)</span> by <span class="math inline">\(2\)</span>, and end up with a mean square value of <span class="math inline">\(1.73\)</span>. For the <code>therapy</code> factor, there’s only 1 degree of freedom, so our calculations are even simpler: dividing <span class="math inline">\(0.47\)</span> (the SS value) by 1 gives us an answer of <span class="math inline">\(0.47\)</span> (the MS value).</p>
<p>Turning to the <span class="math inline">\(F\)</span> statistics and the <span class="math inline">\(p\)</span> values, notice that we have two of each: one corresponding to the <code>drug</code> factor and the other corresponding to the <code>therapy</code> factor. Regardless of which one we’re talking about, the <span class="math inline">\(F\)</span> statistic is calculated by dividing the mean square value associated with the factor by the mean square value associated with the residuals. If we use “A” as shorthand notation to refer to the first factor (factor A; in this case <code>drug</code>) and “R” as shorthand notation to refer to the residuals, then the <span class="math inline">\(F\)</span> statistic associated with factor A is denoted <span class="math inline">\(F_A\)</span>, and is calculated as follows: <span class="math display">\[
F_{A} = \frac{\mbox{MS}_{A}}{\mbox{MS}_{R}}
\]</span> and an equivalent formula exists for factor B (i.e., <code>therapy</code>). Note that this use of “R” to refer to residuals is a bit awkward, since we also used the letter R to refer to the number of rows in the table, but I’m only going to use “R” to mean residuals in the context of SS<span class="math inline">\(_R\)</span> and MS<span class="math inline">\(_R\)</span>, so hopefully this shouldn’t be confusing. Anyway, to apply this formula to the <code>drugs</code> factor, we take the mean square of <span class="math inline">\(1.73\)</span> and divide it by the residual mean square value of <span class="math inline">\(0.07\)</span>, which gives us an <span class="math inline">\(F\)</span>-statistic of <span class="math inline">\(26.15\)</span>. The corresponding calculation for the <code>therapy</code> variable would be to divide <span class="math inline">\(0.47\)</span> by <span class="math inline">\(0.07\)</span> which gives <span class="math inline">\(7.08\)</span> as the <span class="math inline">\(F\)</span>-statistic. Not surprisingly, of course, these are the same values that R has reported in the ANOVA table above.</p>
<p>The last part of the ANOVA table is the calculation of the <span class="math inline">\(p\)</span> values. Once again, there is nothing new here: for each of our two factors, what we’re trying to do is test the null hypothesis that there is no relationship between the factor and the outcome variable (I’ll be a bit more precise about this later on). To that end, we’ve (apparently) followed a similar strategy that we did in the one way ANOVA, and have calculated an <span class="math inline">\(F\)</span>-statistic for each of these hypotheses. To convert these to <span class="math inline">\(p\)</span> values, all we need to do is note that the that the sampling distribution for the <span class="math inline">\(F\)</span> <em>statistic</em> under the null hypothesis (that the factor in question is irrelevant) is an <span class="math inline">\(F\)</span> <em>distribution</em>: and that two degrees of freedom values are those corresponding to the factor, and those corresponding to the residuals. For the <code>drug</code> factor we’re talking about an <span class="math inline">\(F\)</span> distribution with 2 and 14 degrees of freedom (I’ll discuss degrees of freedom in more detail later). In contrast, for the <code>therapy</code> factor sampling distribution is <span class="math inline">\(F\)</span> with 1 and 14 degrees of freedom. If we really wanted to, we could calculate the <span class="math inline">\(p\)</span> value ourselves using the <code>pf()</code> function (see Section <a href="probability.html#otherdists">9.6</a>). Just to prove that there’s nothing funny going on, here’s what that would look like for the <code>drug</code> variable:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pf</span>( <span class="dt">q=</span><span class="fl">26.15</span>, <span class="dt">df1=</span><span class="dv">2</span>, <span class="dt">df2=</span><span class="dv">14</span>, <span class="dt">lower.tail=</span><span class="ot">FALSE</span> )</code></pre></div>
<pre><code>## [1] 1.871981e-05</code></pre>
<p>And as you can see, this is indeed the <span class="math inline">\(p\)</span> value reported in the ANOVA table above.</p>
<p>At this point, I hope you can see that the ANOVA table for this more complicated analysis corresponding to <code>model.2</code> should be read in much the same way as the ANOVA table for the simpler analysis for <code>model.1</code>. In short, it’s telling us that the factorial ANOVA for our <span class="math inline">\(3 \times 2\)</span> design found a significant effect of drug (<span class="math inline">\(F_{2,14} = 26.15, p &lt; .001\)</span>) as well as a significant effect of therapy (<span class="math inline">\(F_{1,14} = 7.08, p = .02\)</span>). Or, to use the more technically correct terminology, we would say that there are two <strong><em>main effects</em></strong> of drug and therapy. At the moment, it probably seems a bit redundant to refer to these as “main” effects: but it actually does make sense. Later on, we’re going to want to talk about the possibility of “interactions” between the two factors, and so we generally make a distinction between main effects and interaction effects.</p>
</div>
<div id="how-are-the-sum-of-squares-calculated" class="section level3">
<h3><span class="header-section-number">16.1.3</span> How are the sum of squares calculated?</h3>
<p>In the previous section I had two goals: firstly, to show you that the R commands needed to do factorial ANOVA are pretty much the same ones that we used for a one way ANOVA. The only difference is the <code>formula</code> argument to the <code>aov()</code> function. Secondly, I wanted to show you what the ANOVA table looks like in this case, so that you can see from the outset that the basic logic and structure behind factorial ANOVA is the same as that which underpins one way ANOVA. Try to hold onto that feeling. It’s genuinely true, insofar as factorial ANOVA is built in more or less the same way as the simpler one-way ANOVA model. It’s just that this feeling of familiarity starts to evaporate once you start digging into the details. Traditionally, this comforting sensation is replaced by an urge to murder the the authors of statistics textbooks.</p>
<p>Okay, let’s start looking at some of those details. The explanation that I gave in the last section illustrates the fact that the hypothesis tests for the main effects (of drug and therapy in this case) are <span class="math inline">\(F\)</span>-tests, but what it doesn’t do is show you how the sum of squares (SS) values are calculated. Nor does it tell you explicitly how to calculate degrees of freedom (<span class="math inline">\(df\)</span> values) though that’s a simple thing by comparison. Let’s assume for now that we have only two predictor variables, Factor A and Factor B. If we use <span class="math inline">\(Y\)</span> to refer to the outcome variable, then we would use <span class="math inline">\(Y_{rci}\)</span> to refer to the outcome associated with the <span class="math inline">\(i\)</span>-th member of group <span class="math inline">\(rc\)</span> (i.e., level/row <span class="math inline">\(r\)</span> for Factor A and level/column <span class="math inline">\(c\)</span> for Factor B). Thus, if we use <span class="math inline">\(\bar{Y}\)</span> to refer to a sample mean, we can use the same notation as before to refer to group means, marginal means and grand means: that is, <span class="math inline">\(\bar{Y}_{rc}\)</span> is the sample mean associated with the <span class="math inline">\(r\)</span>th level of Factor A and the <span class="math inline">\(c\)</span>th level of Factor B, <span class="math inline">\(\bar{Y}_{r.}\)</span> would be the marginal mean for the <span class="math inline">\(r\)</span>th level of Factor A, <span class="math inline">\(\bar{Y}_{.c}\)</span> would be the marginal mean for the <span class="math inline">\(c\)</span>th level of Factor B, and <span class="math inline">\(\bar{Y}_{..}\)</span> is the grand mean. In other words, our sample means can be organised into the same table as the population means. For our clinical trial data, that table looks like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
         <span class="op">~</span>V1,               <span class="op">~</span>V2,               <span class="op">~</span>V3,               <span class="op">~</span>V4,
   <span class="st">&quot;placebo&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">bar{Y}_{11}$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">bar{Y}_{12}$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">bar{Y}_{1.}$&quot;</span>,
  <span class="st">&quot;anxifree&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">bar{Y}_{21}$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">bar{Y}_{22}$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">bar{Y}_{2.}$&quot;</span>,
  <span class="st">&quot;joyzepam&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">bar{Y}_{31}$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">bar{Y}_{32}$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">bar{Y}_{3.}$&quot;</span>,
     <span class="st">&quot;total&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">bar{Y}_{.1}$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">bar{Y}_{.2}$&quot;</span>, <span class="st">&quot;$</span><span class="ch">\\</span><span class="st">bar{Y}_{..}$&quot;</span>
  ), <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;&quot;</span>,      <span class="st">&quot;no therapy&quot;</span>,             <span class="st">&quot;CBT&quot;</span>,           <span class="st">&quot;total&quot;</span>))</code></pre></div>
<table>
<thead>
<tr class="header">
<th></th>
<th align="left">no therapy</th>
<th align="left">CBT</th>
<th align="left">total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>placebo</td>
<td align="left"><span class="math inline">\(\bar{Y}_{11}\)</span></td>
<td align="left"><span class="math inline">\(\bar{Y}_{12}\)</span></td>
<td align="left"><span class="math inline">\(\bar{Y}_{1.}\)</span></td>
</tr>
<tr class="even">
<td>anxifree</td>
<td align="left"><span class="math inline">\(\bar{Y}_{21}\)</span></td>
<td align="left"><span class="math inline">\(\bar{Y}_{22}\)</span></td>
<td align="left"><span class="math inline">\(\bar{Y}_{2.}\)</span></td>
</tr>
<tr class="odd">
<td>joyzepam</td>
<td align="left"><span class="math inline">\(\bar{Y}_{31}\)</span></td>
<td align="left"><span class="math inline">\(\bar{Y}_{32}\)</span></td>
<td align="left"><span class="math inline">\(\bar{Y}_{3.}\)</span></td>
</tr>
<tr class="even">
<td>total</td>
<td align="left"><span class="math inline">\(\bar{Y}_{.1}\)</span></td>
<td align="left"><span class="math inline">\(\bar{Y}_{.2}\)</span></td>
<td align="left"><span class="math inline">\(\bar{Y}_{..}\)</span></td>
</tr>
</tbody>
</table>
<p>And if we look at the sample means that I showed earlier, we have <span class="math inline">\(\bar{Y}_{11} = 0.30\)</span>, <span class="math inline">\(\bar{Y}_{12} = 0.60\)</span> etc. In our clinical trial example, the <code>drugs</code> factor has 3 levels and the <code>therapy</code> factor has 2 levels, and so what we’re trying to run is a <span class="math inline">\(3 \times 2\)</span> factorial ANOVA. However, we’ll be a little more general and say that Factor A (the row factor) has <span class="math inline">\(R\)</span> levels and Factor B (the column factor) has <span class="math inline">\(C\)</span> levels, and so what we’re runnning here is an <span class="math inline">\(R \times C\)</span> factorial ANOVA.</p>
<p>Now that we’ve got our notation straight, we can compute the sum of squares values for each of the two factors in a relatively familiar way. For Factor A, our between group sum of squares is calculated by assessing the extent to which the (row) marginal means <span class="math inline">\(\bar{Y}_{1.}\)</span>, <span class="math inline">\(\bar{Y}_{2.}\)</span> etc, are different from the grand mean <span class="math inline">\(\bar{Y}_{..}\)</span>. We do this in the same way that we did for one-way ANOVA: calculate the sum of squared difference between the <span class="math inline">\(\bar{Y}_{i.}\)</span> values and the <span class="math inline">\(\bar{Y}_{..}\)</span> values. Specifically, if there are <span class="math inline">\(N\)</span> people in each group, then we calculate this: <span class="math display">\[
\mbox{SS}_{A} = (N \times C)  \sum_{r=1}^R  \left( \bar{Y}_{r.} - \bar{Y}_{..} \right)^2
\]</span> As with one-way ANOVA, the most interesting<a href="#fn234" class="footnoteRef" id="fnref234"><sup>234</sup></a> part of this formula is the <span class="math inline">\(\left( \bar{Y}_{r.} - \bar{Y}_{..} \right)^2\)</span> bit, which corresponds to the squared deviation associated with level <span class="math inline">\(r\)</span>. All that this formula does is calculate this squared deviation for all <span class="math inline">\(R\)</span> levels of the factor, add them up, and then multiply the result by <span class="math inline">\(N \times C\)</span>. The reason for this last part is that there are multiple cells in our design that have level <span class="math inline">\(r\)</span> on Factor A: in fact, there are <span class="math inline">\(C\)</span> of them, one corresponding to each possible level of Factor B! For instance, in our toy example, there are <em>two</em> different cells in the design corresponding to the <code>anxifree</code> drug: one for people with <code>no.therapy</code>, and one for the <code>CBT</code> group. Not only that, within each of these cells there are <span class="math inline">\(N\)</span> observations. So, if we want to convert our SS value into a quantity that calculates the between-groups sum of squares on a “per observation” basis, we have to multiply by by <span class="math inline">\(N \times C\)</span>. The formula for factor B is of course the same thing, just with some subscripts shuffled around: <span class="math display">\[
\mbox{SS}_{B} = (N \times R) \sum_{c=1}^C \left( \bar{Y}_{.c} - \bar{Y}_{..} \right)^2
\]</span></p>
<p>Now that we have these formulas, we can check them against the R output from the earlier section. First, notice that we calculated all the marginal means (i.e., row marginal means <span class="math inline">\(\bar{Y}_{r.}\)</span> and column marginal means <span class="math inline">\(\bar{Y}_{.c}\)</span>) earlier using <code>aggregate()</code>, and we also calculated the grand mean. Let’s repeat those calculations, but this time we’ll save the results to varibles so that we can use them in subsequent calculations:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">drug.means &lt;-<span class="st"> </span><span class="kw">aggregate</span>( mood.gain <span class="op">~</span><span class="st"> </span>drug, clin.trial, mean )[,<span class="dv">2</span>]
therapy.means &lt;-<span class="st"> </span><span class="kw">aggregate</span>( mood.gain <span class="op">~</span><span class="st"> </span>therapy, clin.trial, mean )[,<span class="dv">2</span>]
grand.mean &lt;-<span class="st"> </span><span class="kw">mean</span>( clin.trial<span class="op">$</span>mood.gain )</code></pre></div>
<p>Okay, now let’s calculate the sum of squares associated with the main effect of <code>drug</code>. There are a total of <span class="math inline">\(N=3\)</span> people in each group, and <span class="math inline">\(C=2\)</span> different types of therapy. Or, to put it another way, there are <span class="math inline">\(3 \times 2 = 6\)</span> people who received any particular drug. So our calculations are:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SS.drug &lt;-<span class="st"> </span>(<span class="dv">3</span><span class="op">*</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span><span class="kw">sum</span>( (drug.means <span class="op">-</span><span class="st"> </span>grand.mean)<span class="op">^</span><span class="dv">2</span> )
SS.drug</code></pre></div>
<pre><code>## [1] 3.453333</code></pre>
<p>Not surprisingly, this is the same number that you get when you look up the SS value for the drugs factor in the ANOVA table that I presented earlier. We can repeat the same kind of calculation for the effect of therapy. Again there are <span class="math inline">\(N=3\)</span> people in each group, but since there are <span class="math inline">\(R=3\)</span> different drugs, this time around we note that there are <span class="math inline">\(3 \times 3 = 9\)</span> people who received CBT, and an additional 9 people who received the placebo. So our calculation is now:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SS.therapy &lt;-<span class="st"> </span>(<span class="dv">3</span><span class="op">*</span><span class="dv">3</span>) <span class="op">*</span><span class="st"> </span><span class="kw">sum</span>( (therapy.means <span class="op">-</span><span class="st"> </span>grand.mean)<span class="op">^</span><span class="dv">2</span> )
SS.therapy</code></pre></div>
<pre><code>## [1] 0.4672222</code></pre>
<p>and we are, once again, unsurprised to see that our calculations are identical to the ANOVA output.</p>
<p>So that’s how you calculate the SS values for the two main effects. These SS values are analogous to the between-group sum of squares values that we calculated when doing one-way ANOVA in Chapter <a href="anova.html#anova">14</a>. However, it’s not a good idea to think of them as between-groups SS values anymore, just because we have two different grouping variables and it’s easy to get confused. In order to construct an <span class="math inline">\(F\)</span> test, however, we also need to calculate the within-groups sum of squares. In keeping with the terminology that we used in the regression chapter (Chapter <a href="regression.html#regression">15</a>) and the terminology that R uses when printing out the ANOVA table, I’ll start referring to the within-groups SS value as the <em>residual</em> sum of squares SS<span class="math inline">\(_R\)</span>.</p>
<p>The easiest way to think about the residual SS values in this context, I think, is to think of it as the leftover variation in the outcome variable after you take into account the differences in the marginal means (i.e., after you remove SS<span class="math inline">\(_A\)</span> and SS<span class="math inline">\(_B\)</span>). What I mean by that is we can start by calculating the total sum of squares, which I’ll label SS<span class="math inline">\(_T\)</span>. The formula for this is pretty much the same as it was for one-way ANOVA: we take the difference between each observation <span class="math inline">\(Y_{rci}\)</span> and the grand mean <span class="math inline">\(\bar{Y}_{..}\)</span>, square the differences, and add them all up <span class="math display">\[
\mbox{SS}_T = \sum_{r=1}^R \sum_{c=1}^C \sum_{i=1}^N \left( Y_{rci} - \bar{Y}_{..}\right)^2
\]</span> The “triple summation” here looks more complicated than it is. In the first two summations, we’re summing across all levels of Factor A (i.e., over all possible rows <span class="math inline">\(r\)</span> in our table), across all levels of Factor B (i.e., all possible columns <span class="math inline">\(c\)</span>). Each <span class="math inline">\(rc\)</span> combination corresponds to a single group, and each group contains <span class="math inline">\(N\)</span> people: so we have to sum across all those people (i.e., all <span class="math inline">\(i\)</span> values) too. In other words, all we’re doing here is summing across all observations in the data set (i.e., all possible <span class="math inline">\(rci\)</span> combinations).</p>
<p>At this point, we know the total variability of the outcome variable SS<span class="math inline">\(_T\)</span>, and we know how much of that variability can be attributed to Factor A (SS<span class="math inline">\(_A\)</span>) and how much of it can be attributed to Factor B (SS<span class="math inline">\(_B\)</span>). The residual sum of squares is thus defined to be the variability in <span class="math inline">\(Y\)</span> that <em>can’t</em> be attributed to either of our two factors. In other words: <span class="math display">\[
\mbox{SS}_R = \mbox{SS}_T - (\mbox{SS}_A + \mbox{SS}_B)
\]</span> Of course, there is a formula that you can use to calculate the residual SS directly, but I think that it makes more conceptual sense to think of it like this. The whole point of calling it a residual is that it’s the leftover variation, and the formula above makes that clear. I should also note that, in keeping with the terminology used in the regression chapter, it is commonplace to refer to <span class="math inline">\(\mbox{SS}_A + \mbox{SS}_B\)</span> as the variance attributable to the “ANOVA model”, denoted SS<span class="math inline">\(_M\)</span>, and so we often say that the total sum of squares is equal to the model sum of squares plus the residual sum of squares. Later on in this chapter we’ll see that this isn’t just a surface similarity: ANOVA and regression are actually the same thing under the hood.</p>
<p>In any case, it’s probably worth taking a moment to check that we can calculate SS<span class="math inline">\(_R\)</span> using this formula, and verify that we do obtain the same answer that R produces in its ANOVA table. The calculations are pretty straightforward. First we calculate the total sum of squares:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SS.tot &lt;-<span class="st"> </span><span class="kw">sum</span>( (clin.trial<span class="op">$</span>mood.gain <span class="op">-</span><span class="st"> </span>grand.mean)<span class="op">^</span><span class="dv">2</span> )
SS.tot</code></pre></div>
<pre><code>## [1] 4.845</code></pre>
<p>and then we use it to calculate the residual sum of squares:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SS.res &lt;-<span class="st"> </span>SS.tot <span class="op">-</span><span class="st"> </span>(SS.drug <span class="op">+</span><span class="st"> </span>SS.therapy)
SS.res</code></pre></div>
<pre><code>## [1] 0.9244444</code></pre>
<p>Yet again, we get the same answer.</p>
</div>
<div id="what-are-our-degrees-of-freedom" class="section level3">
<h3><span class="header-section-number">16.1.4</span> What are our degrees of freedom?</h3>
<p>The degrees of freedom are calculated in much the same way as for one-way ANOVA. For any given factor, the degrees of freedom is equal to the number of levels minus 1 (i.e., <span class="math inline">\(R-1\)</span> for the row variable, Factor A, and <span class="math inline">\(C-1\)</span> for the column variable, Factor B). So, for the <code>drugs</code> factor we obtain <span class="math inline">\(df = 2\)</span>, and for the <code>therapy</code> factor we obtain <span class="math inline">\(df=1\)</span>. Later on on, when we discuss the interpretation of ANOVA as a regression model (see Section <a href="anova2.html#anovalm">16.6</a>) I’ll give a clearer statement of how we arrive at this number, but for the moment we can use the simple definition of degrees of freedom, namely that the degrees of freedom equals the number of quantities that are observed, minus the number of constraints. So, for the <code>drugs</code> factor, we observe 3 separate group means, but these are constrained by 1 grand mean; and therefore the degrees of freedom is 2. For the residuals, the logic is similar, but not quite the same. The total number of observations in our experiment is 18. The constraints correspond to the 1 grand mean, the 2 additional group means that the <code>drug</code> factor introduces, and the 1 additional group mean that the the <code>therapy</code> factor introduces, and so our degrees of freedom is 14. As a formula, this is <span class="math inline">\(N-1 -(R-1)-(C-1)\)</span>, which simplifies to <span class="math inline">\(N-R-C+1\)</span>.</p>
</div>
<div id="factorial-anova-versus-one-way-anovas" class="section level3">
<h3><span class="header-section-number">16.1.5</span> Factorial ANOVA versus one-way ANOVAs</h3>
<p>Now that we’ve seen <em>how</em> a factorial ANOVA works, it’s worth taking a moment to compare it to the results of the one way analyses, because this will give us a really good sense of <em>why</em> it’s a good idea to run the factorial ANOVA. In Chapter <a href="anova.html#anova">14</a> that I ran a one-way ANOVA that looked to see if there are any differences between drugs, and a second one-way ANOVA to see if there were any differences between therapies. As we saw in Section <a href="anova2.html#factanovahyp">16.1.1</a>, the null and alternative hypotheses tested by the one-way ANOVAs are in fact identical to the hypotheses tested by the factorial ANOVA. Looking even more carefully at the ANOVA tables, we can see that the sum of squares associated with the factors are identical in the two different analyses (3.45 for <code>drug</code> and 0.92 for <code>therapy</code>), as are the degrees of freedom (2 for <code>drug</code>, 1 for <code>therapy</code>). But they don’t give the same answers! Most notably, when we ran the one-way ANOVA for <code>therapy</code> in Section <a href="anova.html#anovaandt">14.11</a> we didn’t find a significant effect (the <span class="math inline">\(p\)</span>-value was 0.21). However, when we look at the main effect of <code>therapy</code> within the context of the two-way ANOVA, we do get a significant effect (<span class="math inline">\(p=.019\)</span>). The two analyses are clearly not the same.</p>
<p>Why does that happen? The answer lies in understanding how the <em>residuals</em> are calculated. Recall that the whole idea behind an <span class="math inline">\(F\)</span>-test is to compare the variability that can be attributed to a particular factor with the variability that cannot be accounted for (the residuals). If you run a one-way ANOVA for <code>therapy</code>, and therefore ignore the effect of <code>drug</code>, the ANOVA will end up dumping all of the drug-induced variability into the residuals! This has the effect of making the data look more noisy than they really are, and the effect of <code>therapy</code> which is correctly found to be significant in the two-way ANOVA now becomes non-significant. If we ignore something that actually matters (e.g., <code>drug</code>) when trying to assess the contribution of something else (e.g., <code>therapy</code>) then our analysis will be distorted. Of course, it’s perfectly okay to ignore variables that are genuinely irrelevant to the phenomenon of interest: if we had recorded the colour of the walls, and that turned out to be non-significant in a three-way ANOVA (i.e. <code>mood.gain ~ drug + therapy + wall.colour</code>), it would be perfectly okay to disregard it and just report the simpler two-way ANOVA that doesn’t include this irrelevant factor. What you shouldn’t do is drop variables that actually make a difference!</p>
<div class="figure"><span id="fig:maineffectsa"></span>
<img src="C:/Users/pcmis/Documents/rbook/bookdown/img/factorialanova/maineffectA.png" alt="A main effect of Factor A, and no effect of Factor B"  />
<p class="caption">
Figure 16.1: A main effect of Factor A, and no effect of Factor B
</p>
</div>
<div class="figure"><span id="fig:maineffectsb"></span>
<img src="C:/Users/pcmis/Documents/rbook/bookdown/img/factorialanova/maineffectB.png" alt="A main effect of Factor B but no effect of Factor A"  />
<p class="caption">
Figure 16.2: A main effect of Factor B but no effect of Factor A
</p>
</div>
<div class="figure"><span id="fig:maineffectsc"></span>
<img src="C:/Users/pcmis/Documents/rbook/bookdown/img/factorialanova/maineffectAB.png" alt="Main effects of both Factor A and Factor B"  />
<p class="caption">
Figure 16.3: Main effects of both Factor A and Factor B
</p>
</div>
<div class="figure"><span id="fig:maineffectsd"></span>
<img src="C:/Users/pcmis/Documents/rbook/bookdown/img/factorialanova/maineffectAB.png" alt="No effect of either factor"  />
<p class="caption">
Figure 16.4: No effect of either factor
</p>
</div>
</div>
<div id="what-kinds-of-outcomes-does-this-analysis-capture" class="section level3">
<h3><span class="header-section-number">16.1.6</span> What kinds of outcomes does this analysis capture?</h3>
<p>The ANOVA model that we’ve been talking about so far covers a range of different patterns that we might observe in our data. For instance, in a two-way ANOVA design, there are four possibilities: (a) only Factor A matters, (b) only Factor B matters, (c) both A and B matter, and (d) neither A nor B matters. An example of each of these four possibilities is plotted in Figure <a href="#fig:maineffects"><strong>??</strong></a>.</p>
</div>
</div>
<div id="interactions" class="section level2">
<h2><span class="header-section-number">16.2</span> Factorial ANOVA 2: balanced designs, interactions allowed</h2>
<div class="figure"><span id="fig:interaction1"></span>
<img src="C:/Users/pcmis/Documents/rbook/bookdown/img/factorialanova/interaction2.png" alt="Qualitatively different interactions for a $2   imes 2$ ANOVA"  />
<p class="caption">
Figure 16.5: Qualitatively different interactions for a <span class="math inline">\(2 imes 2\)</span> ANOVA
</p>
</div>
<div class="figure"><span id="fig:interaction2"></span>
<img src="C:/Users/pcmis/Documents/rbook/bookdown/img/factorialanova/interaction3.png" alt="Qualitatively different interactions for a $2   imes 2$ ANOVA"  />
<p class="caption">
Figure 16.6: Qualitatively different interactions for a <span class="math inline">\(2 imes 2\)</span> ANOVA
</p>
</div>
<div class="figure"><span id="fig:interaction3"></span>
<img src="C:/Users/pcmis/Documents/rbook/bookdown/img/factorialanova/interaction1.png" alt="Qualitatively different interactions for a $2   imes 2$ ANOVA"  />
<p class="caption">
Figure 16.7: Qualitatively different interactions for a <span class="math inline">\(2 imes 2\)</span> ANOVA
</p>
</div>
<div class="figure"><span id="fig:interaction4"></span>
<img src="C:/Users/pcmis/Documents/rbook/bookdown/img/factorialanova/interaction4.png" alt="Qualitatively different interactions for a $2   imes 2$ ANOVA"  />
<p class="caption">
Figure 16.8: Qualitatively different interactions for a <span class="math inline">\(2 imes 2\)</span> ANOVA
</p>
</div>
<p>The four patterns of data shown in Figure <a href="#fig:maineffects"><strong>??</strong></a> are all quite realistic: there are a great many data sets that produce exactly those patterns. However, they are not the whole story, and the ANOVA model that we have been talking about up to this point is not sufficient to fully account for a table of group means. Why not? Well, so far we have the ability to talk about the idea that drugs can influence mood, and therapy can influence mood, but no way of talking about the possibility of an <strong><em>interaction</em></strong> between the two. An interaction between A and B is said to occur whenever the effect of Factor A is <em>different</em>, depending on which level of Factor B we’re talking about. Several examples of an interaction effect with the context of a 2 x 2 ANOVA are shown in Figure <a href="#fig:interaction"><strong>??</strong></a>. To give a more concrete example, suppose that the operation of Anxifree and Joyzepam is governed quite different physiological mechanisms, and one consequence of this is that while Joyzepam has more or less the same effect on mood regardless of whether one is in therapy, Anxifree is actually much more effective when administered in conjunction with CBT. The ANOVA that we developed in the previous section does not capture this idea. To get some idea of whether an interaction is actually happening here, it helps to plot the various group means. There are quite a few different ways draw these plots in R. One easy way is to use the <code>interaction.plot()</code> function, but this function won’t draw error bars for you. A fairly simple function that will include error bars for you is the <code>lineplot.CI()</code> function in the <code>sciplots</code> package (see Section <a href="estimation.html#ciplots">10.5.4</a>). The command</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(sciplot)
<span class="kw">library</span>(lsr)
 <span class="kw">lineplot.CI</span>( <span class="dt">x.factor =</span> clin.trial<span class="op">$</span>drug, 
              <span class="dt">response =</span> clin.trial<span class="op">$</span>mood.gain,
              <span class="dt">group =</span> clin.trial<span class="op">$</span>therapy,
              <span class="dt">ci.fun =</span> ciMean,
              <span class="dt">xlab =</span> <span class="st">&quot;drug&quot;</span>,
              <span class="dt">ylab =</span> <span class="st">&quot;mood gain&quot;</span> )</code></pre></div>
<p>produces the output is shown in Figure <a href="anova2.html#fig:interactionplot">16.9</a> (don’t forget that the <code>ciMean</code> function is in the <code>lsr</code> package, so you need to have <code>lsr</code> loaded!). Our main concern relates to the fact that the two lines aren’t parallel. The effect of CBT (difference between solid line and dotted line) when the drug is Joyzepam (right side) appears to be near zero, even smaller than the effect of CBT when a placebo is used (left side). However, when Anxifree is administered, the effect of CBT is larger than the placebo (middle). Is this effect real, or is this just random variation due to chance? Our original ANOVA cannot answer this question, because we make no allowances for the idea that interactions even exist! In this section, we’ll fix this problem.</p>
<div id="what-exactly-is-an-interaction-effect" class="section level3">
<h3><span class="header-section-number">16.2.1</span> What exactly <em>is an interaction effect?</em></h3>
The key idea that we’re going to introduce in this section is that of an interaction effect. What that means for our R formulas is that we’ll write down models like

<p>so although there are only two <em>factors</em> involved in our model (i.e., <code>drug</code> and <code>therapy</code>), there are three distinct <strong><em>terms</em></strong> (i.e., <code>drug</code>, <code>therapy</code> and <code>drug:therapy</code>). That is, in addition to the main effects of <code>drug</code> and <code>therapy</code>, we have a new component to the model, which is our interaction term <code>drug:therapy</code>. Intuitively, the idea behind an interaction effect is fairly simple: it just means that the effect of Factor A is different, depending on which level of Factor B we’re talking about. But what does that actually mean in terms of our data? Figure <a href="#fig:interaction"><strong>??</strong></a> depicts several different patterns that, although quite different to each other, would all count as an interaction effect. So it’s not entirely straightforward to translate this qualitative idea into something mathematical that a statistician can work with. As a consequence, the way that the idea of an interaction effect is formalised in terms of null and alternative hypotheses is slightly difficult, and I’m guessing that a lot of readers of this book probably won’t be all that interested. Even so, I’ll try to give the basic idea here.</p>
<p>To start with, we need to be a little more explicit about our main effects. Consider the main effect of Factor A (<code>drug</code> in our running example). We originally formulated this in terms of the null hypothesis that the two marginal means <span class="math inline">\(\mu_{r.}\)</span> are all equal to each other. Obviously, if all of these are equal to each other, then they must also be equal to the grand mean <span class="math inline">\(\mu_{..}\)</span> as well, right? So what we can do is define the <em>effect</em> of Factor A at level <span class="math inline">\(r\)</span> to be equal to the difference between the marginal mean <span class="math inline">\(\mu_{r.}\)</span> and the grand mean <span class="math inline">\(\mu_{..}\)</span>.<br />
Let’s denote this effect by <span class="math inline">\(\alpha_r\)</span>, and note that <span class="math display">\[
\alpha_r  = \mu_{r.} - \mu_{..} 
\]</span> Now, by definition all of the <span class="math inline">\(\alpha_r\)</span> values must sum to zero, for the same reason that the average of the marginal means <span class="math inline">\(\mu_{r.}\)</span> must be the grand mean <span class="math inline">\(\mu_{..}\)</span>. We can similarly define the effect of Factor B at level <span class="math inline">\(i\)</span> to be the difference between the column marginal mean <span class="math inline">\(\mu_{.c}\)</span> and the grand mean <span class="math inline">\(\mu_{..}\)</span> <span class="math display">\[
\beta_c = \mu_{.c} - \mu_{..}
\]</span> and once again, these <span class="math inline">\(\beta_c\)</span> values must sum to zero. The reason that statisticians sometimes like to talk about the main effects in terms of these <span class="math inline">\(\alpha_r\)</span> and <span class="math inline">\(\beta_c\)</span> values is that it allows them to be precise about what it means to say that there is no interaction effect. If there is no interaction at all, then these <span class="math inline">\(\alpha_r\)</span> and <span class="math inline">\(\beta_c\)</span> values will perfectly describe the group means <span class="math inline">\(\mu_{rc}\)</span>. Specifically, it means that <span class="math display">\[
\mu_{rc} = \mu_{..} + \alpha_r + \beta_c 
\]</span> That is, there’s nothing <em>special</em> about the group means that you couldn’t predict perfectly by knowing all the marginal means. And that’s our null hypothesis, right there. The alternative hypothesis is that <span class="math display">\[
\mu_{rc} \neq \mu_{..} + \alpha_r + \beta_c 
\]</span> for at least one group <span class="math inline">\(rc\)</span> in our table. However, statisticians often like to write this slightly differently. They’ll usually define the specific interaction associated with group <span class="math inline">\(rc\)</span> to be some number, awkwardly referred to as <span class="math inline">\((\alpha\beta)_{rc}\)</span>, and then they will say that the alternative hypothesis is that <span class="math display">\[\mu_{rc} = \mu_{..} + \alpha_r + \beta_c + (\alpha\beta)_{rc}\]</span> where <span class="math inline">\((\alpha\beta)_{rc}\)</span> is non-zero for at least one group. This notation is kind of ugly to look at, but it is handy as we’ll see in the next section when discussing how to calculate the sum of squares.</p>
<div class="figure"><span id="fig:interactionplot"></span>
<img src="lsr_files/figure-html/interactionplot-1.png" alt="An interaction plot for the group means in the clinical trial data. The command to produce it is included in the main text. You'll notice that the legend doesn't quite fit properly. You can fix this by playing around with the `x.leg` and `y.leg` arguments: type `?lineplot.CI` for details." width="672" />
<p class="caption">
Figure 16.9: An interaction plot for the group means in the clinical trial data. The command to produce it is included in the main text. You’ll notice that the legend doesn’t quite fit properly. You can fix this by playing around with the <code>x.leg</code> and <code>y.leg</code> arguments: type <code>?lineplot.CI</code> for details.
</p>
</div>
</div>
<div id="calculating-sums-of-squares-for-the-interaction" class="section level3">
<h3><span class="header-section-number">16.2.2</span> Calculating sums of squares for the interaction</h3>
How should we calculate the sum of squares for the interaction terms, SS<span class="math inline">\(_{A:B}\)</span>? Well, first off, it helps to notice how the previous section defined the interaction effect in terms of the extent to which the actual group means differ from what you’d expect by just looking at the marginal means. Of course, all of those formulas refer to population parameters rather than sample statistics, so we don’t actually know what they are. However, we can estimate them by using sample means in place of population means. So for Factor A, a good way to estimate the main effect at level <span class="math inline">\(r\)</span> as the difference between the <em>sample</em> marginal mean <span class="math inline">\(\bar{Y}_{rc}\)</span> and the sample grand mean <span class="math inline">\(\bar{Y}_{..}\)</span>. That is, we would use this as our estimate of the effect: <span class="math display">\[
\hat{\alpha}_r = \bar{Y}_{r.} - \bar{Y}_{..}
\]</span> Similarly, our estimate of the main effect of Factor B at level <span class="math inline">\(c\)</span> can be defined as follows: <span class="math display">\[
\hat{\beta}_c = \bar{Y}_{.c} - \bar{Y}_{..}
\]</span> Now, if you go back to the formulas that I used to describe the SS values for the two main effects, you’ll notice that these effect terms are exactly the quantities that we were squaring and summing! So what’s the analog of this for interaction terms? The answer to this can be found by first rearranging the formula for the group means <span class="math inline">\(\mu_{rc}\)</span> under the alternative hypothesis, so that we get this:
<span class="math display">\[\begin{eqnarray*} 
(\alpha \beta)_{rc} &amp;=&amp; \mu_{rc} - \mu_{..} - \alpha_r - \beta_c \\
&amp;=&amp; \mu_{rc} - \mu_{..} - (\mu_{r.} - \mu_{..}) - (\mu_{.c} - \mu_{..}) \\
&amp;=&amp; \mu_{rc} - \mu_{r.} - \mu_{.c} + \mu_{..}
\end{eqnarray*}\]</span>
<p>So, once again, if we substitute our sample statistics in place of the population means, we get the following as our estimate of the interaction effect for group <span class="math inline">\(rc\)</span>, which is <span class="math display">\[
\hat{(\alpha\beta)}_{rc} = \bar{Y}_{rc} - \bar{Y}_{r.} - \bar{Y}_{.c} + \bar{Y}_{..}
\]</span> Now all we have to do is sum all of these estimates across all <span class="math inline">\(R\)</span> levels of Factor A and all <span class="math inline">\(C\)</span> levels of Factor B, and we obtain the following formula for the sum of squares associated with the interaction as a whole: <span class="math display">\[
\mbox{SS}_{A:B} = N \sum_{r=1}^R \sum_{c=1}^C \left( \bar{Y}_{rc} - \bar{Y}_{r.} - \bar{Y}_{.c} + \bar{Y}_{..} \right)^2
\]</span> where, we multiply by <span class="math inline">\(N\)</span> because there are <span class="math inline">\(N\)</span> observations in each of the groups, and we want our SS values to reflect the variation among <em>observations</em> accounted for by the interaction, not the variation among groups.</p>
<p>Now that we have a formula for calculating SS<span class="math inline">\(_{A:B}\)</span>, it’s important to recognise that the interaction term is part of the model (of course), so the total sum of squares associated with the model, SS<span class="math inline">\(_M\)</span> is now equal to the sum of the three relevant SS values, <span class="math inline">\(\mbox{SS}_A + \mbox{SS}_B + \mbox{SS}_{A:B}\)</span>. The residual sum of squares <span class="math inline">\(\mbox{SS}_R\)</span> is still defined as the leftover variation, namely <span class="math inline">\(\mbox{SS}_T - \mbox{SS}_M\)</span>, but now that we have the interaction term this becomes <span class="math display">\[
\mbox{SS}_R = \mbox{SS}_T - (\mbox{SS}_A + \mbox{SS}_B + \mbox{SS}_{A:B})
\]</span> As a consequence, the residual sum of squares SS<span class="math inline">\(_R\)</span> will be smaller than in our original ANOVA that didn’t include interactions.</p>
</div>
<div id="degrees-of-freedom-for-the-interaction" class="section level3">
<h3><span class="header-section-number">16.2.3</span> Degrees of freedom for the interaction</h3>
Calculating the degrees of freedom for the interaction is, once again, slightly trickier than the corresponding calculation for the main effects. To start with, let’s think about the ANOVA model as a whole. Once we include interaction effects in the model, we’re allowing every single group has a unique mean, <span class="math inline">\(\mu_{rc}\)</span>. For an <span class="math inline">\(R \times C\)</span> factorial ANOVA, this means that there are <span class="math inline">\(R \times C\)</span> quantities of interest in the model, and only the one constraint: all of the group means need to average out to the grand mean. So the model as a whole needs to have <span class="math inline">\((R\times C) - 1\)</span> degrees of freedom. But the main effect of Factor A has <span class="math inline">\(R-1\)</span> degrees of freedom, and the main effect of Factor B has <span class="math inline">\(C-1\)</span> degrees of freedom. Which means that the degrees of freedom associated with the interaction is
<span class="math display">\[\begin{eqnarray*}
df_{A:B} &amp;=&amp; (R\times C - 1) - (R - 1) - (C -1 ) \\
&amp;=&amp; RC - R - C + 1 \\
&amp;=&amp; (R-1)(C-1)
\end{eqnarray*}\]</span>
<p>which is just the product of the degrees of freedom associated with the row factor and the column factor.</p>
<p>What about the residual degrees of freedom? Because we’ve added interaction terms, which absorb some degrees of freedom, there are fewer residual degrees of freedom left over. Specifically, note that if the model with interaction has a total of <span class="math inline">\((R\times C) - 1\)</span>, and there are <span class="math inline">\(N\)</span> observations in your data set that are constrained to satisfy 1 grand mean, your residual degrees of freedom now become <span class="math inline">\(N-(R \times C)-1+1\)</span>, or just <span class="math inline">\(N-(R \times C)\)</span>.</p>
</div>
<div id="running-the-anova-in-r" class="section level3">
<h3><span class="header-section-number">16.2.4</span> Running the ANOVA in R</h3>
<p>Adding interaction terms to the ANOVA model in R is straightforward. Returning to our running example of the clinical trial, in addition to the main effect terms of <code>drug</code> and <code>therapy</code>, we include the interaction term <code>drug:therapy</code>. So the R command to create the ANOVA model now looks like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> model.<span class="dv">3</span> &lt;-<span class="st"> </span><span class="kw">aov</span>( mood.gain <span class="op">~</span><span class="st"> </span>drug <span class="op">+</span><span class="st"> </span>therapy <span class="op">+</span><span class="st"> </span>drug<span class="op">:</span>therapy, clin.trial )</code></pre></div>
<p>However, R allows a convenient shorthand. Instead of typing out all three terms, you can shorten the right hand side of the formula to <code>drug*therapy</code>. The <code>*</code> operator inside the formula is taken to indicate that you want both main effects and the interaction. So we can also run our ANOVA like this, and get the same answer:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> model.<span class="dv">3</span> &lt;-<span class="st"> </span><span class="kw">aov</span>( mood.gain <span class="op">~</span><span class="st"> </span>drug <span class="op">*</span><span class="st"> </span>therapy, clin.trial )
 <span class="kw">summary</span>( model.<span class="dv">3</span> )</code></pre></div>
<pre><code>##              Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## drug          2  3.453  1.7267  31.714 1.62e-05 ***
## therapy       1  0.467  0.4672   8.582   0.0126 *  
## drug:therapy  2  0.271  0.1356   2.490   0.1246    
## Residuals    12  0.653  0.0544                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>As it turns out, while we do have a significant main effect of drug (<span class="math inline">\(F_{2,12} = 31.7, p &lt;.001\)</span>) and therapy type (<span class="math inline">\(F_{1,12} = 8.6, p=.013\)</span>), there is no significant interaction between the two (<span class="math inline">\(F_{2,12} = 2.5, p = 0.125\)</span>).</p>
</div>
<div id="interpreting-the-results" class="section level3">
<h3><span class="header-section-number">16.2.5</span> Interpreting the results</h3>
<p>There’s a couple of very important things to consider when interpreting the results of factorial ANOVA. Firstly, there’s the same issue that we had with one-way ANOVA, which is that if you obtain a significant main effect of (say) <code>drug</code>, it doesn’t tell you anything about which drugs are different to one another. To find that out, you need to run additional analyses. We’ll talk about some analyses that you can run in Sections <a href="anova2.html#contrasts">16.7</a> and <a href="#sec:posthoc2"><strong>??</strong></a>. The same is true for interaction effects: knowing that there’s a significant interaction doesn’t tell you anything about what kind of interaction exists. Again, you’ll need to run additional analyses.</p>
<p>Secondly, there’s a very peculiar interpretation issue that arises when you obtain a significant interaction effect but no corresponding main effect. This happens sometimes. For instance, in the crossover interaction shown in Figure <a href="#fig:interactiona"><strong>??</strong></a>, this is exactly what you’d find: in this case, neither of the main effects would be significant, but the interaction effect would be. This is a difficult situation to interpret, and people often get a bit confused about it. The general advice that statisticians like to give in this situation is that you shouldn’t pay much attention to the main effects when an interaction is present. The reason they say this is that, although the tests of the main effects are perfectly valid from a mathematical point of view, when there is a significant interaction effect the main effects rarely test interesting hypotheses. Recall from Section <a href="anova2.html#factanovahyp">16.1.1</a> that the null hypothesis for a main effect is that the <em>marginal means</em> are equal to each other, and that a marginal mean is formed by averaging across several different groups. But if you have a significant interaction effect, then you <em>know</em> that the groups that comprise the marginal mean aren’t homogeneous, so it’s not really obvious why you would even care about those marginal means.</p>
<p>Here’s what I mean. Again, let’s stick with a clinical example. Suppose that we had a <span class="math inline">\(2 \times 2\)</span> design comparing two different treatments for phobias (e.g., systematic desensitisation vs flooding), and two different anxiety reducing drugs (e.g., Anxifree vs Joyzepam). Now suppose what we found was that Anxifree had no effect when desensitisation was the treatment, and Joyzepam had no effect when flooding was the treatment. But both were pretty effective for the other treatment. This is a classic crossover interaction, and what we’d find when running the ANOVA is that there is no main effect of drug, but a significant interaction. Now, what does it actually <em>mean</em> to say that there’s no main effect? Wel, it means that, if we average over the two different psychological treatments, then the <em>average</em> effect of Anxifree and Joyzepam is the same. But why would anyone care about that? When treating someone for phobias, it is never the case that a person can be treated using an “average” of flooding and desensitisation: that doesn’t make a lot of sense. You either get one or the other. For one treatment, one drug is effective; and for the other treatment, the other drug is effective. The interaction is the important thing; the main effect is kind of irrelevant.</p>
<p>This sort of thing happens a lot: the main effect are tests of marginal means, and when an interaction is present we often find ourselves not being terribly interested in marginal means, because they imply averaging over things that the interaction tells us shouldn’t be averaged! Of course, it’s not always the case that a main effect is meaningless when an interaction is present. Often you can get a big main effect and a very small interaction, in which case you can still say things like “drug A is generally more effective than drug B” (because there was a big effect of drug), but you’d need to modify it a bit by adding that “the difference in effectiveness was different for different psychological treatments”. In any case, the main point here is that whenever you get a significant interaction you should stop and <em>think</em> about what the main effect actually means in this context. Don’t automatically assume that the main effect is interesting.</p>
</div>
</div>
<div id="effectsizefactorialanova" class="section level2">
<h2><span class="header-section-number">16.3</span> Effect size, estimated means, and confidence intervals</h2>
<p>In this section I’ll discuss a few additional quantities that you might find yourself wanting to calculate for a factorial ANOVA. The main thing you will probably want to calculate is the effect size for each term in your model, but you may also want to R to give you some estimates for the group means and associated confidence intervals.</p>
<div id="effect-sizes" class="section level3">
<h3><span class="header-section-number">16.3.1</span> Effect sizes</h3>
<p>The effect size calculations for a factorial ANOVA is pretty similar to those used in one way ANOVA (see Section <a href="anova.html#etasquared">14.4</a>). Specifically, we can use <span class="math inline">\(\eta^2\)</span> (eta-squared) as simple way to measure how big the overall effect is for any particular term. As before, <span class="math inline">\(\eta^2\)</span> is defined by dividing the sum of squares associated with that term by the total sum of squares. For instance, to determine the size of the main effect of Factor A, we would use the following formula <span class="math display">\[
\eta_A^2 = \frac{\mbox{SS}_{A}}{\mbox{SS}_{T}}
\]</span> As before, this can be interpreted in much the same way as <span class="math inline">\(R^2\)</span> in regression.<a href="#fn235" class="footnoteRef" id="fnref235"><sup>235</sup></a> It tells you the proportion of variance in the outcome variable that can be accounted for by the main effect of Factor A. It is therefore a number that ranges from 0 (no effect at all) to 1 (accounts for <em>all</em> of the variability in the outcome). Moreover, the sum of all the <span class="math inline">\(\eta^2\)</span> values, taken across all the terms in the model, will sum to the the total <span class="math inline">\(R^2\)</span> for the ANOVA model. If, for instance, the ANOVA model fits perfectly (i.e., there is no within-groups variability at all!), the <span class="math inline">\(\eta^2\)</span> values will sum to 1. Of course, that rarely if ever happens in real life.</p>
<p>However, when doing a factorial ANOVA, there is a second measure of effect size that people like to report, known as partial <span class="math inline">\(\eta^2\)</span>. The idea behind partial <span class="math inline">\(\eta^2\)</span> (which is sometimes denoted <span class="math inline">\(_p\eta^2\)</span> or <span class="math inline">\(\eta^2_p\)</span>) is that, when measuring the effect size for a particular term (say, the main effect of Factor A), you want to deliberately ignore the other effects in the model (e.g., the main effect of Factor B). That is, you would pretend that the effect of all these other terms is zero, and then calculate what the <span class="math inline">\(\eta^2\)</span> value would have been. This is actually pretty easy to calculate. All you have to do is remove the sum of squares associated with the other terms from the denominator. In other words, if you want the partial <span class="math inline">\(\eta^2\)</span> for the main effect of Factor A, the denominator is just the sum of the SS values for Factor A and the residuals: <span class="math display">\[
\mbox{partial } \eta^2_A = \frac{\mbox{SS}_{A}}{\mbox{SS}_{A} + \mbox{SS}_{R}}
\]</span> This will always give you a larger number than <span class="math inline">\(\eta^2\)</span>, which the cynic in me suspects accounts for the popularity of partial <span class="math inline">\(\eta^2\)</span>. And once again you get a number between 0 and 1, where 0 represents no effect. However, it’s slightly trickier to interpret what a large partial <span class="math inline">\(\eta^2\)</span> value means. In particular, you can’t actually compare the partial <span class="math inline">\(\eta^2\)</span> values across terms! Suppose, for instance, there is no within-groups variability at all: if so, SS<span class="math inline">\(_R = 0\)</span>. What that means is that <em>every</em> term has a partial <span class="math inline">\(\eta^2\)</span> value of 1. But that doesn’t mean that all terms in your model are equally important, or indeed that they are equally large. All it mean is that all terms in your model have effect sizes that are large <em>relative to the residual variation</em>. It is not comparable across terms.</p>
<p>To see what I mean by this, it’s useful to see a concrete example. Once again, we’ll use the <code>etaSquared()</code> function from the <code>lsr</code> package. As before, we input the <code>aov</code> object for which we want the <span class="math inline">\(\eta^2\)</span> calculations performed, and R outputs a matrix showing the effect sizes for each term in the model. First, let’s have a look at the effect sizes for the original ANOVA without the interaction term:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">etaSquared</span>( model.<span class="dv">2</span> )</code></pre></div>
<pre><code>##            eta.sq eta.sq.part
## drug    0.7127623   0.7888325
## therapy 0.0964339   0.3357285</code></pre>
<p>Looking at the <span class="math inline">\(\eta^2\)</span> values first, we see that <code>drug</code> accounts for 71.3% of the variance (i.e. <span class="math inline">\(\eta^2 = 0.713\)</span>) in <code>mood.gain</code>, whereas <code>therapy</code> only accounts for 9.6%. This leaves a total of 19.1% of the variation unaccounted for (i.e., the residuals constitute 19.1% of the variation in the outcome). Overall, this implies that we have a very large effect<a href="#fn236" class="footnoteRef" id="fnref236"><sup>236</sup></a> of <code>drug</code> and a modest effect of <code>therapy</code>.</p>
<p>Now let’s look at the partial <span class="math inline">\(\eta^2\)</span> values. Because the effect of <code>therapy</code> isn’t all that large, controlling for it doesn’t make much of a difference, so the partial <span class="math inline">\(\eta^2\)</span> for <code>drug</code> doesn’t increase very much, and we obtain a value of <span class="math inline">\(_p\eta^2 = 0.789\)</span>). In contrast, because the effect of <code>drug</code> was very large, controlling for it makes a big difference, and so when we calculate the partial <span class="math inline">\(\eta^2\)</span> for <code>therapy</code> you can see that it rises to <span class="math inline">\(_p\eta^2 = 0.336\)</span>. The question that we have to ask ourselves is, what does these partial <span class="math inline">\(\eta^2\)</span> values actually <em>mean</em>? The way I generally interpret the partial <span class="math inline">\(\eta^2\)</span> for the main effect of Factor A is to interpret it as a statement about a hypothetical experiment in which <em>only</em> Factor A was being varied. So, even though in <em>this</em> experiment we varied both A and B, we can easily imagine an experiment in which only Factor A was varied: the partial <span class="math inline">\(\eta^2\)</span> statistic tells you how much of the variance in the outcome variable you would expect to see accounted for in that experiment. However, it should be noted that this interpretation – like many things associated with main effects – doesn’t make a lot of sense when there is a large and significant interaction effect.</p>
<p>Speaking of interaction effects, here’s what we get when we calculate the effect sizes for the model that includes the interaction term. As you can see, the <span class="math inline">\(\eta^2\)</span> values for the main effects don’t change, but the partial <span class="math inline">\(\eta^2\)</span> values do:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">etaSquared</span>( model.<span class="dv">3</span> )</code></pre></div>
<pre><code>##                  eta.sq eta.sq.part
## drug         0.71276230   0.8409091
## therapy      0.09643390   0.4169559
## drug:therapy 0.05595689   0.2932692</code></pre>
</div>
<div id="estimated-group-means" class="section level3">
<h3><span class="header-section-number">16.3.2</span> Estimated group means</h3>
<p>In many situations you will find yourself wanting to report estimates of all the group means based on the results of your ANOVA, as well as confidence intervals associated with them. You can use the <code>effect()</code> function in the <code>effects</code> package to do this (don’t forget to install the package if you don’t have it already!). If the ANOVA that you have run is a <strong><em>saturated model</em></strong> (i.e., contains all possible main effects and all possible interaction effects) then the estimates of the group means are actually identical to the sample means, though the confidence intervals will use a pooled estimate of the standard errors, rather than use a separate one for each group. To illustrate this, let’s apply the <code>effect()</code> function to our saturated model (i.e., <code>model.3</code>) for the clinical trial data. The <code>effect()</code> function contains two arguments we care about: the <code>term</code> argument specifies what terms in the model we want the means to be calculated for, and the <code>mod</code> argument specifies the model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">library</span>(effects)
 eff &lt;-<span class="st"> </span><span class="kw">effect</span>( <span class="dt">term =</span> <span class="st">&quot;drug*therapy&quot;</span>, <span class="dt">mod =</span> model.<span class="dv">3</span> )
 eff</code></pre></div>
<pre><code>## 
##  drug*therapy effect
##           therapy
## drug       no.therapy      CBT
##   placebo    0.300000 0.600000
##   anxifree   0.400000 1.033333
##   joyzepam   1.466667 1.500000</code></pre>
<p>Notice that these are actually the same numbers we got when computing the sample means earlier (i.e., the <code>group.means</code> variable that we computed using <code>aggregate()</code>). One useful thing that we can do using the effect variable <code>eff</code>, however, is extract the confidence intervals using the <code>summary()</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">summary</span>(eff)</code></pre></div>
<pre><code>## 
##  drug*therapy effect
##           therapy
## drug       no.therapy      CBT
##   placebo    0.300000 0.600000
##   anxifree   0.400000 1.033333
##   joyzepam   1.466667 1.500000
## 
##  Lower 95 Percent Confidence Limits
##           therapy
## drug        no.therapy       CBT
##   placebo  0.006481093 0.3064811
##   anxifree 0.106481093 0.7398144
##   joyzepam 1.173147759 1.2064811
## 
##  Upper 95 Percent Confidence Limits
##           therapy
## drug       no.therapy       CBT
##   placebo   0.5935189 0.8935189
##   anxifree  0.6935189 1.3268522
##   joyzepam  1.7601856 1.7935189</code></pre>
<p>In this output, we see that the estimated mean mood gain for the placebo group with no therapy was 0.300, with a 95% confidence interval from 0.006 to 0.594. Note that these are not the same confidence intervals that you would get if you calculated them separately for each group, because of the fact that the ANOVA model assumes homogeneity of variance and therefore uses a pooled estimate of the standard deviation.</p>
<p>When the model doesn’t contain the interaction term, then the estimated group means will be different from the sample means. Instead of reporting the sample mean, the <code>effect()</code> function will calculate the value of the group means that would be expected on the basis of the marginal means (i.e., assuming no interaction). Using the notation we developed earlier, the estimate reported for <span class="math inline">\(\mu_{rc}\)</span>, the mean for level <span class="math inline">\(r\)</span> on the (row) Factor A and level <span class="math inline">\(c\)</span> on the (column) Factor B would be <span class="math inline">\(\mu_{..} + \alpha_r + \beta_c\)</span>. If there are genuinely no interactions between the two factors, this is actually a better estimate of the population mean than the raw sample mean would be. The command to obtain these estimates is actually identical to the last one, except that we use <code>model.2</code>. When you do this, R will give you a warning message:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> eff &lt;-<span class="st"> </span><span class="kw">effect</span>( <span class="st">&quot;drug*therapy&quot;</span>, model.<span class="dv">2</span> )</code></pre></div>
<pre><code>## NOTE: drug:therapy does not appear in the model</code></pre>
<p>but this isn’t anything to worry about. This is R being polite, and letting you know that the estimates it is constructing are based on the assumption that no interactions exist. It kind of makes sense that it would do this: when we use <code>&quot;drug*therapy&quot;</code> as our input, we’re telling R that we want it to output the estimated group means (rather than marginal means), but the actual input <code>&quot;drug*therapy&quot;</code> might mean that you want interactions included or you might not. There’s no <em>actual</em> ambiguity here, because the model itself either does or doesn’t have interactions, but the authors of the function thought it sensible to include a warning just to make sure that you’ve specified the actual model you care about. But, assuming that we genuinely don’t believe that there are any interactions, <code>model.2</code> is the right model to use, so we can ignore this warning.<a href="#fn237" class="footnoteRef" id="fnref237"><sup>237</sup></a> In any case, when we inspect the output, we get the following table of estimated group means:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> eff</code></pre></div>
<pre><code>## 
##  drug*therapy effect
##           therapy
## drug       no.therapy       CBT
##   placebo   0.2888889 0.6111111
##   anxifree  0.5555556 0.8777778
##   joyzepam  1.3222222 1.6444444</code></pre>
<p>As before, we can obtain confidence intervals using the following command:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">summary</span>( eff )</code></pre></div>
<pre><code>## 
##  drug*therapy effect
##           therapy
## drug       no.therapy       CBT
##   placebo   0.2888889 0.6111111
##   anxifree  0.5555556 0.8777778
##   joyzepam  1.3222222 1.6444444
## 
##  Lower 95 Percent Confidence Limits
##           therapy
## drug       no.therapy       CBT
##   placebo  0.02907986 0.3513021
##   anxifree 0.29574653 0.6179687
##   joyzepam 1.06241319 1.3846354
## 
##  Upper 95 Percent Confidence Limits
##           therapy
## drug       no.therapy       CBT
##   placebo   0.5486979 0.8709201
##   anxifree  0.8153646 1.1375868
##   joyzepam  1.5820313 1.9042535</code></pre>
<p>but the output looks pretty much the same as last time, and this book is already way too long, so I won’t include it here.</p>
</div>
</div>
<div id="factorialanovaassumptions" class="section level2">
<h2><span class="header-section-number">16.4</span> Assumption checking</h2>
<p>As with one-way ANOVA, the key assumptions of factorial ANOVA are homogeneity of variance (all groups have the same standard deviation), normality of the residuals, and independence of the observations. The first two are things we can test for. The third is something that you need to assess yourself by asking if there are any special relationships between different observations. Additionally, if you aren’t using a saturated model (e.g., if you’ve omitted the interaction terms) then you’re also assuming that the omitted terms aren’t important. Of course, you can check this last one by running an ANOVA with the omitted terms included and see if they’re significant, so that’s pretty easy. What about homogeneity of variance and normality of the residuals? As it turns out, these are pretty easy to check: it’s no different to the checks we did for a one-way ANOVA.</p>
<div id="levene-test-for-homogeneity-of-variance" class="section level3">
<h3><span class="header-section-number">16.4.1</span> Levene test for homogeneity of variance</h3>
<p>To test whether the groups have the same variance, we can use the Levene test. The theory behind the Levene test was discussed in Section <a href="anova.html#levene">14.7</a>, so I won’t discuss it again. Once again, you can use the <code>leveneTest()</code> function in the <code>car</code> package to do this. This function expects that you have a saturated model (i.e., included all of the relevant terms), because the test is primarily concerned with the within-group variance, and it doesn’t really make a lot of sense to calculate this any way other than with respect to the full model. So we try either of the following commands:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">leveneTest</span>( model.<span class="dv">2</span> )
 <span class="kw">leveneTest</span>( mood.gain <span class="op">~</span><span class="st"> </span>drug <span class="op">+</span><span class="st"> </span>therapy, clin.trial )</code></pre></div>
<p>R will spit out the following error:</p>
<pre><code>Error in leveneTest.formula(formula(y), data = model.frame(y), ...) : 
  Model must be completely crossed formula only.</code></pre>
<p>Instead, if you want to run the Levene test, you need to specify a saturated model. Either of the following two commands would work:<a href="#fn238" class="footnoteRef" id="fnref238"><sup>238</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(car)
 <span class="kw">leveneTest</span>( model.<span class="dv">3</span> )</code></pre></div>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = median)
##       Df F value Pr(&gt;F)
## group  5  0.0955 0.9912
##       12</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">leveneTest</span>( mood.gain <span class="op">~</span><span class="st"> </span>drug <span class="op">*</span><span class="st"> </span>therapy, clin.trial )</code></pre></div>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = median)
##       Df F value Pr(&gt;F)
## group  5  0.0955 0.9912
##       12</code></pre>
<p>The fact that the Levene test is non-significant means that we can safely assume that the homogeneity of variance assumption is not violated.</p>
</div>
<div id="normality-of-residuals" class="section level3">
<h3><span class="header-section-number">16.4.2</span> Normality of residuals</h3>
<p>As with one-way ANOVA, we can test for the normality of residuals in a straightforward fashion (see Section <a href="anova.html#anovanormality">14.9</a>). First, we use the <code>residuals()</code> function to extract the residuals from the model itself, and then we can examine those residuals in a few different ways. It’s generally a good idea to examine them graphically, by drawing histograms (i.e., <code>hist()</code> function) and QQ plots (i.e., <code>qqnorm()</code> function. If you want a formal test for the normality of the residuals, then we can run the Shapiro-Wilk test (i.e., <code>shapiro.test()</code>). If we wanted to check the residuals with respect to <code>model.2</code> (i.e., the model with both main effects but no interactions) then we could do the following:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> resid &lt;-<span class="st"> </span><span class="kw">residuals</span>( model.<span class="dv">2</span> )  <span class="co"># pull the residuals</span>
 <span class="kw">hist</span>( resid )                  <span class="co"># draw a histogram</span></code></pre></div>
<p><img src="lsr_files/figure-html/unnamed-chunk-743-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">qqnorm</span>( resid )                <span class="co"># draw a normal QQ plot</span></code></pre></div>
<p><img src="lsr_files/figure-html/unnamed-chunk-743-2.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">shapiro.test</span>( resid )          <span class="co"># run the Shapiro-Wilk test</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  resid
## W = 0.95635, p-value = 0.5329</code></pre>
<p>I haven’t included the plots (you can draw them yourself if you want to see them), but you can see from the non-significance of the Shapiro-Wilk test that normality isn’t violated here.</p>
</div>
</div>
<div id="omnibusF" class="section level2">
<h2><span class="header-section-number">16.5</span> The <span class="math inline">\(F\)</span> test as a model comparison</h2>
<p>At this point, I want to talk in a little more detail about what the <span class="math inline">\(F\)</span>-tests in an ANOVA are actually doing. In the context of ANOVA, I’ve been referring to the <span class="math inline">\(F\)</span>-test as a way of testing whether a particular term in the model (e.g., main effect of Factor A) is significant. This interpretation is perfectly valid, but it’s not necessarily the most useful way to think about the test. In fact, it’s actually a fairly limiting way of thinking about what the <span class="math inline">\(F\)</span>-test does. Consider the clinical trial data we’ve been working with in this chapter. Suppose I want to see if there are <em>any</em> effects of any kind that involve <code>therapy</code>. I’m not fussy: I don’t care if it’s a main effect or an interaction effect.<a href="#fn239" class="footnoteRef" id="fnref239"><sup>239</sup></a> One thing I could do is look at the output for <code>model.3</code> earlier: in this model we did see a main effect of therapy (<span class="math inline">\(p=.013\)</span>) but we did not see an interaction effect (<span class="math inline">\(p=.125\)</span>). That’s kind of telling us what we want to know, but it’s not quite the same thing. What we really want is a single test that <em>jointly</em> checks the main effect of therapy and the interaction effect.</p>
<p>Given the way that I’ve been describing the ANOVA <span class="math inline">\(F\)</span>-test up to this point, you’d be tempted to think that this isn’t possible. On the other hand, if you recall the chapter on regression (in Section <a href="regression.html#modelselreg">15.10</a>), we were able to use <span class="math inline">\(F\)</span>-tests to make comparisons between a wide variety of regression models. Perhaps something of that sort is possible with ANOVA? And of course, the answer here is yes. The thing that you really need to understand is that the <span class="math inline">\(F\)</span>-test, as it is used in both ANOVA and regression, is really a comparison of <em>two</em> statistical models. One of these models is the full model (alternative hypothesis), and the other model is a simpler model that is missing one or more of the terms that the full model includes (null hypothesis). The null model cannot contain any terms that are not in the full model. In the example I gave above, the full model is <code>model.3</code>, and it contains a main effect for therapy, a main effect for drug, and the drug by therapy interaction term. The null model would be <code>model.1</code> since it contains only the main effect of drug.</p>
<div id="the-f-test-comparing-two-models" class="section level3">
<h3><span class="header-section-number">16.5.1</span> The <span class="math inline">\(F\)</span> test comparing two models</h3>
<p>Let’s frame this in a slightly more abstract way. We’ll say that our full model can be written as an R formula that contains several different terms, say <code>Y ~ A + B + C + D</code>. Our null model only contains some subset of these terms, say <code>Y ~ A + B</code>. Some of these terms might be main effect terms, others might be interaction terms. It really doesn’t matter. The only thing that matters here is that we want to treat some of these terms as the “starting point” (i.e. the terms in the null model, <code>A</code> and <code>B</code>), and we want to see if including the other terms (i.e., <code>C</code> and <code>D</code>) leads to a significant improvement in model performance, over and above what could be achieved by a model that includes only <code>A</code> and <code>B</code>. In essence, we have null and alternative hypotheses that look like this:</p>
<table>
<thead>
<tr class="header">
<th align="left">Hypothesis</th>
<th align="left">Correct model?</th>
<th align="left">R formula for correct model</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Null</td>
<td align="left"><span class="math inline">\(M0\)</span></td>
<td align="left"><code>Y ~ A + B</code></td>
</tr>
<tr class="even">
<td align="left">Alternative</td>
<td align="left"><span class="math inline">\(M1\)</span></td>
<td align="left"><code>Y ~ A + B + C + D</code></td>
</tr>
</tbody>
</table>
<p>Is there a way of making this comparison directly?</p>
<p>To answer this, let’s go back to fundamentals. As we saw in Chapter <a href="anova.html#anova">14</a>, the <span class="math inline">\(F\)</span>-test is constructed from two kinds of quantity: sums of squares (SS) and degrees of freedom (df). These two things define a mean square value (MS = SS/df), and we obtain our <span class="math inline">\(F\)</span> statistic by contrasting the MS value associated with “the thing we’re interested in” (the model) with the MS value associated with “everything else” (the residuals). What we want to do is figure out how to talk about the SS value that is associated with the <em>difference</em> between two models. It’s actually not all that hard to do.</p>
<p>Let’s start with the fundamental rule that we used throughout the chapter on regression: <span class="math display">\[
\mbox{SS}_{T} = \mbox{SS}_{M} + \mbox{SS}_{R} 
\]</span> That is, the total sums of squares (i.e., the overall variability of the outcome variable) can be decomposed into two parts: the variability associated with the model <span class="math inline">\(\mbox{SS}_{M}\)</span>, and the residual or leftover variability, <span class="math inline">\(\mbox{SS}_{R}\)</span>. However, it’s kind of useful to rearrange this equation slightly, and say that the SS value associated with a model is defined like this… <span class="math display">\[
\mbox{SS}_{M} = \mbox{SS}_{T} - \mbox{SS}_{R} 
\]</span> Now, in our scenario, we have two models: the null model (M0) and the full model (M1):</p>
<p><span class="math display">\[
\mbox{SS}_{M0} = \mbox{SS}_{T} - \mbox{SS}_{R0}
\]</span></p>
<p><span class="math display">\[
\mbox{SS}_{M1} = \mbox{SS}_{T} - \mbox{SS}_{R1} 
\]</span> Next, let’s think about what it is we <em>actually</em> care about here. What we’re interested in is the <em>difference</em> between the full model and the null model. So, if we want to preserve the idea that what we’re doing is an “analysis of the variance” (ANOVA) in the outcome variable, what we should do is define the SS associated with the difference to be equal to the difference in the SS: <span class="math display">\[
\begin{array}
\mbox{SS}_{\Delta} &amp;=&amp; \mbox{SS}_{M1} - \mbox{SS}_{M0}\\
&amp;=&amp; (\mbox{SS}_{T} - \mbox{SS}_{R1}) - (\mbox{SS}_{T} - \mbox{SS}_{R0} ) \\
&amp;=&amp; \mbox{SS}_{R0} - \mbox{SS}_{R1}
\end{array}
\]</span></p>
<p>Now that we have our degrees of freedom, we can calculate mean squares and <span class="math inline">\(F\)</span> values in the usual way. Specifically, we’re interested in the mean square for the difference between models, and the mean square for the residuals associated with the <em>full</em> model (M1), which are given by <span class="math display">\[
\begin{array}
\mbox{MS}_{\Delta} &amp;=&amp; \frac{\mbox{SS}_{\Delta} }{ \mbox{df}_{\Delta} } \\
\mbox{MS}_{R1} &amp;=&amp; \frac{ \mbox{SS}_{R1} }{  \mbox{df}_{R1} }\\
\end{array}
\]</span> Finally, taking the ratio of these two gives us our <span class="math inline">\(F\)</span> statistic: <span class="math display">\[
F = \frac\mbox{MS}_{\Delta}\mbox{MS}_{R1}
\]</span> ### Running the test in R</p>
<p>At this point, it may help to go back to our concrete example. The null model here is <code>model.1</code>, which stipulates that there is a main effect of drug, but no other effects exist. We expressed this via the model formula <code>mood.gain ~ drug</code>. The alternative model here is <code>model.3</code>, which stipulates that there is a main effect of drug, a main effect of therapy, <em>and</em> an interaction. If we express this in the “long” format, this model corresponds to the formula <code>mood.gain ~ drug + therapy + drug:therapy</code>, though we often express this using the <code>*</code> shorthand. The key thing here is that if we compare <code>model.1</code> to <code>model.3</code>, we’re lumping the main effect of therapy and the interaction term together. Running this test in R is straightforward: we just input both models to the <code>anova()</code> function, and it will run the exact <span class="math inline">\(F\)</span>-test that I outlined above.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">anova</span>( model.<span class="dv">1</span>, model.<span class="dv">3</span> )</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: mood.gain ~ drug
## Model 2: mood.gain ~ drug * therapy
##   Res.Df     RSS Df Sum of Sq      F  Pr(&gt;F)  
## 1     15 1.39167                              
## 2     12 0.65333  3   0.73833 4.5204 0.02424 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Let’s see if we can reproduce this <span class="math inline">\(F\)</span>-test ourselves. Firstly, if you go back and look at the ANOVA tables that we printed out for <code>model.1</code> and <code>model.3</code> you can reassure yourself that the RSS values printed in this table really do correspond to the residual sum of squares associated with these two models. So let’s type them in as variables:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> ss.res.null &lt;-<span class="st"> </span><span class="fl">1.392</span>
 ss.res.full &lt;-<span class="st"> </span><span class="fl">0.653</span></code></pre></div>
<p>Now, following the procedure that I described above, we will say that the “between model” sum of squares, is the difference between these two residual sum of squares values. So, if we do the subtraction, we discover that the sum of squares associated with those terms that appear in the full model but not the null model is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> ss.diff &lt;-<span class="st"> </span>ss.res.null <span class="op">-</span><span class="st"> </span>ss.res.full 
 ss.diff</code></pre></div>
<pre><code>## [1] 0.739</code></pre>
<p>Right. Next, as always we need to convert these SS values into MS (mean square) values, which we do by dividing by the degrees of freedom. The degrees of freedom associated with the full-model residuals hasn’t changed from our original ANOVA for <code>model.3</code>: it’s the total sample size <span class="math inline">\(N\)</span>, minus the total number of groups <span class="math inline">\(G\)</span> that are relevant to the model. We have 18 people in the trial and 6 possible groups (i.e., 2 therapies <span class="math inline">\(\times\)</span> 3 drugs), so the degrees of freedom here is 12. The degrees of freedom for the null model are calculated similarly. The only difference here is that there are only 3 relevant groups (i.e., 3 drugs), so the degrees of freedom here is 15. And, because the degrees of freedom associated with the difference is equal to the difference in the two degrees of freedom, we arrive at the conclusion that we have <span class="math inline">\(15-12 = 3\)</span> degrees of freedom. Now that we know the degrees of freedom, we can calculate our MS values:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> ms.res &lt;-<span class="st"> </span>ss.res.full <span class="op">/</span><span class="st"> </span><span class="dv">12</span>
 ms.diff &lt;-<span class="st"> </span>ss.diff <span class="op">/</span><span class="st"> </span><span class="dv">3</span> </code></pre></div>
<p>Okay, now that we have our two MS values, we can divide one by the other, and obtain an <span class="math inline">\(F\)</span>-statistic …</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> F.stat &lt;-<span class="st"> </span>ms.diff <span class="op">/</span><span class="st"> </span>ms.res 
 F.stat</code></pre></div>
<pre><code>## [1] 4.526799</code></pre>
<p>… and, just as we had hoped, this turns out to be identical to the <span class="math inline">\(F\)</span>-statistic that the <code>anova()</code> function produced earlier.</p>
</div>
</div>
<div id="anovalm" class="section level2">
<h2><span class="header-section-number">16.6</span> ANOVA as a linear model</h2>
<p>One of the most important things to understand about ANOVA and regression is that they’re basically the same thing. On the surface of it, you wouldn’t think that this is true: after all, the way that I’ve described them so far suggests that ANOVA is primarily concerned with testing for group differences, and regression is primarily concerned with understanding the correlations between variables. And as far as it goes, that’s perfectly true. But when you look under the hood, so to speak, the underlying mechanics of ANOVA and regression are awfully similar. In fact, if you think about it, you’ve already seen evidence of this. ANOVA and regression both rely heavily on sums of squares (SS), both make use of <span class="math inline">\(F\)</span> tests, and so on. Looking back, it’s hard to escape the feeling that Chapters <a href="anova.html#anova">14</a> and <a href="regression.html#regression">15</a> were a bit repetitive.</p>
<p>The reason for this is that ANOVA and regression are both kinds of <strong><em>linear models</em></strong>. In the case of regression, this is kind of obvious. The regression equation that we use to define the relationship between predictors and outcomes <em>is</em> the equation for a straight line, so it’s quite obviously a linear model. And if that wasn’t a big enough clue, the simple fact that the command to run a regression is <code>lm()</code> is kind of a hint too. When we use an R formula like <code>outcome ~ predictor1 + predictor2</code> what we’re really working with is the somewhat uglier linear model: <span class="math display">\[
Y_{p} = b_1 X_{1p} + b_2 X_{2p} + b_0 + \epsilon_{p}
\]</span> where <span class="math inline">\(Y_p\)</span> is the outcome value for the <span class="math inline">\(p\)</span>-th observation (e.g., <span class="math inline">\(p\)</span>-th person), <span class="math inline">\(X_{1p}\)</span> is the value of the first predictor for the <span class="math inline">\(p\)</span>-th observation, <span class="math inline">\(X_{2p}\)</span> is the value of the second predictor for the <span class="math inline">\(p\)</span>-th observation, the <span class="math inline">\(b_1\)</span>, <span class="math inline">\(b_2\)</span> and <span class="math inline">\(b_0\)</span> terms are our regression coefficients, and <span class="math inline">\(\epsilon_{p}\)</span> is the <span class="math inline">\(p\)</span>-th residual. If we ignore the residuals <span class="math inline">\(\epsilon_{p}\)</span> and just focus on the regression line itself, we get the following formula: <span class="math display">\[
\hat{Y}_{p} = b_1 X_{1p} + b_2 X_{2p} + b_0
\]</span> where <span class="math inline">\(\hat{Y}_p\)</span> is the value of <span class="math inline">\(Y\)</span> that the regression line predicts for person <span class="math inline">\(p\)</span>, as opposed to the actually-observed value <span class="math inline">\(Y_p\)</span>. The thing that isn’t immediately obvious is that we can write ANOVA as a linear model as well. However, it’s actually pretty straightforward to do this. Let’s start with a really simple example: rewriting a <span class="math inline">\(2 \times 2\)</span> factorial ANOVA as a linear model.</p>
<div id="some-data" class="section level3">
<h3><span class="header-section-number">16.6.1</span> Some data</h3>
<p>To make things concrete, let’s suppose that our outcome variable is the <code>grade</code> that a student receives in my class, a ratio-scale variable corresponding to a mark from 0% to 100%. There are two predictor variables of interest: whether or not the student turned up to lectures (the <code>attend</code> variable), and whether or not the student actually read the textbook (the <code>reading</code> variable). We’ll say that <code>attend = 1</code> if the student attended class, and <code>attend = 0</code> if they did not. Similarly, we’ll say that <code>reading = 1</code> if the student read the textbook, and <code>reading = 0</code> if they did not.</p>
<p>Okay, so far that’s simple enough. The next thing we need to do is to wrap some maths around this (sorry!). For the purposes of this example, let <span class="math inline">\(Y_p\)</span> denote the <code>grade</code> of the <span class="math inline">\(p\)</span>-th student in the class. This is not quite the same notation that we used earlier in this chapter: previously, we’ve used the notation <span class="math inline">\(Y_{rci}\)</span> to refer to the <span class="math inline">\(i\)</span>-th person in the <span class="math inline">\(r\)</span>-th group for predictor 1 (the row factor) and the <span class="math inline">\(c\)</span>-th group for predictor 2 (the column factor). This extended notation was really handy for describing how the SS values are calculated, but it’s a pain in the current context, so I’ll switch notation here. Now, the <span class="math inline">\(Y_p\)</span> notation is visually simpler than <span class="math inline">\(Y_{rci}\)</span>, but it has the shortcoming that it doesn’t actually keep track of the group memberships! That is, if I told you that <span class="math inline">\(Y_{0,0,3} = 35\)</span>, you’d immediately know that we’re talking about a student (the 3rd such student, in fact) who didn’t attend the lectures (i.e., <code>attend = 0</code>) and didn’t read the textbook (i.e. <code>reading = 0</code>), and who ended up failing the class (<code>grade = 35</code>). But if I tell you that <span class="math inline">\(Y_p = 35\)</span> all you know is that the <span class="math inline">\(p\)</span>-th student didn’t get a good grade. We’ve lost some key information here. Of course, it doesn’t take a lot of thought to figure out how to fix this: what we’ll do instead is introduce two new variables <span class="math inline">\(X_{1p}\)</span> and <span class="math inline">\(X_{2p}\)</span> that keep track of this information. In the case of our hypothetical student, we know that <span class="math inline">\(X_{1p} = 0\)</span> (i.e., <code>attend = 0</code>) and <span class="math inline">\(X_{2p} = 0\)</span> (i.e., <code>reading = 0</code>). So the data might look like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
       <span class="op">~</span>V1,   <span class="op">~</span>V2,     <span class="op">~</span>V3,     <span class="op">~</span>V4,
       <span class="st">&quot;1&quot;</span>,  <span class="st">&quot;90&quot;</span>,     <span class="st">&quot;1&quot;</span>,     <span class="st">&quot;1&quot;</span>,
       <span class="st">&quot;2&quot;</span>,  <span class="st">&quot;87&quot;</span>,     <span class="st">&quot;1&quot;</span>,     <span class="st">&quot;1&quot;</span>,
       <span class="st">&quot;3&quot;</span>,  <span class="st">&quot;75&quot;</span>,     <span class="st">&quot;0&quot;</span>,     <span class="st">&quot;1&quot;</span>,
       <span class="st">&quot;4&quot;</span>,  <span class="st">&quot;60&quot;</span>,     <span class="st">&quot;1&quot;</span>,     <span class="st">&quot;0&quot;</span>,
       <span class="st">&quot;5&quot;</span>,  <span class="st">&quot;35&quot;</span>,     <span class="st">&quot;0&quot;</span>,     <span class="st">&quot;0&quot;</span>,
       <span class="st">&quot;6&quot;</span>,  <span class="st">&quot;50&quot;</span>,     <span class="st">&quot;0&quot;</span>,     <span class="st">&quot;0&quot;</span>,
       <span class="st">&quot;7&quot;</span>,  <span class="st">&quot;65&quot;</span>,     <span class="st">&quot;1&quot;</span>,     <span class="st">&quot;0&quot;</span>,
       <span class="st">&quot;8&quot;</span>,  <span class="st">&quot;70&quot;</span>,     <span class="st">&quot;0&quot;</span>,     <span class="st">&quot;1&quot;</span>), 
<span class="dt">col.names=</span> <span class="kw">c</span>(<span class="st">&quot;person $p$&quot;</span>, <span class="st">&quot;grade $Y_p$&quot;</span>, <span class="st">&quot;attendance $X_{1p}$&quot;</span>, <span class="st">&quot;reading $X_{2p}$&quot;</span>), <span class="dt">align =</span> <span class="st">&#39;cccc&#39;</span>)</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="center">person <span class="math inline">\(p\)</span></th>
<th align="center">grade <span class="math inline">\(Y_p\)</span></th>
<th align="center">attendance <span class="math inline">\(X_{1p}\)</span></th>
<th align="center">reading <span class="math inline">\(X_{2p}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">90</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">87</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">75</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">60</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">35</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">6</td>
<td align="center">50</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">7</td>
<td align="center">65</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">8</td>
<td align="center">70</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<p>This isn’t anything particularly special, of course: it’s exactly the format in which we expect to see our data! In other words, if your data have been stored as a data frame in R then you’re probably expecting to see something that looks like the <code>rtfm.1</code> data frame:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">load</span>(<span class="kw">file.path</span>(projecthome, <span class="st">&quot;data&quot;</span>,<span class="st">&quot;rtfm.Rdata&quot;</span>))
rtfm.<span class="dv">1</span></code></pre></div>
<pre><code>##   grade attend reading
## 1    90      1       1
## 2    87      1       1
## 3    75      0       1
## 4    60      1       0
## 5    35      0       0
## 6    50      0       0
## 7    65      1       0
## 8    70      0       1</code></pre>
<p>Well, sort of. I suspect that a few readers are probably frowning a little at this point. Earlier on in the book I emphasised the importance of converting nominal scale variables such as <code>attend</code> and <code>reading</code> to factors, rather than encoding them as numeric variables. The <code>rtfm.1</code> data frame doesn’t do this, but the <code>rtfm.2</code> data frame does, and so you might instead be expecting to see data like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> rtfm.<span class="dv">2</span></code></pre></div>
<pre><code>##   grade attend reading
## 1    90    yes     yes
## 2    87    yes     yes
## 3    75     no     yes
## 4    60    yes      no
## 5    35     no      no
## 6    50     no      no
## 7    65    yes      no
## 8    70     no     yes</code></pre>
<p>However, for the purposes of this section it’s important that we be able to switch back and forth between these two different ways of thinking about the data. After all, our goal in this section is to look at some of the mathematics that underpins ANOVA, and if we want to do that we need to be able to see the numerical representation of the data (in <code>rtfm.1</code>) as well as the more meaningful factor representation (in <code>rtfm.2</code>). In any case, we can use the <code>xtabs()</code> function to confirm that this data set corresponds to a balanced design</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">xtabs</span>( <span class="op">~</span><span class="st"> </span>attend <span class="op">+</span><span class="st"> </span>reading, rtfm.<span class="dv">2</span> )</code></pre></div>
<pre><code>##       reading
## attend no yes
##    no   2   2
##    yes  2   2</code></pre>
<p>For each possible combination of the <code>attend</code> and <code>reading</code> variables, we have exactly two students. If we’re interested in calculating the mean <code>grade</code> for each of these cells, we can use the <code>aggregate()</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">aggregate</span>( grade <span class="op">~</span><span class="st"> </span>attend <span class="op">+</span><span class="st"> </span>reading, rtfm.<span class="dv">2</span>, mean )</code></pre></div>
<pre><code>##   attend reading grade
## 1     no      no  42.5
## 2    yes      no  62.5
## 3     no     yes  72.5
## 4    yes     yes  88.5</code></pre>
<p>Looking at this table, one gets the strong impression that reading the text and attending the class both matter a lot.</p>
</div>
<div id="anova-with-binary-factors-as-a-regression-model" class="section level3">
<h3><span class="header-section-number">16.6.2</span> ANOVA with binary factors as a regression model</h3>
<p>Okay, let’s get back to talking about the mathematics. We now have our data expressed in terms of three numeric variables: the continuous variable <span class="math inline">\(Y\)</span>, and the two binary variables <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>. What I want to you to recognise is that our 2$$2 factorial ANOVA is <em>exactly</em> equivalent to the regression model <span class="math display">\[
Y_{p} = b_1 X_{1p} + b_2 X_{2p} + b_0 + \epsilon_p
\]</span> This is, of course, the exact same equation that I used earlier to describe a two-predictor regression model! The only difference is that <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are now <em>binary</em> variables (i.e., values can only be 0 or 1), whereas in a regression analysis we expect that <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> will be continuous. There’s a couple of ways I could try to convince you of this. One possibility would be to do a lengthy mathematical exercise, proving that the two are identical. However, I’m going to go out on a limb and guess that most of the readership of this book will find that to be annoying rather than helpful. Instead, I’ll explain the basic ideas, and then rely on R to show that that ANOVA analyses and regression analyses aren’t just similar, they’re identical for all intents and purposes.<a href="#fn240" class="footnoteRef" id="fnref240"><sup>240</sup></a> Let’s start by running this as an ANOVA. To do this, we’ll use the <code>rtfm.2</code> data frame, since that’s the one in which I did the proper thing of coding <code>attend</code> and <code>reading</code> as factors, and I’ll use the <code>aov()</code> function to do the analysis. Here’s what we get…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> anova.model &lt;-<span class="st"> </span><span class="kw">aov</span>( grade <span class="op">~</span><span class="st"> </span>attend <span class="op">+</span><span class="st"> </span>reading, <span class="dt">data =</span> rtfm.<span class="dv">2</span> )
 <span class="kw">summary</span>( anova.model )    </code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value  Pr(&gt;F)    
## attend       1    648     648   21.60 0.00559 ** 
## reading      1   1568    1568   52.27 0.00079 ***
## Residuals    5    150      30                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>So, by reading the key numbers off the ANOVA table and the table of means that we presented earlier, we can see that the students obtained a higher grade if they attended class <span class="math inline">\((F_{1,5} = 26.1, p = .0056)\)</span> and if they read the textbook <span class="math inline">\((F_{1,5} = 52.3, p = .0008)\)</span>. Let’s make a note of those <span class="math inline">\(p\)</span>-values and those <span class="math inline">\(F\)</span> statistics.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">library</span>(effects)
 <span class="kw">Effect</span>( <span class="kw">c</span>(<span class="st">&quot;attend&quot;</span>,<span class="st">&quot;reading&quot;</span>), anova.model )</code></pre></div>
<pre><code>## 
##  attend*reading effect
##       reading
## attend   no  yes
##    no  43.5 71.5
##    yes 61.5 89.5</code></pre>
<p>Now let’s think about the same analysis from a linear regression perspective. In the <code>rtfm.1</code> data set, we have encoded <code>attend</code> and <code>reading</code> as if they were numeric predictors. In this case, this is perfectly acceptable. There really is a sense in which a student who turns up to class (i.e. <code>attend = 1</code>) has in fact done “more attendance” than a student who does not (i.e. <code>attend = 0</code>). So it’s not at all unreasonable to include it as a predictor in a regression model. It’s a little unusual, because the predictor only takes on two possible values, but it doesn’t violate any of the assumptions of linear regression. And it’s easy to interpret. If the regression coefficient for <code>attend</code> is greater than 0, it means that students that attend lectures get higher grades; if it’s less than zero, then students attending lectures get lower grades. The same is true for our <code>reading</code> variable.</p>
<p>Wait a second… <em>why</em> is this true? It’s something that is intuitively obvious to everyone who has taken a few stats classes and is comfortable with the maths, but it <em>isn’t</em> clear to everyone else at first pass. To see why this is true, it helps to look closely at a few specific students. Let’s start by considering the 6th and 7th students in our data set (i.e. <span class="math inline">\(p=6\)</span> and <span class="math inline">\(p=7\)</span>). Neither one has read the textbook, so in both cases we can set <code>reading = 0</code>. Or, to say the same thing in our mathematical notation, we observe <span class="math inline">\(X_{2,6} = 0\)</span> and <span class="math inline">\(X_{2,7} = 0\)</span>. However, student number 7 did turn up to lectures (i.e., <code>attend = 1</code>, <span class="math inline">\(X_{1,7} = 1\)</span>) whereas student number 6 did not (i.e., <code>attend = 0</code>, <span class="math inline">\(X_{1,6} = 0\)</span>). Now let’s look at what happens when we insert these numbers into the general formula for our regression line. For student number 6, the regression predicts that <span class="math display">\[
\begin{array}
\hat{Y}_{6} &amp;=&amp; b_1 X_{1,6} + b_2 X_{2,6} + b_0 \\
&amp;=&amp;  (b_1 \times 0)  + ( b_2 \times 0)  + b_0 \\
&amp;=&amp;  b_0
\end{array}
\]</span> So we’re expecting that this student will obtain a grade corresponding to the value of the intercept term <span class="math inline">\(b_0\)</span>. What about student 7? This time, when we insert the numbers into the formula for the regression line, we obtain the following: <span class="math display">\[
\begin{array}
\hat{Y}_{7} &amp;=&amp; b_1 X_{1,7} + b_2 X_{2,7} + b_0 \\
&amp;=&amp;  (b_1 \times 1)  + ( b_2 \times 0)  + b_0 \\
&amp;=&amp;  b_1 + b_0
\end{array}
\]</span> Because this student attended class, the predicted grade is equal to the intercept term <span class="math inline">\(b_0\)</span> <em>plus</em> the coefficient associated with the <code>attend</code> variable, <span class="math inline">\(b_1\)</span>. So, if <span class="math inline">\(b_1\)</span> is greater than zero, we’re expecting that the students who turn up to lectures will get higher grades than those students who don’t. If this coefficient is negative, we’re expecting the opposite: students who turn up at class end up performing much worse. In fact, we can push this a little bit further. What about student number 1, who turned up to class (<span class="math inline">\(X_{1,1} = 1\)</span>) <em>and</em> read the textbook (<span class="math inline">\(X_{2,1} = 1\)</span>)? If we plug these numbers into the regression, we get <span class="math display">\[
\begin{array}
\hat{Y}_{1} &amp;=&amp; b_1 X_{1,1} + b_2 X_{2,1} + b_0 \\
&amp;=&amp;  (b_1 \times 1)  + ( b_2 \times 1)  + b_0 \\
&amp;=&amp;  b_1 + b_2 + b_0
\end{array}
\]</span> So if we assume that attending class helps you get a good grade (i.e., <span class="math inline">\(b_1 &gt; 0\)</span>) and if we assume that reading the textbook also helps you get a good grade (i.e., <span class="math inline">\(b_2 &gt;0\)</span>), then our expectation is that student 1 will get a grade that that is higher than student 6 and student 7.</p>
<p>And at this point, you won’t be at all suprised to learn that the regression model predicts that student 3, who read the book but didn’t attend lectures, will obtain a grade of <span class="math inline">\(b_2 + b_0\)</span>. I won’t bore you with yet another regression formula. Instead, what I’ll do is show you the following table of <em>expected grades</em>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
               <span class="op">~</span>V1,           <span class="op">~</span>V2,   <span class="op">~</span>V3,   

   <span class="st">&quot;attended - no&quot;</span>,<span class="st">&quot;$b_0$&quot;</span>,<span class="st">&quot;$b_0 + b_2$&quot;</span>,   
  <span class="st">&quot;attended - yes&quot;</span>, <span class="st">&quot;$b_0 + b_1$&quot;</span>, <span class="st">&quot;$b_0 + b_1 + b_2$&quot;</span>),
  <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;&quot;</span>,<span class="st">&quot;read textbook? no&quot;</span>, <span class="st">&quot;read textbook? yes&quot;</span>))</code></pre></div>
<table>
<thead>
<tr class="header">
<th></th>
<th align="left">read textbook? no</th>
<th align="left">read textbook? yes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>attended - no</td>
<td align="left"><span class="math inline">\(b_0\)</span></td>
<td align="left"><span class="math inline">\(b_0 + b_2\)</span></td>
</tr>
<tr class="even">
<td>attended - yes</td>
<td align="left"><span class="math inline">\(b_0 + b_1\)</span></td>
<td align="left"><span class="math inline">\(b_0 + b_1 + b_2\)</span></td>
</tr>
</tbody>
</table>
<p>As you can see, the intercept term <span class="math inline">\(b_0\)</span> acts like a kind of “baseline” grade that you would expect from those students who don’t take the time to attend class or read the textbook. Similarly, <span class="math inline">\(b_1\)</span> represents the boost that you’re expected to get if you come to class, and <span class="math inline">\(b_2\)</span> represents the boost that comes from reading the textbook. In fact, if this were an ANOVA you might very well want to characterise <span class="math inline">\(b_1\)</span> as the main effect of attendance, and <span class="math inline">\(b_2\)</span> as the main effect of reading! In fact, for a simple <span class="math inline">\(2 \times 2\)</span> ANOVA that’s <em>exactly</em> how it plays out.</p>
<p>Okay, now that we’re really starting to see why ANOVA and regression are basically the same thing, let’s actually run our regression using the <code>rtfm.1</code> data and the <code>lm()</code> function to convince ourselves that this is really true. Running the regression in the usual way gives us the following output:<a href="#fn241" class="footnoteRef" id="fnref241"><sup>241</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> regression.model &lt;-<span class="st"> </span><span class="kw">lm</span>( grade <span class="op">~</span><span class="st"> </span>attend <span class="op">+</span><span class="st"> </span>reading, <span class="dt">data =</span> rtfm.<span class="dv">1</span> )
 <span class="kw">summary</span>( regression.model )</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = grade ~ attend + reading, data = rtfm.1)
## 
## Residuals:
##    1    2    3    4    5    6    7    8 
##  0.5 -2.5  3.5 -1.5 -8.5  6.5  3.5 -1.5 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   43.500      3.354  12.969 4.86e-05 ***
## attend        18.000      3.873   4.648  0.00559 ** 
## reading       28.000      3.873   7.230  0.00079 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.477 on 5 degrees of freedom
## Multiple R-squared:  0.9366, Adjusted R-squared:  0.9112 
## F-statistic: 36.93 on 2 and 5 DF,  p-value: 0.001012</code></pre>
<p>There’s a few interesting things to note here. Firstly, notice that the intercept term is 43.5, which is close to the “group” mean of 42.5 observed for those two students who didn’t read the text or attend class. Moreover, it’s <em>identical</em> to the predicted group mean that we pulled out of our ANOVA using the <code>Effects()</code> function! Secondly, notice that we have the regression coefficient of <span class="math inline">\(b_1 = 18.0\)</span> for the attendance variable, suggesting that those students that attended class scored 18% higher than those who didn’t. So our expectation would be that those students who turned up to class but didn’t read the textbook would obtain a grade of <span class="math inline">\(b_0 + b_1\)</span>, which is equal to <span class="math inline">\(43.5 + 18.0 = 61.5\)</span>. Again, this is similar to the observed group mean of 62.5, and identical to the expected group mean that we pulled from our ANOVA. You can verify for yourself that the same thing happens when we look at the students that read the textbook.</p>
<p>Actually, we can push a little further in establishing the equivalence of our ANOVA and our regression. Look at the <span class="math inline">\(p\)</span>-values associated with the <code>attend</code> variable and the <code>reading</code> variable in the regression output. They’re identical to the ones we encountered earlier when running the ANOVA. This might seem a little surprising, since the test used when running our regression model calculates a <span class="math inline">\(t\)</span>-statistic and the ANOVA calculates an <span class="math inline">\(F\)</span>-statistic. However, if you can remember all the way back to Chapter <a href="probability.html#probability">9</a>, I mentioned that there’s a relationship between the <span class="math inline">\(t\)</span>-distribution and the <span class="math inline">\(F\)</span>-distribution: if you have some quantity that is distributed according to a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(k\)</span> degrees of freedom and you square it, then this new squared quantity follows an <span class="math inline">\(F\)</span>-distribution whose degrees of freedom are 1 and <span class="math inline">\(k\)</span>. We can check this with respect to the <span class="math inline">\(t\)</span> statistics in our regression model. For the <code>attend</code> variable we get a <span class="math inline">\(t\)</span> value of 4.648. If we square this number we end up with 21.604, which is identical to the corresponding <span class="math inline">\(F\)</span> statistic in our ANOVA.</p>
<p>Finally, one last thing you should know. Because R understands the fact that ANOVA and regression are both examples of linear models, it lets you extract the classic ANOVA table from your regression model using the <code>anova()</code> function. All you have to do is this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">anova</span>( regression.model )</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: grade
##           Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## attend     1    648     648  21.600 0.0055943 ** 
## reading    1   1568    1568  52.267 0.0007899 ***
## Residuals  5    150      30                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="changingbaseline" class="section level3">
<h3><span class="header-section-number">16.6.3</span> Changing the baseline category</h3>
<p>At this point, you’re probably convinced that the ANOVA and the regression are actually identical to each other. So there’s one last thing I should show you. What happens if I use the data from <code>rtfm.2</code> to run the regression? In <code>rtfm.2</code>, we coded the <code>attend</code> and <code>reading</code> variables as factors rather than as numeric variables. Does this matter? It turns out that it doesn’t. The only differences are superficial:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> regression.model.<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">lm</span>( grade <span class="op">~</span><span class="st"> </span>attend <span class="op">+</span><span class="st"> </span>reading, <span class="dt">data =</span> rtfm.<span class="dv">2</span> )
 <span class="kw">summary</span>( regression.model.<span class="dv">2</span> )</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = grade ~ attend + reading, data = rtfm.2)
## 
## Residuals:
##    1    2    3    4    5    6    7    8 
##  0.5 -2.5  3.5 -1.5 -8.5  6.5  3.5 -1.5 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   43.500      3.354  12.969 4.86e-05 ***
## attendyes     18.000      3.873   4.648  0.00559 ** 
## readingyes    28.000      3.873   7.230  0.00079 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.477 on 5 degrees of freedom
## Multiple R-squared:  0.9366, Adjusted R-squared:  0.9112 
## F-statistic: 36.93 on 2 and 5 DF,  p-value: 0.001012</code></pre>
<p>The only thing that is different is that R labels the two variables differently: the output now refers to <code>attendyes</code> and <code>readingyes</code>. You can probably guess what this means. When R refers to <code>readingyes</code> it’s trying to indicate that it is assuming that “yes = 1” and “no = 0”. This is important. Suppose we wanted to say that “yes = 0” and “no = 1”. We could still run this as a regression model, but now all of our coefficients will go in the opposite direction, because the effect of <code>readingno</code> would be referring to the consequences of <em>not</em> reading the textbook. To show you how this works, we can use the <code>relevel()</code> function in R to change which level of the <code>reading</code> variable is set to “0”. Here’s how it works. First, let’s get R to print out the <code>reading</code> factor as it currently stands:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> rtfm.<span class="dv">2</span><span class="op">$</span>reading</code></pre></div>
<pre><code>## [1] yes yes yes no  no  no  no  yes
## Levels: no yes</code></pre>
<p>Notice that order in which R prints out the levels is “no” and then “yes”. Now let’s apply the <code>relevel()</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">relevel</span>( <span class="dt">x =</span> rtfm.<span class="dv">2</span><span class="op">$</span>reading, <span class="dt">ref =</span> <span class="st">&quot;yes&quot;</span> )</code></pre></div>
<pre><code>## [1] yes yes yes no  no  no  no  yes
## Levels: yes no</code></pre>
<p>R now lists “yes” before “no”. This means that R will now treat “yes” as the “reference” level (sometimes called the baseline level) when you include it in an ANOVA. So let’s now create a new data frame with our factors recoded…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> rtfm.<span class="dv">3</span> &lt;-<span class="st"> </span>rtfm.<span class="dv">2</span>                                        <span class="co"># copy the old data frame</span>
 rtfm.<span class="dv">3</span><span class="op">$</span>reading &lt;-<span class="st"> </span><span class="kw">relevel</span>( rtfm.<span class="dv">2</span><span class="op">$</span>reading, <span class="dt">ref=</span><span class="st">&quot;yes&quot;</span> )  <span class="co"># re-level the reading factor</span>
 rtfm.<span class="dv">3</span><span class="op">$</span>attend &lt;-<span class="st"> </span><span class="kw">relevel</span>( rtfm.<span class="dv">2</span><span class="op">$</span>attend, <span class="dt">ref=</span><span class="st">&quot;yes&quot;</span> )    <span class="co"># re-level the attend factor</span></code></pre></div>
<p>Finally, let’s re-run our regression, this time using the re-coded data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> regression.model.<span class="dv">3</span> &lt;-<span class="st"> </span><span class="kw">lm</span>( grade <span class="op">~</span><span class="st"> </span>attend <span class="op">+</span><span class="st"> </span>reading, <span class="dt">data =</span> rtfm.<span class="dv">3</span> )
 <span class="kw">summary</span>( regression.model.<span class="dv">3</span> )</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = grade ~ attend + reading, data = rtfm.3)
## 
## Residuals:
##    1    2    3    4    5    6    7    8 
##  0.5 -2.5  3.5 -1.5 -8.5  6.5  3.5 -1.5 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   89.500      3.354  26.684 1.38e-06 ***
## attendno     -18.000      3.873  -4.648  0.00559 ** 
## readingno    -28.000      3.873  -7.230  0.00079 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.477 on 5 degrees of freedom
## Multiple R-squared:  0.9366, Adjusted R-squared:  0.9112 
## F-statistic: 36.93 on 2 and 5 DF,  p-value: 0.001012</code></pre>
<p>As you can see, there are now a few changes. Most obviously, the <code>attendno</code> and <code>readingno</code> effects are both negative, though they’re the same magnitude as before: if you <em>don’t</em> read the textbook, for instance, you should expect your grade to drop by 28% relative to someone who did. The <span class="math inline">\(t\)</span>-statistics have reversed sign too. The <span class="math inline">\(p\)</span>-values remain the same, of course. The intercept has changed too. In our original regression, the baseline corresponded to a student who didn’t attend class and didn’t read the textbook, so we got a value of 43.5 as the expected baseline grade. However, now that we’ve recoded our variables, the baseline corresponds to a student who has read the textbook and did attend class, and for that student we would expect a grade of 89.5.</p>
</div>
<div id="how-to-encode-non-binary-factors-as-contrasts" class="section level3">
<h3><span class="header-section-number">16.6.4</span> How to encode non binary factors as contrasts</h3>
<p>At this point, I’ve shown you how we can view a <span class="math inline">\(2\times 2\)</span> ANOVA into a linear model. And it’s pretty easy to see how this generalises to a <span class="math inline">\(2 \times 2 \times 2\)</span> ANOVA or a <span class="math inline">\(2 \times 2 \times 2 \times 2\)</span> ANOVA… it’s the same thing, really: you just add a new binary variable for each of your factors. Where it begins to get trickier is when we consider factors that have more than two levels. Consider, for instance, the <span class="math inline">\(3 \times 2\)</span> ANOVA that we ran earlier in this chapter using the <code>clin.trial</code> data. How can we convert the three-level <code>drug</code> factor into a numerical form that is appropriate for a regression?</p>
<p>The answer to this question is pretty simple, actually. All we have to do is realise that a three-level factor can be redescribed as <em>two</em> binary variables. Suppose, for instance, I were to create a new binary variable called <code>druganxifree</code>. Whenever the <code>drug</code> variable is equal to <code>&quot;anxifree&quot;</code> we set <code>druganxifree = 1</code>. Otherwise, we set <code>druganxifree = 0</code>. This variable sets up a <strong><em>contrast</em></strong>, in this case between anxifree and the other two drugs. By itself, of course, the <code>druganxifree</code> contrast isn’t enough to fully capture all of the information in our <code>drug</code> variable. We need a second contrast, one that allows us to distinguish between joyzepam and the placebo. To do this, we can create a second binary contrast, called <code>drugjoyzepam</code>, which equals 1 if the drug is joyzepam, and 0 if it is not. Taken together, these two contrasts allows us to perfectly discriminate between all three possible drugs. The table below illustrates this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
           <span class="op">~</span>V1,              <span class="op">~</span>V2,              <span class="op">~</span>V3,
   <span class="st">&quot;`placebo`&quot;</span>,              <span class="st">&quot;0&quot;</span>,              <span class="st">&quot;0&quot;</span>,
  <span class="st">&quot;`anxifree`&quot;</span>,              <span class="st">&quot;1&quot;</span>,              <span class="st">&quot;0&quot;</span>,
  <span class="st">&quot;`joyzepam`&quot;</span>,              <span class="st">&quot;0&quot;</span>,              <span class="st">&quot;1&quot;</span>
  ), <span class="dt">col.names =</span> <span class="kw">c</span>(      <span class="st">&quot;`drug`&quot;</span>, <span class="st">&quot;`druganxifree`&quot;</span>, <span class="st">&quot;`drugjoyzepam`&quot;</span>))</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left"><code>drug</code></th>
<th align="left"><code>druganxifree</code></th>
<th align="left"><code>drugjoyzepam</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>placebo</code></td>
<td align="left">0</td>
<td align="left">0</td>
</tr>
<tr class="even">
<td align="left"><code>anxifree</code></td>
<td align="left">1</td>
<td align="left">0</td>
</tr>
<tr class="odd">
<td align="left"><code>joyzepam</code></td>
<td align="left">0</td>
<td align="left">1</td>
</tr>
</tbody>
</table>
<p>If the drug administered to a patient is a placebo, then both of the two contrast variables will equal 0. If the drug is Anxifree, then the <code>druganxifree</code> variable will equal 1, and <code>drugjoyzepam</code> will be 0. The reverse is true for Joyzepam: <code>drugjoyzepam</code> is 1, and <code>druganxifree</code> is 0.</p>
<p>Creating contrast variables manually is not too difficult to do using basic R commands. For example, here’s how we would create the <code>druganxifree</code> variable:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> druganxifree &lt;-<span class="st"> </span><span class="kw">as.numeric</span>( clin.trial<span class="op">$</span>drug <span class="op">==</span><span class="st"> &quot;anxifree&quot;</span> )
 druganxifree</code></pre></div>
<pre><code>##  [1] 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 0 0 0</code></pre>
<p>The <code>clin.trial$drug == &quot;anxifree&quot;</code> part of the command returns a logical vector that has a value of <code>TRUE</code> if the drug is Anxifree, and a value of <code>FALSE</code> if the drug is Joyzepam or the placebo. The <code>as.numeric()</code> function just converts <code>TRUE</code> to 1 and <code>FALSE</code> to 0. Obviously, this command creates the <code>druganxifree</code> variable inside the workspace. If you wanted to add it to the <code>clin.trial</code> data frame, you’d use a commmand like this instead:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> clin.trial<span class="op">$</span>druganxifree &lt;-<span class="st"> </span><span class="kw">as.numeric</span>( clin.trial<span class="op">$</span>drug <span class="op">==</span><span class="st"> &quot;anxifree&quot;</span> )</code></pre></div>
<p>You could then repeat this for the other contrasts that you wanted to use. However, it’s kind of tedious to do this over and over again for every single contrast that you want to create. To make it a little easier, the <code>lsr</code> package contains a simple function called <code>expandFactors()</code> that will convert every factor in a data frame into a set of contrast variables.<a href="#fn242" class="footnoteRef" id="fnref242"><sup>242</sup></a> We can use it to create a new data frame, <code>clin.trial.2</code> that contains the same data as <code>clin.trial</code>, but with the two factors represented in terms of the contrast variables:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> clin.trial.<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">expandFactors</span>( clin.trial )</code></pre></div>
<pre><code>##    (Intercept) druganxifree drugjoyzepam therapyCBT mood.gain druganxifree
## 1            1            0            0          0       0.5            0
## 2            1            0            0          0       0.3            0
## 3            1            0            0          0       0.1            0
## 4            1            1            0          0       0.6            1
## 5            1            1            0          0       0.4            1
## 6            1            1            0          0       0.2            1
## 7            1            0            1          0       1.4            0
## 8            1            0            1          0       1.7            0
## 9            1            0            1          0       1.3            0
## 10           1            0            0          1       0.6            0
## 11           1            0            0          1       0.9            0
## 12           1            0            0          1       0.3            0
## 13           1            1            0          1       1.1            1
## 14           1            1            0          1       0.8            1
## 15           1            1            0          1       1.2            1
## 16           1            0            1          1       1.8            0
## 17           1            0            1          1       1.3            0
## 18           1            0            1          1       1.4            0
## attr(,&quot;assign&quot;)
## [1] 0 1 1 2 3 4
## attr(,&quot;contrasts&quot;)
## attr(,&quot;contrasts&quot;)$drug
## [1] &quot;contr.treatment&quot;
## 
## attr(,&quot;contrasts&quot;)$therapy
## [1] &quot;contr.treatment&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> clin.trial.<span class="dv">2</span></code></pre></div>
<pre><code>##    druganxifree drugjoyzepam therapyCBT mood.gain druganxifree
## 1             0            0          0       0.5            0
## 2             0            0          0       0.3            0
## 3             0            0          0       0.1            0
## 4             1            0          0       0.6            1
## 5             1            0          0       0.4            1
## 6             1            0          0       0.2            1
## 7             0            1          0       1.4            0
## 8             0            1          0       1.7            0
## 9             0            1          0       1.3            0
## 10            0            0          1       0.6            0
## 11            0            0          1       0.9            0
## 12            0            0          1       0.3            0
## 13            1            0          1       1.1            1
## 14            1            0          1       0.8            1
## 15            1            0          1       1.2            1
## 16            0            1          1       1.8            0
## 17            0            1          1       1.3            0
## 18            0            1          1       1.4            0</code></pre>
<p>It’s not as pretty as the original <code>clin.trial</code> data, but it’s definitely saying the same thing. We have now recoded our three-level factor in terms of two binary variables, and we’ve already seen that ANOVA and regression behave the same way for binary variables. However, there are some additional complexities that arise in this case, which we’ll discuss in the next section.</p>
</div>
<div id="the-equivalence-between-anova-and-regression-for-non-binary-factors" class="section level3">
<h3><span class="header-section-number">16.6.5</span> The equivalence between ANOVA and regression for non-binary factors</h3>
<p>Now we have two different versions of the same data set: our original data frame <code>clin.trial</code> in which the <code>drug</code> variable is expressed as a single three-level factor, and the expanded data set <code>clin.trial.2</code> in which it is expanded into two binary contrasts. Once again, the thing that we want to demonstrate is that our original <span class="math inline">\(3 \times 2\)</span> factorial ANOVA is equivalent to a regression model applied to the contrast variables. Let’s start by re-running the ANOVA:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> drug.anova &lt;-<span class="st"> </span><span class="kw">aov</span>( mood.gain <span class="op">~</span><span class="st"> </span>drug <span class="op">+</span><span class="st"> </span>therapy, clin.trial )
 <span class="kw">summary</span>( drug.anova )</code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## drug         2  3.453  1.7267  26.149 1.87e-05 ***
## therapy      1  0.467  0.4672   7.076   0.0187 *  
## Residuals   14  0.924  0.0660                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Obviously, there’s no surprises here. That’s the exact same ANOVA that we ran earlier, except for the fact that I’ve arbitrarily decided to rename the output variable as <code>drug.anova</code> for some stupid reason.<a href="#fn243" class="footnoteRef" id="fnref243"><sup>243</sup></a> Next, let’s run a regression, using <code>druganxifree</code>, <code>drugjoyzepam</code> and <code>therapyCBT</code> as the predictors. Here’s what we get:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> drug.regression &lt;-<span class="st"> </span><span class="kw">lm</span>( mood.gain <span class="op">~</span><span class="st"> </span>druganxifree <span class="op">+</span><span class="st"> </span>drugjoyzepam <span class="op">+</span><span class="st"> </span>therapyCBT, clin.trial.<span class="dv">2</span> )
 <span class="kw">summary</span>( drug.regression )</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mood.gain ~ druganxifree + drugjoyzepam + therapyCBT, 
##     data = clin.trial.2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.3556 -0.1806  0.0000  0.1972  0.3778 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    0.2889     0.1211   2.385   0.0318 *  
## druganxifree   0.2667     0.1484   1.797   0.0939 .  
## drugjoyzepam   1.0333     0.1484   6.965  6.6e-06 ***
## therapyCBT     0.3222     0.1211   2.660   0.0187 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.257 on 14 degrees of freedom
## Multiple R-squared:  0.8092, Adjusted R-squared:  0.7683 
## F-statistic: 19.79 on 3 and 14 DF,  p-value: 2.64e-05</code></pre>
<p>Hm. This isn’t the same output that we got last time. Not surprisingly, the regression output prints out the results for each of the three predictors separately, just like it did every other time we used <code>lm()</code>. On the one hand, we can see that the <span class="math inline">\(p\)</span>-value for the <code>therapyCBT</code> variable is exactly the same as the one for the <code>therapy</code> factor in our original ANOVA, so we can be reassured that the regression model is doing the same thing as the ANOVA did. On the other hand, this regression model is testing the <code>druganxifree</code> contrast and the <code>drugjoyzepam</code> contrast <em>separately</em>, as if they were two completely unrelated variables. It’s not surprising of course, because the poor <code>lm()</code> function has no way of knowing that <code>drugjoyzepam</code> and <code>druganxifree</code> are actually the two different contrasts that we used to encode our three-level <code>drug</code> factor. As far as it knows, <code>drugjoyzepam</code> and <code>druganxifree</code> are no more related to one another than <code>drugjoyzepam</code> and <code>therapyCBT</code>. However, you and I know better. At this stage we’re not at all interested in determining whether these two contrasts are individually significant. We just want to know if there’s an “overall” effect of drug. That is, what <em>we</em> want R to do is to run some kind of “omnibus” test, one in which the two “drug-related” contrasts are lumped together for the purpose of the test. Sound familiar? This is <em>exactly</em> the situation that we discussed in Section <a href="anova2.html#omnibusF">16.5</a>, and it is precisely this situation that the <span class="math inline">\(F\)</span>-test is built to handle. All we need to do is specify our null model, which in this case would include the <code>therapyCBT</code> predictor, and omit both of the drug-related variables, and then run it through the <code>anova()</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> nodrug.regression &lt;-<span class="st"> </span><span class="kw">lm</span>( mood.gain <span class="op">~</span><span class="st"> </span>therapyCBT, clin.trial.<span class="dv">2</span> )
 <span class="kw">anova</span>( nodrug.regression, drug.regression )</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: mood.gain ~ therapyCBT
## Model 2: mood.gain ~ druganxifree + drugjoyzepam + therapyCBT
##   Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1     16 4.3778                                  
## 2     14 0.9244  2    3.4533 26.149 1.872e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Ah, that’s better. Our <span class="math inline">\(F\)</span>-statistic is 26.1, the degrees of freedom are 2 and 14, and the <span class="math inline">\(p\)</span>-value is <span class="math inline">\(0.000019\)</span>. The numbers are identical to the ones we obtained for the main effect of <code>drug</code> in our original ANOVA. Once again, we see that ANOVA and regression are essentially the same: they are both linear models, and the underlying statistical machinery for ANOVA is identical to the machinery used in regression. The importance of this fact should not be understated. Throughout the rest of this chapter we’re going to rely heavily on this idea.</p>
</div>
<div id="degrees-of-freedom-as-parameter-counting" class="section level3">
<h3><span class="header-section-number">16.6.6</span> Degrees of freedom as parameter counting!</h3>
<p>At long last, I can finally give a definition of degrees of freedom that I am happy with. Degrees of freedom are defined in terms of the number of parameters that have to be estimated in a model. For a regression model or an ANOVA, the number of parameters corresponds to the number of regression coefficients (i.e. <span class="math inline">\(b\)</span>-values), including the intercept. Keeping in mind that any <span class="math inline">\(F\)</span>-test is always a comparison between two models, the first <span class="math inline">\(df\)</span> is the difference in the number of parameters. For example, model comparison above, the null model (<code>mood.gain ~ therapyCBT</code>) has two parameters: there’s one regression coefficient for the <code>therapyCBT</code> variable, and a second one for the intercept. The alternative model (<code>mood.gain ~ druganxifree + drugjoyzepam + therapyCBT</code>) has four parameters: one regression coefficient for each of the three contrasts, and one more for the intercept. So the degrees of freedom associated with the <em>difference</em> between these two models is <span class="math inline">\(df_1 = 4-2 = 2\)</span>.</p>
<p>What about the case when there doesn’t seem to <em>be</em> a null model? For instance, you might be thinking of the <span class="math inline">\(F\)</span>-test that appears at the very bottom of the regression output. I originally described that as a test of the regression model as a whole. However, that is still a comparison between two models. The null model is the trivial model that only includes an intercept, which is written as <code>outcome ~ 1</code> in R, and the alternative model is the full regression model. The null model in this case contains 1 regression coefficient, for the intercept term. The alternative model contains <span class="math inline">\(K+1\)</span> regression coefficients, one for each of the <span class="math inline">\(K\)</span> predictor variables and one more for the intercept. So the <span class="math inline">\(df\)</span> value that you see in this <span class="math inline">\(F\)</span> test is equal to <span class="math inline">\(df_1 = K+1-1 = K\)</span>.</p>
<p>What about the second <span class="math inline">\(df\)</span> value that appears in the <span class="math inline">\(F\)</span>-test? This always refers to the degrees of freedom associated with the residuals. It is possible to think of this in terms of parameters too, but in a slightly counterintuitive way. Think of it like this: suppose that the total number of observations across the study as a whole is <span class="math inline">\(N\)</span>. If you wanted to <em>perfectly</em> describe each of these <span class="math inline">\(N\)</span> values, you need to do so using, well… <span class="math inline">\(N\)</span> numbers. When you build a regression model, what you’re really doing is specifying some of the numbers need to perfectly describe the data. If your model has <span class="math inline">\(K\)</span> predictors and an intercept, then you’ve specified <span class="math inline">\(K+1\)</span> numbers. So, without bothering to figure out exactly <em>how</em> this would be done, how many <em>more</em> numbers do you think are going to be needed to transform a <span class="math inline">\(K+1\)</span> parameter regression model into a perfect redescription of the raw data? If you found yourself thinking that <span class="math inline">\((K+1) + (N-K-1) = N\)</span>, and so the answer would have to be <span class="math inline">\(N-K-1\)</span>, well done! That’s exactly right: in principle you can imagine an absurdly complicated regression model that includes a parameter for every single data point, and it would of course provide a perfect description of the data. This model would contain <span class="math inline">\(N\)</span> parameters in total, but we’re interested in the difference between the number of parameters required to describe this full model (i.e. <span class="math inline">\(N\)</span>) and the number of parameters used by the simpler regression model that you’re actually interested in (i.e., <span class="math inline">\(K+1\)</span>), and so the second degrees of freedom in the <span class="math inline">\(F\)</span> test is <span class="math inline">\(df_2 = N-K-1\)</span>, where <span class="math inline">\(K\)</span> is the number of predictors (in a regression model) or the number of contrasts (in an ANOVA). In the example I gave above, there are <span class="math inline">\(N=18\)</span> observations in the data set, and <span class="math inline">\(K+1 = 4\)</span> regression coefficients associated with the ANOVA model, so the degrees of freedom for the residuals is <span class="math inline">\(df_2 = 18-4 = 14\)</span>.</p>
</div>
<div id="a-postscript" class="section level3">
<h3><span class="header-section-number">16.6.7</span> A postscript</h3>
<p>There’s one last thing I want to mention in this section. In the previous example, I used the <code>aov()</code> function to run an ANOVA using the <code>clin.trial</code> data which codes <code>drug</code> variable as a single factor. I also used the <code>lm()</code> function to run a regression using the <code>clin.trial</code> data in which we have two separate contrasts describing the drug. However, it’s also possible to use the <code>lm()</code> function on the the original data. That is, you could use a command like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> drug.lm &lt;-<span class="st"> </span><span class="kw">lm</span>( mood.gain <span class="op">~</span><span class="st"> </span>drug <span class="op">+</span><span class="st"> </span>therapy, clin.trial )</code></pre></div>
<p>The fact that <code>drug</code> is a three-level factor does not matter. As long as the <code>drug</code> variable has been declared to be a factor, R will automatically translate it into two binary contrast variables, and will perform the appropriate analysis. After all, as I’ve been saying throughout this section, ANOVA and regression are both linear models, and <code>lm()</code> is the function that handles linear models. In fact, the <code>aov()</code> function doesn’t actually do very much of the work when you run an ANOVA using it: internally, R just passes all the hard work straight to <code>lm()</code>. However, I want to emphasise again that it is <em>critical</em> that your factor variables are declared as such. If <code>drug</code> were declared to be a numeric variable, then R would be happy to treat it as one. After all, it might be that <code>drug</code> refers to the number of drugs that one has taken in the past, or something that is genuinely numeric. R won’t second guess you here. It assumes your factors are factors and your numbers are numbers. Don’t make the mistake of encoding your factors as numbers, or R will run the wrong analysis. This is <em>not</em> a flaw in R: it is <em>your</em> responsibility as the analyst to make sure you’re specifying the right model for your data. Software really can’t be trusted with this sort of thing.</p>
<p>Okay, warnings aside, it’s actually kind of neat to run your ANOVA using the <code>lm()</code> function in the way I did above. Because you’ve called the <code>lm()</code> function, the <code>summary()</code> that R pulls out is formatted like a regression. To save space I won’t show you the output here, but you can easily verify this by typing</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">summary</span>( drug.lm )</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mood.gain ~ drug + therapy, data = clin.trial)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.3556 -0.1806  0.0000  0.1972  0.3778 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    0.2889     0.1211   2.385   0.0318 *  
## druganxifree   0.2667     0.1484   1.797   0.0939 .  
## drugjoyzepam   1.0333     0.1484   6.965  6.6e-06 ***
## therapyCBT     0.3222     0.1211   2.660   0.0187 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.257 on 14 degrees of freedom
## Multiple R-squared:  0.8092, Adjusted R-squared:  0.7683 
## F-statistic: 19.79 on 3 and 14 DF,  p-value: 2.64e-05</code></pre>
<p>However, because the <code>drug</code> and <code>therapy</code> variables were both factors, the <code>anova()</code> function actually knows which contrasts to group together for the purposes of running the <span class="math inline">\(F\)</span>-tests, so you can extract the classic ANOVA table. Again, I won’t reproduce the output here since it’s identical to the ANOVA table I showed at the start of the section, but it’s worth trying the following command</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">anova</span>( drug.lm )</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: mood.gain
##           Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## drug       2 3.4533 1.72667 26.1490 1.872e-05 ***
## therapy    1 0.4672 0.46722  7.0757   0.01866 *  
## Residuals 14 0.9244 0.06603                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>just to see for yourself. However, this behaviour of the <code>anova()</code> function only occurs when the predictor variables are factors. If we try a command like <code>anova( drug.regression )</code>, the output will continue to treate <code>druganxifree</code> and <code>drugjoyzepam</code> as if they were two distinct binary factors. This is because in the <code>drug.regression</code> model we included all the contrasts as “raw” variables, so R had no idea which ones belonged together. However, when we ran the <code>drug.lm</code> model, we gave R the original factor variables, so it does know which contrasts go together. The behaviour of the <code>anova()</code> function reflects that.</p>
</div>
</div>
<div id="contrasts" class="section level2">
<h2><span class="header-section-number">16.7</span> Different ways to specify contrasts</h2>
<p>In the previous section, I showed you a method for converting a factor into a collection of contrasts. In the method I showed you, we specify a set of binary variables, in which define a table like this one:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
           <span class="op">~</span>V1,              <span class="op">~</span>V2,              <span class="op">~</span>V3,

   <span class="st">&quot;</span><span class="ch">\&quot;</span><span class="st">placebo</span><span class="ch">\&quot;</span><span class="st">&quot;</span>,              <span class="st">&quot;0&quot;</span>,              <span class="st">&quot;0&quot;</span>,
  <span class="st">&quot;</span><span class="ch">\&quot;</span><span class="st">anxifree</span><span class="ch">\&quot;</span><span class="st">&quot;</span>,              <span class="st">&quot;1&quot;</span>,              <span class="st">&quot;0&quot;</span>,
  <span class="st">&quot;</span><span class="ch">\&quot;</span><span class="st">joyzepam</span><span class="ch">\&quot;</span><span class="st">&quot;</span>,              <span class="st">&quot;0&quot;</span>,              <span class="st">&quot;1&quot;</span>
  ), <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;drug&quot;</span>, <span class="st">&quot;druganxifree&quot;</span>, <span class="st">&quot;drugjoyzepam&quot;</span>))</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">drug</th>
<th align="left">druganxifree</th>
<th align="left">drugjoyzepam</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">“placebo”</td>
<td align="left">0</td>
<td align="left">0</td>
</tr>
<tr class="even">
<td align="left">“anxifree”</td>
<td align="left">1</td>
<td align="left">0</td>
</tr>
<tr class="odd">
<td align="left">“joyzepam”</td>
<td align="left">0</td>
<td align="left">1</td>
</tr>
</tbody>
</table>
<p>Each row in the table corresponds to one of the factor levels, and each column corresponds to one of the contrasts. This table, which always has one more row than columns, has a special name: it is called a <strong><em>contrast matrix</em></strong>. However, there are lots of different ways to specify a contrast matrix. In this section I discuss a few of the standard contrast matrices that statisticians use, and how you can use them in R. If you’re planning to read the section on unbalanced ANOVA later on (Section <a href="anova2.html#unbalancedanova">16.10</a>) it’s worth reading this section carefully. If not, you can get away with skimming it, because the choice of contrasts doesn’t matter much for balanced designs.</p>
<div id="treatment-contrasts" class="section level3">
<h3><span class="header-section-number">16.7.1</span> Treatment contrasts</h3>
<p>In the particular kind of contrasts that I’ve described above, one level of the factor is special, and acts as a kind of “baseline” category (i.e., <code>placebo</code> in our example), against which the other two are defined. The name for these kinds of contrast is <strong><em>treatment contrasts</em></strong>. The name reflects the fact that these contrasts are quite natural and sensible when one of the categories in your factor really is special because it actually does represent a baseline. That makes sense in our clinical trial example: the <code>placebo</code> condition corresponds to the situation where you don’t give people any real drugs, and so it’s special. The other two conditions are defined in relation to the placebo: in one case you replace the placebo with Anxifree, and in the other case your replace it with Joyzepam.</p>
<p>R comes with a variety of functions that can generate different kinds of contrast matrices. For example, the table shown above is a matrix of treatment contrasts for a factor that has 3 levels. But suppose I want a matrix of treatment contrasts for a factor with 5 levels? The <code>contr.treatment()</code> function will do this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">contr.treatment</span>( <span class="dt">n=</span><span class="dv">5</span> )</code></pre></div>
<pre><code>##   2 3 4 5
## 1 0 0 0 0
## 2 1 0 0 0
## 3 0 1 0 0
## 4 0 0 1 0
## 5 0 0 0 1</code></pre>
<p>Notice that, by default, the <em>first</em> level of the factor is always treated as the baseline category (i.e., it’s the one that has all zeros, and doesn’t have an explicit contrast associated with it). In Section <a href="anova2.html#changingbaseline">16.6.3</a> I mentioned that you can use the <code>relevel()</code> function to change which category is the first level of the factor.<a href="#fn244" class="footnoteRef" id="fnref244"><sup>244</sup></a> There’s also a special function in R called <code>contr.SAS()</code> that generates a treatment contrast matrix in which the <em>last</em> category is treated as the baseline:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">contr.SAS</span>( <span class="dt">n=</span><span class="dv">5</span> )</code></pre></div>
<pre><code>##   1 2 3 4
## 1 1 0 0 0
## 2 0 1 0 0
## 3 0 0 1 0
## 4 0 0 0 1
## 5 0 0 0 0</code></pre>
<p>However, you can actually select any category you like as the baseline within the <code>contr.treatment()</code> function, by specifying the <code>base</code> argument in that function. See the help documentation for more details.</p>
</div>
<div id="helmert-contrasts" class="section level3">
<h3><span class="header-section-number">16.7.2</span> Helmert contrasts</h3>
<p>Treatment contrasts are useful for a lot of situations, and they’re the default in R. However, they make most sense in the situation when there really is a baseline category, and you want to assess all the other groups in relation to that one. In other situations, however, no such baseline category exists, and it may make more sense to compare each group to the mean of the other groups. This is where <strong><em>Helmert contrasts</em></strong>, generated by the <code>contr.helmert()</code> function, can be useful. The idea behind Helmert contrasts is to compare each group to the mean of the “previous” ones. That is, the first contrast represents the difference between group 2 and group 1, the second contrast represents the difference between group 3 and the mean of groups 1 and 2, and so on. This translates to a contrast matrix that looks like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">contr.helmert</span>( <span class="dt">n=</span><span class="dv">5</span> )</code></pre></div>
<pre><code>##   [,1] [,2] [,3] [,4]
## 1   -1   -1   -1   -1
## 2    1   -1   -1   -1
## 3    0    2   -1   -1
## 4    0    0    3   -1
## 5    0    0    0    4</code></pre>
<p>One useful thing about Helmert contrasts is that every contrast sums to zero (i.e., all the columns sum to zero). This has the consequence that, when we interpret the ANOVA as a regression, the intercept term corresponds to the grand mean <span class="math inline">\(\mu_{..})\)</span> if we are using Helmert contrasts. Compare this to treatment contrasts, in which the intercept term corresponds to the group mean for the baseline category. This property can be very useful in some situations. It doesn’t matter very much if you have a balanced design, which we’ve been assuming so far, but it will turn out to be important later when we consider unbalanced designs in Section <a href="anova2.html#unbalancedanova">16.10</a>. In fact, the main reason why I’ve even bothered to include this section on specifying is that contrasts become important if you want to understand unbalanced ANOVA.</p>
</div>
<div id="sum-to-zero-contrasts" class="section level3">
<h3><span class="header-section-number">16.7.3</span> Sum to zero contrasts</h3>
<p>The third option that I should briefly mention are “sum to zero” contrasts, which are used to construct pairwise comparisons between groups. Specifically, each contrast encodes the difference between one of the groups and a baseline category, which in this case corresponds to the last group:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">contr.sum</span>( <span class="dt">n=</span><span class="dv">5</span> )</code></pre></div>
<pre><code>##   [,1] [,2] [,3] [,4]
## 1    1    0    0    0
## 2    0    1    0    0
## 3    0    0    1    0
## 4    0    0    0    1
## 5   -1   -1   -1   -1</code></pre>
<p>Much like Helmert contrasts, we see that each column sums to zero, which means that the intercept term corresponds to the grand mean when ANOVA is treated as a regression model. When interpreting these contrasts, the thing to recognise is that each of these contrasts is a pairwise comparison between group 5 and one of the other four groups. Specifically, contrast 1 corresponds to a “group 1 minus group 5” comparison, contrast 2 corresponds to a “group 2 minus group 5” comparison, and so on.</p>
</div>
<div id="viewing-and-setting-the-default-contrasts-in-r" class="section level3">
<h3><span class="header-section-number">16.7.4</span> Viewing and setting the default contrasts in R</h3>
<p>Every factor variable in R is associated with a contrast matrix. It has to be, otherwise R wouldn’t be able to run ANOVAs properly! If you don’t specify one explictly, or R will implicitly specify one for you. Here’s what I mean. When I created the <code>clin.trial</code> data, I didn’t specify any contrast matrix for either of the factors. You can see this by using the <code>attr()</code> function to print out the “contrasts” attribute of the factors. For example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">attr</span>( clin.trial<span class="op">$</span>drug, <span class="st">&quot;contrasts&quot;</span> )</code></pre></div>
<pre><code>## NULL</code></pre>
<p>The <code>NULL</code> output here means that R is telling you that the <code>drug</code> factor doesn’t have any attribute called “contrasts” for which it has any data. There is no contrast matrix stored anywhere explicitly for this factor. However, if we now ask R to tell us what contrasts are set up for this factor, it give us this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">contrasts</span>( clin.trial<span class="op">$</span>drug )</code></pre></div>
<pre><code>##          anxifree joyzepam
## placebo         0        0
## anxifree        1        0
## joyzepam        0        1</code></pre>
<p>These are the same treatment contrast that we set up manually in Section <a href="anova2.html#anovalm">16.6</a>. How did R know to set up treatment contrasts, even though I never actually told it anything about what contrasts I wanted? The answer is that R has a hidden list of default “options” that it looks up to resolve situations like this. You can print out all of the options by typing <code>options()</code> at the command prompt, but it’s not a very enlightening read. There are a lot of options, and we’re only interested in contrasts right now. Instead of printing out all of the options, we can ask for just one, like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">options</span>( <span class="st">&quot;contrasts&quot;</span> )</code></pre></div>
<pre><code>## $contrasts
##         unordered           ordered 
## &quot;contr.treatment&quot;      &quot;contr.poly&quot;</code></pre>
<p>What this is telling us is that the default contrasts for unordered factors (i.e., nominal scale variables) are treatment contrasts, and the default for ordered factors (i.e., interval scale variables) are “polynomial” contrasts. I don’t discuss ordered factors much in this book, and so I won’t go into what polynomial contrasts are all about. The key thing is that the <code>options()</code> function also allows you to reset these defaults (though only for the current session: they’ll revert to the original settings once you close R). Here’s the command:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">options</span>(<span class="dt">contrasts =</span> <span class="kw">c</span>(<span class="st">&quot;contr.helmert&quot;</span>, <span class="st">&quot;contr.poly&quot;</span>))</code></pre></div>
<p>Once we’ve done this, we can inspect the contrast settings again:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">options</span>(<span class="st">&quot;contrasts&quot;</span>) </code></pre></div>
<pre><code>## $contrasts
## [1] &quot;contr.helmert&quot; &quot;contr.poly&quot;</code></pre>
<p>Now we see that the default contrasts for unordered factors have changed. So if I now ask R to tell me what contrasts are associated with the <code>drug</code> factor, it gives a different answer because I changed the default:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">contrasts</span>( clin.trial<span class="op">$</span>drug )</code></pre></div>
<pre><code>##          [,1] [,2]
## placebo    -1   -1
## anxifree    1   -1
## joyzepam    0    2</code></pre>
<p>Those are Helmert contrasts. In general, if you’re changing the default settings for something in R, it’s a good idea to reset them to their original values once you’re done. So let’s do that:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">options</span>(<span class="dt">contrasts =</span> <span class="kw">c</span>(<span class="st">&quot;contr.treatment&quot;</span>, <span class="st">&quot;contr.poly&quot;</span>))</code></pre></div>
</div>
<div id="setting-the-contrasts-for-a-single-factor" class="section level3">
<h3><span class="header-section-number">16.7.5</span> Setting the contrasts for a single factor</h3>
<p>In the previous section, I showed you how to alter the default contrasts. However, suppose that all you really want to do is change the contrasts associated with a single factor, and leave the defaults as they are. To do this, what you need to do is specifically assign the contrast matrix as an “attribute’ of the factor. This is easy to do via the <code>contrasts()</code> function. For instance, suppose I wanted to use sum to zero contrasts for the <code>drug</code> factor, but keep the default treatment contrasts for everything else. I could do that like so:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">contrasts</span>( clin.trial<span class="op">$</span>drug ) &lt;-<span class="st"> </span><span class="kw">contr.sum</span>(<span class="dv">3</span>)</code></pre></div>
<p>And if I now inspect the contrasts, I get the following</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">contrasts</span>( clin.trial<span class="op">$</span>drug)</code></pre></div>
<pre><code>##          [,1] [,2]
## placebo     1    0
## anxifree    0    1
## joyzepam   -1   -1</code></pre>
<p>However, the contrasts for everything else will still be the defaults. You can check that we have actually made a specific change to the factor itself by checking to see if it now has an attribute, using the command <code>attr( clin.trial$drug, &quot;contrasts&quot; )</code>. This will print out the same output shown above, because the contrast has in fact been attached to the <code>drug</code> factor, and does not rely on the defaults. If you want to wipe the attribute and revert the defaults, use a command like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">contrasts</span>( clin.trial<span class="op">$</span>drug ) &lt;-<span class="st"> </span><span class="ot">NULL</span></code></pre></div>
</div>
<div id="setting-the-contrasts-for-a-single-analysis" class="section level3">
<h3><span class="header-section-number">16.7.6</span> Setting the contrasts for a single analysis</h3>
<p>One last way of changing contrasts. You might find yourself wanting to change the contrasts only for one specific analysis. That’s allowed too, because the <code>aov()</code> and <code>lm()</code> functions have a <code>contrasts</code> argument that you can use. To change contrasts for one specific analysis, we first set up a list variable that names<a href="#fn245" class="footnoteRef" id="fnref245"><sup>245</sup></a> the contrast types that you want to use for each of the factors:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> my.contrasts &lt;-<span class="st"> </span><span class="kw">list</span>( <span class="dt">drug =</span> contr.helmert, <span class="dt">therapy =</span> contr.helmert )</code></pre></div>
<p>Next, fit the ANOVA model in the usual way, but this time we’ll specify the <code>contrasts</code> argument:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> mod &lt;-<span class="st"> </span><span class="kw">aov</span>( mood.gain <span class="op">~</span><span class="st"> </span>drug<span class="op">*</span>therapy, clin.trial, <span class="dt">contrasts =</span> my.contrasts )</code></pre></div>
<p>If you try a command like <code>summary(aov)</code> you won’t see any difference in the output because the choice of contrasts does not affect the outcome when you have a balanced design (this won’t always be true later on). However, if you want to check that it has actually worked, you can inspect the value of <code>mod$contrasts</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> mod<span class="op">$</span>contrasts</code></pre></div>
<pre><code>## $drug
##          [,1] [,2]
## placebo    -1   -1
## anxifree    1   -1
## joyzepam    0    2
## 
## $therapy
##            [,1]
## no.therapy   -1
## CBT           1</code></pre>
<p>As you can see, for the purposes of this one particular ANOVA, R has used Helmert contrasts for both variables. If I had omitted the part of the command that specified the <code>contrasts</code> argument, you’d be looking at treatment contrasts here because it would have reverted to whatever values the <code>contrasts()</code> function prints out for each of the factors.</p>
</div>
</div>
<div id="posthoc2" class="section level2">
<h2><span class="header-section-number">16.8</span> Post hoc tests</h2>
<p>Time to switch to a different topic. Let’s suppose you’ve done your ANOVA, and it turns out that you obtained some significant effects. Because of the fact that the <span class="math inline">\(F\)</span>-tests are “omnibus” tests that only really test the null hypothesis that there are no differences among groups, obtaining a significant effect doesn’t tell you which groups are different to which other ones. We discussed this issue back in Chapter <a href="anova.html#anova">14</a>, and in that chapter our solution was to run <span class="math inline">\(t\)</span>-tests for all possible pairs of groups, making corrections for multiple comparisons (e.g., Bonferroni, Holm) to control the Type I error rate across all comparisons. The methods that we used back in Chapter <a href="anova.html#anova">14</a> have the advantage of being relatively simple, and being the kind of tools that you can use in a lot of different situations where you’re testing multiple hypotheses, but they’re not necessarily the best choices if you’re interested in doing efficient post hoc testing in an ANOVA context. There are actually quite a lot of different methods for performing multiple comparisons in the statistics literature <span class="citation">(Hsu <a href="#ref-Hsu1996">1996</a>)</span>, and it would be beyond the scope of an introductory text like this one to discuss all of them in any detail.</p>
<p>That being said, there’s one tool that I do want to draw your attention to, namely Tukey’s “Honestly Significant Difference”, or <strong><em>Tukey’s HSD</em></strong> for short. For once, I’ll spare you the formulas, and just stick to the qualitative ideas. The basic idea in Tukey’s HSD is to examine all relevant pairwise comparisons between groups, and it’s only really appropriate to use Tukey’s HSD if it is <em>pairwise</em> differences that you’re interested in.<a href="#fn246" class="footnoteRef" id="fnref246"><sup>246</sup></a> For instance, in <code>model.2</code>, where we specified a main effect for drug and a main effect of therapy, we would be interested in the following four comparisons:</p>
<ul>
<li>The difference in mood gain for people given Anxifree versus people given the placebo.</li>
<li>The difference in mood gain for people given Joyzepam versus people given the placebo.</li>
<li>The difference in mood gain for people given Anxifree versus people given Joyzepam.</li>
<li>The difference in mood gain for people treated with CBT and people given no therapy.</li>
</ul>
<p>For any one of these comparisons, we’re interested in the true difference between (population) group means. Tukey’s HSD constructs <strong><em>simultaneous confidence intervals</em></strong> for all four of these comparisons. What we mean by 95% “simultaneous” confidence interval is that there is a 95% probability that <em>all</em> of these confidence intervals contain the relevant true value. Moreover, we can use these confidence intervals to calculate an adjusted <span class="math inline">\(p\)</span> value for any specific comparison.</p>
<p>The <code>TukeyHSD()</code> function in R is pretty easy to use: you simply input the model that you want to run the post hoc tests for. For example, if we were looking to run post hoc tests for <code>model.2</code>, here’s the command we would use:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">TukeyHSD</span>( model.<span class="dv">2</span> )</code></pre></div>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = mood.gain ~ drug + therapy, data = clin.trial)
## 
## $drug
##                        diff        lwr       upr     p adj
## anxifree-placebo  0.2666667 -0.1216321 0.6549655 0.2062942
## joyzepam-placebo  1.0333333  0.6450345 1.4216321 0.0000186
## joyzepam-anxifree 0.7666667  0.3783679 1.1549655 0.0003934
## 
## $therapy
##                     diff       lwr       upr     p adj
## CBT-no.therapy 0.3222222 0.0624132 0.5820312 0.0186602</code></pre>
<p>The output here is (I hope) pretty straightforward. The first comparison, for example, is the Anxifree versus placebo difference, and the first part of the output indicates that the observed difference in group means is <span class="math inline">\(.27\)</span>. The next two numbers indicate that the 95% (simultaneous) confidence interval for this comparison runs from <span class="math inline">\(-.12\)</span> to <span class="math inline">\(.65\)</span>. Because the confidence interval for the difference includes 0, we cannot reject the null hypothesis that the two group means are identical, and so we’re not all that surprised to see that the adjusted <span class="math inline">\(p\)</span>-value is <span class="math inline">\(.21\)</span>. In contrast, if you look at the next line, we see that the observed difference between Joyzepam and the placebo is 1.03, and the 95% confidence interval runs from <span class="math inline">\(.64\)</span> to <span class="math inline">\(1.42\)</span>. Because the interval excludes 0, we see that the result is significant <span class="math inline">\((p&lt;.001)\)</span>.</p>
<p>So far, so good. What about the situation where your model includes interaction terms? For instance, in <code>model.3</code> we allowed for the possibility that there is an interaction between drug and therapy. If that’s the case, the number of pairwise comparisons that we need to consider starts to increase. As before, we need to consider the three comparisons that are relevant to the main effect of <code>drug</code> and the one comparison that is relevant to the main effect of <code>therapy</code>. But, if we want to consider the possibility of a significant interaction (and try to find the group differences that underpin that significant interaction), we need to include comparisons such as the following:</p>
<ul>
<li>The difference in mood gain for people given Anxifree and treated with CBT, versus people given the placebo and treated with CBT</li>
<li>The difference in mood gain for people given Anxifree and given no therapy, versus people given the placebo and given no therapy.</li>
<li>etc</li>
</ul>
<p>There are quite a lot of these comparisons that you need to consider. So, when we run the <code>TukeyHSD()</code> command for <code>model.3</code> we see that it has made a <em>lot</em> of pairwise comparisons (19 in total). Here’s the output:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">TukeyHSD</span>( model.<span class="dv">3</span> )</code></pre></div>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = mood.gain ~ drug * therapy, data = clin.trial)
## 
## $drug
##                        diff         lwr       upr     p adj
## anxifree-placebo  0.2666667 -0.09273475 0.6260681 0.1597148
## joyzepam-placebo  1.0333333  0.67393191 1.3927348 0.0000160
## joyzepam-anxifree 0.7666667  0.40726525 1.1260681 0.0002740
## 
## $therapy
##                     diff        lwr       upr    p adj
## CBT-no.therapy 0.3222222 0.08256504 0.5618794 0.012617
## 
## $`drug:therapy`
##                                                diff          lwr
## anxifree:no.therapy-placebo:no.therapy   0.10000000 -0.539927728
## joyzepam:no.therapy-placebo:no.therapy   1.16666667  0.526738939
## placebo:CBT-placebo:no.therapy           0.30000000 -0.339927728
## anxifree:CBT-placebo:no.therapy          0.73333333  0.093405606
## joyzepam:CBT-placebo:no.therapy          1.20000000  0.560072272
## joyzepam:no.therapy-anxifree:no.therapy  1.06666667  0.426738939
## placebo:CBT-anxifree:no.therapy          0.20000000 -0.439927728
## anxifree:CBT-anxifree:no.therapy         0.63333333 -0.006594394
## joyzepam:CBT-anxifree:no.therapy         1.10000000  0.460072272
## placebo:CBT-joyzepam:no.therapy         -0.86666667 -1.506594394
## anxifree:CBT-joyzepam:no.therapy        -0.43333333 -1.073261061
## joyzepam:CBT-joyzepam:no.therapy         0.03333333 -0.606594394
## anxifree:CBT-placebo:CBT                 0.43333333 -0.206594394
## joyzepam:CBT-placebo:CBT                 0.90000000  0.260072272
## joyzepam:CBT-anxifree:CBT                0.46666667 -0.173261061
##                                                upr     p adj
## anxifree:no.therapy-placebo:no.therapy   0.7399277 0.9940083
## joyzepam:no.therapy-placebo:no.therapy   1.8065944 0.0005667
## placebo:CBT-placebo:no.therapy           0.9399277 0.6280049
## anxifree:CBT-placebo:no.therapy          1.3732611 0.0218746
## joyzepam:CBT-placebo:no.therapy          1.8399277 0.0004380
## joyzepam:no.therapy-anxifree:no.therapy  1.7065944 0.0012553
## placebo:CBT-anxifree:no.therapy          0.8399277 0.8917157
## anxifree:CBT-anxifree:no.therapy         1.2732611 0.0529812
## joyzepam:CBT-anxifree:no.therapy         1.7399277 0.0009595
## placebo:CBT-joyzepam:no.therapy         -0.2267389 0.0067639
## anxifree:CBT-joyzepam:no.therapy         0.2065944 0.2750590
## joyzepam:CBT-joyzepam:no.therapy         0.6732611 0.9999703
## anxifree:CBT-placebo:CBT                 1.0732611 0.2750590
## joyzepam:CBT-placebo:CBT                 1.5399277 0.0050693
## joyzepam:CBT-anxifree:CBT                1.1065944 0.2139229</code></pre>
<p>It looks pretty similar to before, but with a lot more comparisons made.</p>
</div>
<div id="plannedcomparisons" class="section level2">
<h2><span class="header-section-number">16.9</span> The method of planned comparisons</h2>
<p>Okay, I have a confession to make. I haven’t had time to write this section, but I think the method of planned comparisons is important enough to deserve a quick discussion. In our discussions of multiple comparisons, in the previous section and back in Chapter <a href="anova.html#anova">14</a>, I’ve been assuming that the tests you want to run are genuinely post hoc. For instance, in our drugs example above, maybe you thought that the drugs would all have different effects on mood (i.e., you hypothesised a main effect of drug), but you didn’t have any specific hypothesis about how they would be different, nor did you have any real idea about <em>which</em> pairwise comparisons would be worth looking at. If that is the case, then you really have to resort to something like Tukey’s HSD to do your pairwise comparisons.</p>
<p>The situation is rather different, however, if you genuinely did have real, specific hypotheses about which comparisons are of interest, and you <em>never</em> <em>ever</em> have any intention to look at any other comparisons besides the ones that you specified ahead of time. When this is true, and if you honestly and rigourously stick to your noble intentions to not run any other comparisons (even when the data look like they’re showing you deliciously significant effects for stuff you didn’t have a hypothesis test for), then it doesn’t really make a lot of sense to run something like Tukey’s HSD, because it makes corrections for a whole bunch of comparisons that you never cared about and never had any intention of looking at. Under those circumstances, you can safely run a (limited) number of hypothesis tests without making an adjustment for multiple testing. This situation is known as the <strong><em>method of planned comparisons</em></strong>, and it is sometimes used in clinical trials. In a later version of this book, I would like to talk a lot more about planned comparisons.</p>
</div>
<div id="unbalancedanova" class="section level2">
<h2><span class="header-section-number">16.10</span> Factorial ANOVA 3: unbalanced designs</h2>
<p>Factorial ANOVA is a very handy thing to know about. It’s been one of the standard tools used to analyse experimental data for many decades, and you’ll find that you can’t read more than two or three papers in psychology without running into an ANOVA in there somewhere. However, there’s one huge difference between the ANOVAs that you’ll see in a lot of real scientific articles and the ANOVA that I’ve just described: in real life, we’re rarely lucky enough to have perfectly balanced designs. For one reason or another, it’s typical to end up with more observations in some cells than in others. Or, to put it another way, we have an <strong><em>unbalanced design</em></strong>.</p>
<p>Unbalanced designs need to be treated with a lot more care than balanced designs, and the statistical theory that underpins them is a lot messier. It might be a consequence of this messiness, or it might be a shortage of time, but my experience has been that undergraduate research methods classes in psychology have a nasty tendency to ignore this issue completely. A lot of stats textbooks tend to gloss over it too. The net result of this, I think, is that a lot of active researchers in the field don’t actually know that there’s several different “types” of unbalanced ANOVAs, and they produce quite different answers. In fact, reading the psychological literature, I’m kind of amazed at the fact that most people who report the results of an unbalanced factorial ANOVA don’t actually give you enough details to reproduce the analysis: I secretly suspect that most people don’t even realise that their statistical software package is making a whole lot of substantive data analysis decisions on their behalf. It’s actually a little terrifying, when you think about it. So, if you want to avoid handing control of your data analysis to stupid software, read on…</p>
<div id="the-coffee-data" class="section level3">
<h3><span class="header-section-number">16.10.1</span> The coffee data</h3>
<p>As usual, it will help us to work with some data. The <code>coffee.Rdata</code> file contains a hypothetical data set (the <code>coffee</code> data frame) that produces an unbalanced <span class="math inline">\(3 \times 2\)</span> ANOVA. Suppose we were interested in finding out whether or not the tendency of people to <code>babble</code> when they have too much coffee is purely an effect of the coffee itself, or whether there’s some effect of the <code>milk</code> and <code>sugar</code> that people add to the coffee. Suppose we took 18 people, and gave them some coffee to drink. The amount of coffee / caffeine was held constant, and we varied whether or not milk was added: so <code>milk</code> is a binary factor with two levels, <code>&quot;yes&quot;</code> and <code>&quot;no&quot;</code>. We also varied the kind of sugar involved. The coffee might contain <code>&quot;real&quot;</code> sugar, or it might contain <code>&quot;fake&quot;</code> sugar (i.e., artificial sweetener), or it might contain <code>&quot;none&quot;</code> at all, so the <code>sugar</code> variable is a three level factor. Our outcome variable is a continuous variable that presumably refers to some psychologically sensible measure of the extent to which someone is “babbling”. The details don’t really matter for our purpose. To get a sense of what the data look like, we use the <code>some()</code> function in the <code>car</code> package. The <code>some()</code> function randomly picks a few of the observations in the data frame to print out, which is often very handy:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">load</span>(<span class="kw">file.path</span>(projecthome, <span class="st">&quot;data&quot;</span>,<span class="st">&quot;coffee.Rdata&quot;</span>))
 <span class="kw">some</span>( coffee )</code></pre></div>
<pre><code>##    milk sugar babble
## 2    no  fake    4.4
## 4   yes  real    5.6
## 5   yes  real    5.1
## 7   yes  none    3.9
## 9   yes  none    3.7
## 10   no  fake    5.6
## 12  yes  fake    5.9
## 13   no  real    6.0
## 14   no  real    5.4
## 17   no  none    5.3</code></pre>
<p>If we use the <code>aggregate()</code> function to quickly produce a table of means, we get a strong impression that there are differences between the groups:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">aggregate</span>( babble <span class="op">~</span><span class="st"> </span>milk <span class="op">+</span><span class="st"> </span>sugar, coffee, mean )</code></pre></div>
<pre><code>##   milk sugar babble
## 1  yes  none  3.700
## 2   no  none  5.550
## 3  yes  fake  5.800
## 4   no  fake  4.650
## 5  yes  real  5.100
## 6   no  real  5.875</code></pre>
<p>This is especially true when we compare these means to the standard deviations for the <code>babble</code> variable, which you can calculate using <code>aggregate()</code> in much the same way. Across groups, this standard deviation varies from .14 to .71, which is fairly small relative to the differences in group means.<a href="#fn247" class="footnoteRef" id="fnref247"><sup>247</sup></a> So far, it’s looking like a straightforward factorial ANOVA, just like we did earlier. The problem arises when we check to see how many observations we have in each group:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">xtabs</span>( <span class="op">~</span><span class="st"> </span>milk <span class="op">+</span><span class="st"> </span>sugar, coffee )</code></pre></div>
<pre><code>##      sugar
## milk  none fake real
##   yes    3    2    3
##   no     2    4    4</code></pre>
<p>This violates one of our original assumptions, namely that the number of people in each group is the same. We haven’t really discussed how to handle this situation.</p>
</div>
<div id="standard-anova-does-not-exist-for-unbalanced-designs" class="section level3">
<h3><span class="header-section-number">16.10.2</span> “Standard ANOVA” does not exist for unbalanced designs</h3>
<p>Unbalanced designs lead us to the somewhat unsettling discovery that there isn’t really any one thing that we might refer to as a standard ANOVA. In fact, it turns out that there are <em>three</em> fundamentally different ways<a href="#fn248" class="footnoteRef" id="fnref248"><sup>248</sup></a> in which you might want to run an ANOVA in an unbalanced design. If you have a balanced design, all three versions produce identical results, with the sums of squares, <span class="math inline">\(F\)</span>-values etc all conforming to the formulas that I gave at the start of the chapter. However, when your design is unbalanced they don’t give the same answers. Furthermore, they are not all equally appropriate to every situation: some methods will be more appropriate to your situation than others. Given all this, it’s important to understand what the different types of ANOVA are and how they differ from one another.</p>
<p>The first kind of ANOVA is conventionally referred to as <strong><em>Type I sum of squares</em></strong>. I’m sure you can guess what they other two are called. The “sum of squares” part of the name was introduced by the SAS statistical software package, and has become standard nomenclature, but it’s a bit misleading in some ways. I think the logic for referring to them as different types of sum of squares is that, when you look at the ANOVA tables that they produce, the key difference in the numbers is the SS values. The degrees of freedom don’t change, the MS values are still defined as SS divided by df, etc. However, what the terminology gets wrong is that it hides the reason <em>why</em> the SS values are different from one another. To that end, it’s a lot more helpful to think of the three different kinds of ANOVA as three different <em>hypothesis testing strategies</em>. These different strategies lead to different SS values, to be sure, but it’s the strategy that is the important thing here, not the SS values themselves. Recall from Section <a href="anova2.html#omnibusF">16.5</a> and <a href="anova2.html#anovalm">16.6</a> that any particular <span class="math inline">\(F\)</span>-test is best thought of as a comparison between two linear models. So when you’re looking at an ANOVA table, it helps to remember that each of those <span class="math inline">\(F\)</span>-tests corresponds to a <em>pair</em> of models that are being compared. Of course, this leads naturally to the question of <em>which</em> pair of models is being compared. This is the fundamental difference between ANOVA Types I, II and III: each one corresponds to a different way of choosing the model pairs for the tests.</p>
</div>
<div id="type-i-sum-of-squares" class="section level3">
<h3><span class="header-section-number">16.10.3</span> Type I sum of squares</h3>
<p>The Type I method is sometimes referred to as the “sequential” sum of squares, because it involves a process of adding terms to the model one at a time. Consider the coffee data, for instance. Suppose we want to run the full <span class="math inline">\(3 \times 2\)</span> factorial ANOVA, including interaction terms. The full model, as we’ve discussed earlier, is expressed by the R formula <code>babble ~ sugar + milk + sugar:milk</code>, though we often shorten it by using the <code>sugar * milk</code> notation. The Type I strategy builds this model up sequentially, starting from the simplest possible model and gradually adding terms.</p>
<p>The simplest possible model for the data would be one in which neither milk nor sugar is assumed to have any effect on babbling. The only term that would be included in such a model is the intercept, and in R formula notation we would write it as <code>babble ~ 1</code>. This is our initial null hypothesis. The next simplest model for the data would be one in which only one of the two main effects is included. In the coffee data, there are two different possible choices here, because we could choose to add milk first or to add sugar first (pardon the pun). The order actually turns out to matter, as we’ll see later, but for now let’s just make a choice arbitrarily, and pick sugar. So the second model in our sequence of models is <code>babble ~ sugar</code>, and it forms the alternative hypothesis for our first test. We now have our first hypothesis test:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
                   <span class="op">~</span>V1,                <span class="op">~</span>V2,
         <span class="st">&quot;Null model:&quot;</span>,     <span class="st">&quot;`babble ~ 1`&quot;</span>,
  <span class="st">&quot;Alternative model:&quot;</span>, <span class="st">&quot;`babble ~ sugar`&quot;</span>
  ), <span class="dt">col.names=</span> <span class="kw">c</span>(<span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>))</code></pre></div>
<table>
<tbody>
<tr class="odd">
<td align="left">Null model:</td>
<td align="left"><code>babble ~ 1</code></td>
</tr>
<tr class="even">
<td align="left">Alternative model:</td>
<td align="left"><code>babble ~ sugar</code></td>
</tr>
</tbody>
</table>
<p>This comparison forms our hypothesis test of the main effect of <code>sugar</code>. The next step in our model building exercise it to add the other main effect term, so the next model in our sequence is <code>babble ~ sugar + milk</code>. The second hypothesis test is then formed by comparing the following pair of models:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
                   <span class="op">~</span>V1,                <span class="op">~</span>V2,
         <span class="st">&quot;Null model:&quot;</span>,     <span class="st">&quot;`babble ~ sugar`&quot;</span>,
  <span class="st">&quot;Alternative model:&quot;</span>, <span class="st">&quot;`babble ~ sugar + milk`&quot;</span>
  ), <span class="dt">col.names=</span> <span class="kw">c</span>(<span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>))</code></pre></div>
<table>
<tbody>
<tr class="odd">
<td align="left">Null model:</td>
<td align="left"><code>babble ~ sugar</code></td>
</tr>
<tr class="even">
<td align="left">Alternative model:</td>
<td align="left"><code>babble ~ sugar + milk</code></td>
</tr>
</tbody>
</table>
<p>This comparison forms our hypothesis test of the main effect of <code>milk</code>. In one sense, this approach is very elegant: the alternative hypothesis from the first test forms the null hypothesis for the second one. It is in this sense that the Type I method is strictly sequential. Every test builds directly on the results of the last one. However, in another sense it’s very inelegant, because there’s a strong asymmetry between the two tests. The test of the main effect of <code>sugar</code> (the first test) completely ignores <code>milk</code>, whereas the test of the main effect of <code>milk</code> (the second test) does take <code>sugar</code> into account. In any case, the fourth model in our sequence is now the full model, <code>babble ~ sugar + milk + sugar:milk</code>, and the corresponding hypothesis test is</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
                   <span class="op">~</span>V1,                <span class="op">~</span>V2,
         <span class="st">&quot;Null model:&quot;</span>,     <span class="st">&quot;`babble ~ sugar + milk`&quot;</span>,
  <span class="st">&quot;Alternative model:&quot;</span>, <span class="st">&quot;`babble ~ sugar + milk + sugar:milk`&quot;</span>
  ), <span class="dt">col.names=</span> <span class="kw">c</span>(<span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>))</code></pre></div>
<table>
<tbody>
<tr class="odd">
<td align="left">Null model:</td>
<td align="left"><code>babble ~ sugar + milk</code></td>
</tr>
<tr class="even">
<td align="left">Alternative model:</td>
<td align="left"><code>babble ~ sugar + milk + sugar:milk</code></td>
</tr>
</tbody>
</table>
<p>Type I sum of squares is the default hypothesis testing method used by the <code>anova()</code> function, so it’s easy to produce the results from a Type I analysis. We just type in the same commands that we always did. Since we’ve now reached the point that we don’t need to hide the fact that ANOVA and regression are both linear models, I’ll use the <code>lm()</code> function to run the analyses:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> mod &lt;-<span class="st"> </span><span class="kw">lm</span>( babble <span class="op">~</span><span class="st"> </span>sugar <span class="op">+</span><span class="st"> </span>milk <span class="op">+</span><span class="st"> </span>sugar<span class="op">:</span>milk, coffee )
 <span class="kw">anova</span>( mod )</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: babble
##            Df Sum Sq Mean Sq F value   Pr(&gt;F)   
## sugar       2 3.5575 1.77876  6.7495 0.010863 * 
## milk        1 0.9561 0.95611  3.6279 0.081061 . 
## sugar:milk  2 5.9439 2.97193 11.2769 0.001754 **
## Residuals  12 3.1625 0.26354                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Leaving aside for one moment the question of how this result should be interpreted, let’s take note of the fact that our three <span class="math inline">\(p\)</span>-values are <span class="math inline">\(.0109\)</span>, <span class="math inline">\(.0811\)</span> and <span class="math inline">\(.0018\)</span> respectively. Next, let’s see if we can replicate the analysis using tools that we’re a little more familiar with. First, let’s fit all four models:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> mod.<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">lm</span>( babble <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, coffee )
 mod.<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">lm</span>( babble <span class="op">~</span><span class="st"> </span>sugar, coffee )
 mod.<span class="dv">3</span> &lt;-<span class="st"> </span><span class="kw">lm</span>( babble <span class="op">~</span><span class="st"> </span>sugar <span class="op">+</span><span class="st"> </span>milk, coffee )
 mod.<span class="dv">4</span> &lt;-<span class="st"> </span><span class="kw">lm</span>( babble <span class="op">~</span><span class="st"> </span>sugar <span class="op">+</span><span class="st"> </span>milk <span class="op">+</span><span class="st"> </span>sugar<span class="op">:</span>milk, coffee )</code></pre></div>
<p>To run the first hypothesis test comparing <code>mod.1</code> to <code>mod.2</code> we can use the command <code>anova(mod.1, mod.2)</code> in much the same way that we did in Section <a href="anova2.html#omnibusF">16.5</a>. Similarly, we can use the commands <code>anova(mod.2, mod.3)</code> and <code>anova(mod.3, mod.4)</code> and to run the second and third hypothesis tests. However, rather than run each of those commands separately, we can enter the full sequence of models like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">anova</span>( mod.<span class="dv">1</span>, mod.<span class="dv">2</span>, mod.<span class="dv">3</span>, mod.<span class="dv">4</span> )</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: babble ~ 1
## Model 2: babble ~ sugar
## Model 3: babble ~ sugar + milk
## Model 4: babble ~ sugar + milk + sugar:milk
##   Res.Df     RSS Df Sum of Sq       F   Pr(&gt;F)   
## 1     17 13.6200                                 
## 2     15 10.0625  2    3.5575  6.7495 0.010863 * 
## 3     14  9.1064  1    0.9561  3.6279 0.081061 . 
## 4     12  3.1625  2    5.9439 11.2769 0.001754 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>This output is rather more verbose than the last one, but it’s telling essentially the same story.<a href="#fn249" class="footnoteRef" id="fnref249"><sup>249</sup></a></p>
<p>The big problem with using Type I sum of squares is the fact that it really does depend on the order in which you enter the variables. Yet, in many situations the researcher has no reason to prefer one ordering over another. This is presumably the case for our milk and sugar problem. Should we add milk first, or sugar first? It feels exactly as arbitrary as a data analysis question as it does as a coffee-making question. There may in fact be some people with firm opinions about ordering, but it’s hard to imagine a principled answer to the question. Yet, look what happens when we change the ordering:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> mod &lt;-<span class="st"> </span><span class="kw">lm</span>( babble <span class="op">~</span><span class="st">  </span>milk <span class="op">+</span><span class="st"> </span>sugar <span class="op">+</span><span class="st"> </span>sugar<span class="op">:</span>milk, coffee )
 <span class="kw">anova</span>( mod )</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: babble
##            Df Sum Sq Mean Sq F value   Pr(&gt;F)   
## milk        1 1.4440 1.44400  5.4792 0.037333 * 
## sugar       2 3.0696 1.53482  5.8238 0.017075 * 
## milk:sugar  2 5.9439 2.97193 11.2769 0.001754 **
## Residuals  12 3.1625 0.26354                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The <span class="math inline">\(p\)</span>-values for both main effect terms have changed, and fairly dramatically. Among other things, the effect of <code>milk</code> has become significant (though one should avoid drawing any strong conclusions about this, as I’ve mentioned previously). Which of these two ANOVAs should one report? It’s not immediately obvious.</p>
<p>When you look at the hypothesis tests that are used to define the “first” main effect and the “second” one, it’s clear that they’re qualitatively different from one another. In our initial example, we saw that the test for the main effect of <code>sugar</code> completely ignores <code>milk</code>, whereas the test of the main effect of <code>milk</code> does take <code>sugar</code> into account. As such, the Type I testing strategy really does treat the first main effect as if it had a kind of theoretical primacy over the second one. In my experience there is very rarely if ever any theoretically primacy of this kind that would justify treating any two main effects asymmetrically.</p>
<p>The consequence of all this is that Type I tests are very rarely of much interest, and so we should move on to discuss Type II tests and Type III tests. However, for the sake of completeness – on the off chance that you ever find yourself needing to run Type I tests – I’ll comment briefly on how R determines the ordering of terms in a Type I test. The key principle in Type I sum of squares is that the hypothesis testing be sequential, with terms added one at a time. However, it does also imply that main effects be added first (e.g., factors <code>A</code>, <code>B</code>, <code>C</code> etc), followed by first order interaction terms (e.g., terms like <code>A:B</code> and <code>B:C</code>), then second order interactions (e.g., <code>A:B:C</code>) and so on. Within each “block” you can specify whatever order you like. So, for instance, if we specified our model using a command like this,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> mod &lt;-<span class="st"> </span><span class="kw">lm</span>( outcome <span class="op">~</span><span class="st"> </span>A <span class="op">+</span><span class="st"> </span>B <span class="op">+</span><span class="st"> </span>C <span class="op">+</span><span class="st"> </span>B<span class="op">:</span>C <span class="op">+</span><span class="st"> </span>A<span class="op">:</span>B <span class="op">+</span><span class="st"> </span>A<span class="op">:</span>C )</code></pre></div>
<p>and then used <code>anova(mod)</code> to produce sequential hypothesis tests, what we’d see is that the main effect terms would be entered <code>A</code> then <code>B</code> and then <code>C</code>, but then the interactions would be entered in the order <code>B:C</code> first, then <code>A:B</code> and then finally <code>A:C</code>. Reordering the terms within each group will change the ordering, as we saw earlier. However, changing the order of terms across blocks has no effect. For instance, if we tried to move the interaction term <code>B:C</code> to the front, like this,</p>
<pre reval="FALSE"><code> mod &lt;- lm( outcome ~ B:C + A + B + C + A:B + A:C )</code></pre>
<p>it would have no effect. R would still enter the terms in the same order as last time. If for some reason you really, really need an interaction term to be entered first, then you have to do it the long way, creating each model manually using a separate <code>lm()</code> command and then using a command like <code>anova(mod.1, mod.2, mod.3, mod.4)</code> to force R to enter them in the order that you want.</p>
</div>
<div id="type-iii-sum-of-squares" class="section level3">
<h3><span class="header-section-number">16.10.4</span> Type III sum of squares</h3>
<p>Having just finished talking about Type I tests, you might think that the natural thing to do next would be to talk about Type II tests. However, I think it’s actually a bit more natural to discuss Type III tests (which are simple) before talking about Type II tests (which are trickier). The basic idea behind Type III tests is extremely simple: regardless of which term you’re trying to evaluate, run the <span class="math inline">\(F\)</span>-test in which the alternative hypothesis corresponds to the full ANOVA model as specified by the user, and the null model just deletes that one term that you’re testing. For instance, in the coffee example, in which our full model was <code>babble ~ sugar + milk + sugar:milk</code>, the test for a main effect of <code>sugar</code> would correspond to a comparison between the following two models:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
                   <span class="op">~</span>V1,                <span class="op">~</span>V2,
         <span class="st">&quot;Null model:&quot;</span>,     <span class="st">&quot;`babble ~ milk + sugar:milk`&quot;</span>,
  <span class="st">&quot;Alternative model:&quot;</span>, <span class="st">&quot;`babble ~ sugar + milk + sugar:milk`&quot;</span>
  ), <span class="dt">col.names=</span> <span class="kw">c</span>(<span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>))</code></pre></div>
<table>
<tbody>
<tr class="odd">
<td align="left">Null model:</td>
<td align="left"><code>babble ~ milk + sugar:milk</code></td>
</tr>
<tr class="even">
<td align="left">Alternative model:</td>
<td align="left"><code>babble ~ sugar + milk + sugar:milk</code></td>
</tr>
</tbody>
</table>
<p>Similarly the main effect of <code>milk</code> is evaluated by testing the full model against a null model that removes the <code>milk</code> term, like so:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
                   <span class="op">~</span>V1,                <span class="op">~</span>V2,
         <span class="st">&quot;Null model:&quot;</span>,     <span class="st">&quot;`babble ~ sugar + sugar:milk`&quot;</span>,
  <span class="st">&quot;Alternative model:&quot;</span>, <span class="st">&quot;`babble ~ sugar + milk + sugar:milk`&quot;</span>
  ), <span class="dt">col.names=</span> <span class="kw">c</span>(<span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>))</code></pre></div>
<table>
<tbody>
<tr class="odd">
<td align="left">Null model:</td>
<td align="left"><code>babble ~ sugar + sugar:milk</code></td>
</tr>
<tr class="even">
<td align="left">Alternative model:</td>
<td align="left"><code>babble ~ sugar + milk + sugar:milk</code></td>
</tr>
</tbody>
</table>
<p>Finally, the interaction term <code>sugar:milk</code> is evaluated in exactly the same way. Once again, we test the full model against a null model that removes the <code>sugar:milk</code> interaction term, like so:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
                   <span class="op">~</span>V1,                <span class="op">~</span>V2,
         <span class="st">&quot;Null model:&quot;</span>,     <span class="st">&quot;`babble ~ sugar + milk`&quot;</span>,
  <span class="st">&quot;Alternative model:&quot;</span>, <span class="st">&quot;`babble ~ sugar + milk + sugar:milk`&quot;</span>
  ), <span class="dt">col.names=</span> <span class="kw">c</span>(<span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>))</code></pre></div>
<table>
<tbody>
<tr class="odd">
<td align="left">Null model:</td>
<td align="left"><code>babble ~ sugar + milk</code></td>
</tr>
<tr class="even">
<td align="left">Alternative model:</td>
<td align="left"><code>babble ~ sugar + milk + sugar:milk</code></td>
</tr>
</tbody>
</table>
<p>The basic idea generalises to higher order ANOVAs. For instance, suppose that we were trying to run an ANOVA with three factors, <code>A</code>, <code>B</code> and <code>C</code>, and we wanted to consider all possible main effects and all possible interactions, including the three way interaction <code>A:B:C</code>. The table below shows you what the Type III tests look like for this situation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
                     <span class="op">~</span>V1,                                 <span class="op">~</span>V2,                                     <span class="op">~</span>V3,

                   <span class="st">&quot;`A`&quot;</span>, <span class="st">&quot;`B + C + A:B + A:C + B:C + A:B:C`&quot;</span>, <span class="st">&quot;`A + B + C + A:B + A:C + B:C + A:B:C`&quot;</span>,
                   <span class="st">&quot;`B`&quot;</span>, <span class="st">&quot;`A + C + A:B + A:C + B:C + A:B:C`&quot;</span>, <span class="st">&quot;`A + B + C + A:B + A:C + B:C + A:B:C`&quot;</span>,
                   <span class="st">&quot;`C`&quot;</span>, <span class="st">&quot;`A + B + A:B + A:C + B:C + A:B:C`&quot;</span>, <span class="st">&quot;`A + B + C + A:B + A:C + B:C + A:B:C`&quot;</span>,
                 <span class="st">&quot;`A:B`&quot;</span>,   <span class="st">&quot;`A + B + C + A:C + B:C + A:B:C`&quot;</span>, <span class="st">&quot;`A + B + C + A:B + A:C + B:C + A:B:C`&quot;</span>,
                 <span class="st">&quot;`A:C`&quot;</span>,   <span class="st">&quot;`A + B + C + A:B + B:C + A:B:C`&quot;</span>, <span class="st">&quot;`A + B + C + A:B + A:C + B:C + A:B:C`&quot;</span>,
                 <span class="st">&quot;`B:C`&quot;</span>,   <span class="st">&quot;`A + B + C + A:B + A:C + A:B:C`&quot;</span>, <span class="st">&quot;`A + B + C + A:B + A:C + B:C + A:B:C`&quot;</span>,
               <span class="st">&quot;`A:B:C`&quot;</span>,     <span class="st">&quot;`A + B + C + A:B + A:C + B:C`&quot;</span>, <span class="st">&quot;`A + B + C + A:B + A:C + B:C + A:B:C`&quot;</span>
  ), <span class="dt">col.names =</span> <span class="kw">c</span>(  <span class="st">&quot;Term being tested is&quot;</span>,     <span class="st">&quot;Null model is `outcome ~ ...`&quot;</span>,  <span class="st">&quot;Alternative model is `outcome ~ ...`&quot;</span>))</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Term being tested is</th>
<th align="left">Null model is <code>outcome ~ ...</code></th>
<th align="left">Alternative model is <code>outcome ~ ...</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>A</code></td>
<td align="left"><code>B + C + A:B + A:C + B:C + A:B:C</code></td>
<td align="left"><code>A + B + C + A:B + A:C + B:C + A:B:C</code></td>
</tr>
<tr class="even">
<td align="left"><code>B</code></td>
<td align="left"><code>A + C + A:B + A:C + B:C + A:B:C</code></td>
<td align="left"><code>A + B + C + A:B + A:C + B:C + A:B:C</code></td>
</tr>
<tr class="odd">
<td align="left"><code>C</code></td>
<td align="left"><code>A + B + A:B + A:C + B:C + A:B:C</code></td>
<td align="left"><code>A + B + C + A:B + A:C + B:C + A:B:C</code></td>
</tr>
<tr class="even">
<td align="left"><code>A:B</code></td>
<td align="left"><code>A + B + C + A:C + B:C + A:B:C</code></td>
<td align="left"><code>A + B + C + A:B + A:C + B:C + A:B:C</code></td>
</tr>
<tr class="odd">
<td align="left"><code>A:C</code></td>
<td align="left"><code>A + B + C + A:B + B:C + A:B:C</code></td>
<td align="left"><code>A + B + C + A:B + A:C + B:C + A:B:C</code></td>
</tr>
<tr class="even">
<td align="left"><code>B:C</code></td>
<td align="left"><code>A + B + C + A:B + A:C + A:B:C</code></td>
<td align="left"><code>A + B + C + A:B + A:C + B:C + A:B:C</code></td>
</tr>
<tr class="odd">
<td align="left"><code>A:B:C</code></td>
<td align="left"><code>A + B + C + A:B + A:C + B:C</code></td>
<td align="left"><code>A + B + C + A:B + A:C + B:C + A:B:C</code></td>
</tr>
</tbody>
</table>
<p>As ugly as that table looks, it’s pretty simple. In all cases, the alternative hypothesis corresponds to the full model, which contains three main effect terms (e.g. <code>A</code>), three first order interactions (e.g. <code>A:B</code>) and one second order interaction (i.e., <code>A:B:C</code>). The null model always contains 6 of thes 7 terms: and the missing one is the one whose significance we’re trying to test.</p>
<p>At first pass, Type III tests seem like a nice idea. Firstly, we’ve removed the asymmetry that caused us to have problems when running Type I tests. And because we’re now treating all terms the same way, the results of the hypothesis tests do not depend on the order in which we specify them. This is definitely a good thing. However, there is a big problem when interpreting the results of the tests, especially for main effect terms. Consider the coffee data. Suppose it turns out that the main effect of <code>milk</code> is not significant according to the Type III tests. What this is telling us is that <code>babble ~ sugar + sugar:milk</code> is a better model for the data than the full model. But what does that even <em>mean</em>? If the interaction term <code>sugar:milk</code> was also non-significant, we’d be tempted to conclude that the data are telling us that the only thing that matters is <code>sugar</code>. But suppose we have a significant interaction term, but a non-significant main effect of <code>milk</code>. In this case, are we to assume that there really is an “effect of sugar”, an “interaction between milk and sugar”, but no “effect of milk”? That seems crazy. The right answer simply <em>must</em> be that it’s meaningless<a href="#fn250" class="footnoteRef" id="fnref250"><sup>250</sup></a> to talk about the main effect if the interaction is significant. In general, this seems to be what most statisticians advise us to do, and I think that’s the right advice. But if it really is meaningless to talk about non-significant main effects in the presence of a significant interaction, then it’s not at all obvious why Type III tests should allow the null hypothesis to rely on a model that includes the interaction but omits one of the main effects that make it up. When characterised in this fashion, the null hypotheses really don’t make much sense at all.</p>
<p>Later on, we’ll see that Type III tests can be redeemed in some contexts, but I’d better show you how to actually compute a Type III ANOVA first. The <code>anova()</code> function in R does not directly support Type II tests or Type III tests. Technically, you <em>can</em> do it by creating the various models that form the null and alternative hypotheses for each test, and then using <code>anova()</code> to compare the models to one another. I outlined the gist of how that would be done when talking about Type I tests, but speaking from first hand experience<a href="#fn251" class="footnoteRef" id="fnref251"><sup>251</sup></a> I can tell you that it’s very tedious. In practice, the <code>anova()</code> function is only used to produce Type I tests or to compare specific models of particular interest (see Section <a href="anova2.html#omnibusF">16.5</a>). If you want Type II or Type III tests you need to use the <code>Anova()</code> function in the <code>car</code> package. It’s pretty easy to use, since there’s a <code>type</code> argument that you specify. So, to return to our coffee example, our Type III tests are run as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> mod &lt;-<span class="st"> </span><span class="kw">lm</span>( babble <span class="op">~</span><span class="st"> </span>sugar <span class="op">*</span><span class="st"> </span>milk, coffee )
 <span class="kw">Anova</span>( mod, <span class="dt">type=</span><span class="dv">3</span> )</code></pre></div>
<pre><code>## Anova Table (Type III tests)
## 
## Response: babble
##             Sum Sq Df F value   Pr(&gt;F)    
## (Intercept) 41.070  1 155.839 3.11e-08 ***
## sugar        5.880  2  11.156 0.001830 ** 
## milk         4.107  1  15.584 0.001936 ** 
## sugar:milk   5.944  2  11.277 0.001754 ** 
## Residuals    3.162 12                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>As you can see, I got lazy this time and used <code>sugar * milk</code> as a shorthand way of referring to <code>sugar + milk + sugar:milk</code>. The important point here is that this is just a regular ANOVA table, and we can see that our Type III tests are significant for all terms, even the intercept.</p>
<p>Except, as usual, it’s not that simple. One of the perverse features of the Type III testing strategy is that the results turn out to depend on the <em>contrasts</em> that you use to encode your factors (see Section <a href="anova2.html#contrasts">16.7</a> if you’ve forgotten what the different types of contrasts are). The results that I presented in the ANOVA table above are based on the R default, which is treatment contrasts; and as we’ll see later, this is usually a very poor choice if you want to run Type III tests. So let’s see what happens if switch to Helmert contrasts:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> my.contrasts &lt;-<span class="st"> </span><span class="kw">list</span>( <span class="dt">milk =</span> <span class="st">&quot;contr.Helmert&quot;</span>, <span class="dt">sugar =</span> <span class="st">&quot;contr.Helmert&quot;</span> )
 mod.H &lt;-<span class="st"> </span><span class="kw">lm</span>( babble <span class="op">~</span><span class="st"> </span>sugar <span class="op">*</span><span class="st"> </span>milk, coffee, <span class="dt">contrasts =</span> my.contrasts )
 <span class="kw">Anova</span>( mod.H, <span class="dt">type=</span><span class="dv">3</span> )</code></pre></div>
<pre><code>## Anova Table (Type III tests)
## 
## Response: babble
##             Sum Sq Df   F value    Pr(&gt;F)    
## (Intercept) 434.29  1 1647.8882 3.231e-14 ***
## sugar         2.13  2    4.0446  0.045426 *  
## milk          1.00  1    3.8102  0.074672 .  
## sugar:milk    5.94  2   11.2769  0.001754 ** 
## Residuals     3.16 12                        
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Oh, that’s not good at all. In the case of <code>milk</code> in particular, the <span class="math inline">\(p\)</span>-value has changed from .002 to .07. This is a pretty substantial difference, and hopefully it gives you a sense of how important it is that you take care when using Type III tests.</p>
<p>Okay, so if the <span class="math inline">\(p\)</span>-values that come out of Type III analyses are so sensitive to the choice of contrasts, does that mean that Type III tests are essentially arbitrary and not to be trusted? To some extent that’s true, and when we turn to a discussion of Type II tests we’ll see that Type II analyses avoid this arbitrariness entirely, but I think that’s too strong a conclusion. Firstly, it’s important to recognise that some choices of contrasts will always produce the same answers. Of particular importance is the fact that if the columns of our contrast matrix are all constrained to sum to zero, then the Type III analysis will always give the same answers. This means that you’ll get the same answers if you use <code>contr.Helmert</code> or <code>contr.sum</code> or <code>contr.poly</code>, but different answers for <code>contr.treatment</code> or <code>contr.SAS</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> random.contrasts &lt;-<span class="st"> </span><span class="kw">matrix</span>( <span class="kw">rnorm</span>(<span class="dv">6</span>), <span class="dv">3</span>, <span class="dv">2</span> )   <span class="co"># create a random matrix</span>
 random.contrasts[, <span class="dv">1</span>] &lt;-<span class="st"> </span>random.contrasts[, <span class="dv">1</span>] <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>( random.contrasts[, <span class="dv">1</span>] ) <span class="co"># contrast 1 sums to 0</span>
 random.contrasts[, <span class="dv">2</span>] &lt;-<span class="st"> </span>random.contrasts[, <span class="dv">2</span>] <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>( random.contrasts[, <span class="dv">2</span>] ) <span class="co"># contrast 2 sums to 0</span>
 random.contrasts  <span class="co"># print it to check that we really have an arbitrary contrast matrix...</span></code></pre></div>
<pre><code>##            [,1]       [,2]
## [1,] -0.4340623 -0.9359380
## [2,] -0.2459009  0.1507430
## [3,]  0.6799632  0.7851949</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">contrasts</span>( coffee<span class="op">$</span>sugar ) &lt;-<span class="st"> </span>random.contrasts <span class="co"># random contrasts for sugar</span>
 <span class="kw">contrasts</span>( coffee<span class="op">$</span>milk ) &lt;-<span class="st"> </span><span class="kw">contr.Helmert</span>(<span class="dv">2</span>)  <span class="co"># Helmert contrasts for the milk factor </span>
 mod.R &lt;-<span class="st"> </span><span class="kw">lm</span>( babble <span class="op">~</span><span class="st"> </span>sugar <span class="op">*</span><span class="st"> </span>milk, coffee )  <span class="co"># R will use the contrasts that we assigned</span>
 <span class="kw">Anova</span>( mod.R, <span class="dt">type =</span> <span class="dv">3</span> )                   </code></pre></div>
<pre><code>## Anova Table (Type III tests)
## 
## Response: babble
##             Sum Sq Df   F value    Pr(&gt;F)    
## (Intercept) 434.29  1 1647.8882 3.231e-14 ***
## sugar         2.13  2    4.0446  0.045426 *  
## milk          1.00  1    3.8102  0.074672 .  
## sugar:milk    5.94  2   11.2769  0.001754 ** 
## Residuals     3.16 12                        
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Yep, same answers.</p>
</div>
<div id="type-ii-sum-of-squares" class="section level3">
<h3><span class="header-section-number">16.10.5</span> Type II sum of squares</h3>
<p>Okay, so we’ve seen Type I and III tests now, and both are pretty straightforward: Type I tests are performed by gradually adding terms one at a time, whereas Type III tests are performed by taking the full model and looking to see what happens when you remove each term. However, both have some serious flaws: Type I tests are dependent on the order in which you enter the terms, and Type III tests are dependent on how you code up your contrasts. Because of these flaws, neither one is easy to interpret. Type II tests are a little harder to describe, but they avoid both of these problems, and as a result they are a little easier to interpret.</p>
<p>Type II tests are broadly similar to Type III tests: start with a “full” model, and test a particular term by deleting it from that model. However, Type II tests are based on the <strong><em>marginality principle</em></strong> which states that you should not omit a lower order term from your model if there are any higher order ones that depend on it. So, for instance, if your model contains the interaction <code>A:B</code> (a 2nd order term), then it really ought to contain the main effects <code>A</code> and <code>B</code> (1st order terms). Similarly, if it contains a three way interaction term <code>A:B:C</code>, then the model must also include the main effects <code>A</code>, <code>B</code> and <code>C</code> as well as the simpler interactions <code>A:B</code>, <code>A:C</code> and <code>B:C</code>. Type III tests routinely violate the marginality principle. For instance, consider the test of the main effect of <code>A</code> in the context of a three-way ANOVA that includes all possible interaction terms. According to Type III tests, our null and alternative models are:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
                   <span class="op">~</span>V1,                                               <span class="op">~</span>V2,
         <span class="st">&quot;Null model:&quot;</span>,     <span class="st">&quot;`outcome ~ B + C + A:B + A:C + B:C + A:B:C`&quot;</span>,
  <span class="st">&quot;Alternative model:&quot;</span>, <span class="st">&quot;`outcome ~ A + B + C + A:B + A:C + B:C + A:B:C`&quot;</span>
  ), <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>))</code></pre></div>
<table>
<tbody>
<tr class="odd">
<td align="left">Null model:</td>
<td align="left"><code>outcome ~ B + C + A:B + A:C + B:C + A:B:C</code></td>
</tr>
<tr class="even">
<td align="left">Alternative model:</td>
<td align="left"><code>outcome ~ A + B + C + A:B + A:C + B:C + A:B:C</code></td>
</tr>
</tbody>
</table>
<p>Notice that the null hypothesis omits <code>A</code>, but includes <code>A:B</code>, <code>A:C</code> and <code>A:B:C</code> as part of the model. This, according to the Type II tests, is not a good choice of null hypothesis. What we should do instead, if we want to test the null hypothesis that <code>A</code> is not relevant to our <code>outcome</code>, is to specify the null hypothesis that is the most complicated model that does not rely on <code>A</code> in any form, even as an interaction. The alternative hypothesis corresponds to this null model plus a main effect term of <code>A</code>. This is a lot closer to what most people would intuitively think of as a “main effect of <code>A</code>”, and it yields the following as our Type II test of the main effect of <code>A</code>.<a href="#fn252" class="footnoteRef" id="fnref252"><sup>252</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
                   <span class="op">~</span>V1,                                               <span class="op">~</span>V2,
         <span class="st">&quot;Null model:&quot;</span>,     <span class="st">&quot;`outcome ~ B + C + B:C`&quot;</span>,
  <span class="st">&quot;Alternative model:&quot;</span>, <span class="st">&quot;`outcome ~ A + B + C + B:C`&quot;</span>
  ), <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>))</code></pre></div>
<table>
<tbody>
<tr class="odd">
<td align="left">Null model:</td>
<td align="left"><code>outcome ~ B + C + B:C</code></td>
</tr>
<tr class="even">
<td align="left">Alternative model:</td>
<td align="left"><code>outcome ~ A + B + C + B:C</code></td>
</tr>
</tbody>
</table>
<p>Anyway, just to give you a sense of how the Type II tests play out, here’s the full table of tests that would be applied in a three-way factorial ANOVA:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
                     <span class="op">~</span>V1,                             <span class="op">~</span>V2,                                     <span class="op">~</span>V3,

                   <span class="st">&quot;`A`&quot;</span>,                 <span class="st">&quot;`B + C + B:C`&quot;</span>,                     <span class="st">&quot;`A + B + C + B:C`&quot;</span>,
                   <span class="st">&quot;`B`&quot;</span>,                 <span class="st">&quot;`A + C + A:C`&quot;</span>,                     <span class="st">&quot;`A + B + C + A:C`&quot;</span>,
                   <span class="st">&quot;`C`&quot;</span>,                 <span class="st">&quot;`A + B + A:B`&quot;</span>,                     <span class="st">&quot;`A + B + C + A:B`&quot;</span>,
                 <span class="st">&quot;`A:B`&quot;</span>,       <span class="st">&quot;`A + B + C + A:C + B:C`&quot;</span>,         <span class="st">&quot;`A + B + C + A:B + A:C + B:C`&quot;</span>,
                 <span class="st">&quot;`A:C`&quot;</span>,       <span class="st">&quot;`A + B + C + A:B + B:C`&quot;</span>,         <span class="st">&quot;`A + B + C + A:B + A:C + B:C`&quot;</span>,
                 <span class="st">&quot;`B:C`&quot;</span>,       <span class="st">&quot;`A + B + C + A:B + A:C`&quot;</span>,         <span class="st">&quot;`A + B + C + A:B + A:C + B:C`&quot;</span>,
               <span class="st">&quot;`A:B:C`&quot;</span>, <span class="st">&quot;`A + B + C + A:B + A:C + B:C`&quot;</span>, <span class="st">&quot;`A + B + C + A:B + A:C + B:C + A:B:C`&quot;</span>
  ), <span class="dt">col.names =</span> <span class="kw">c</span>(  <span class="st">&quot;Term being tested is&quot;</span>, <span class="st">&quot;Null model is `outcome ~ ...`&quot;</span>,  <span class="st">&quot;Alternative model is `outcome ~ ...`&quot;</span>))</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">Term being tested is</th>
<th align="left">Null model is <code>outcome ~ ...</code></th>
<th align="left">Alternative model is <code>outcome ~ ...</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>A</code></td>
<td align="left"><code>B + C + B:C</code></td>
<td align="left"><code>A + B + C + B:C</code></td>
</tr>
<tr class="even">
<td align="left"><code>B</code></td>
<td align="left"><code>A + C + A:C</code></td>
<td align="left"><code>A + B + C + A:C</code></td>
</tr>
<tr class="odd">
<td align="left"><code>C</code></td>
<td align="left"><code>A + B + A:B</code></td>
<td align="left"><code>A + B + C + A:B</code></td>
</tr>
<tr class="even">
<td align="left"><code>A:B</code></td>
<td align="left"><code>A + B + C + A:C + B:C</code></td>
<td align="left"><code>A + B + C + A:B + A:C + B:C</code></td>
</tr>
<tr class="odd">
<td align="left"><code>A:C</code></td>
<td align="left"><code>A + B + C + A:B + B:C</code></td>
<td align="left"><code>A + B + C + A:B + A:C + B:C</code></td>
</tr>
<tr class="even">
<td align="left"><code>B:C</code></td>
<td align="left"><code>A + B + C + A:B + A:C</code></td>
<td align="left"><code>A + B + C + A:B + A:C + B:C</code></td>
</tr>
<tr class="odd">
<td align="left"><code>A:B:C</code></td>
<td align="left"><code>A + B + C + A:B + A:C + B:C</code></td>
<td align="left"><code>A + B + C + A:B + A:C + B:C + A:B:C</code></td>
</tr>
</tbody>
</table>
<p>In the context of the two way ANOVA that we’ve been using in the coffee data, the hypothesis tests are even simpler. The main effect of <code>sugar</code> corresponds to an <span class="math inline">\(F\)</span>-test comparing these two models:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
                   <span class="op">~</span>V1,                                               <span class="op">~</span>V2,
         <span class="st">&quot;Null model:&quot;</span>,     <span class="st">&quot;`babble ~ milk`&quot;</span>,
  <span class="st">&quot;Alternative model:&quot;</span>, <span class="st">&quot;`babble ~ sugar + milk`&quot;</span>
  ), <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>))</code></pre></div>
<table>
<tbody>
<tr class="odd">
<td align="left">Null model:</td>
<td align="left"><code>babble ~ milk</code></td>
</tr>
<tr class="even">
<td align="left">Alternative model:</td>
<td align="left"><code>babble ~ sugar + milk</code></td>
</tr>
</tbody>
</table>
<p>The test for the main effect of <code>milk</code> is</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
                   <span class="op">~</span>V1,                                               <span class="op">~</span>V2,
         <span class="st">&quot;Null model:&quot;</span>,     <span class="st">&quot;`babble ~ sugar`&quot;</span>,
  <span class="st">&quot;Alternative model:&quot;</span>, <span class="st">&quot;`babble ~ sugar + milk`&quot;</span>
  ), <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>))</code></pre></div>
<table>
<tbody>
<tr class="odd">
<td align="left">Null model:</td>
<td align="left"><code>babble ~ sugar</code></td>
</tr>
<tr class="even">
<td align="left">Alternative model:</td>
<td align="left"><code>babble ~ sugar + milk</code></td>
</tr>
</tbody>
</table>
<p>Finally, the test for the interaction <code>sugar:milk</code> is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
                   <span class="op">~</span>V1,                                               <span class="op">~</span>V2,
         <span class="st">&quot;Null model:&quot;</span>,     <span class="st">&quot;`babble ~ sugar + milk`&quot;</span>,
  <span class="st">&quot;Alternative model:&quot;</span>, <span class="st">&quot;`babble ~ sugar + milk + sugar:milk`&quot;</span>
  ), <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>))</code></pre></div>
<table>
<tbody>
<tr class="odd">
<td align="left">Null model:</td>
<td align="left"><code>babble ~ sugar + milk</code></td>
</tr>
<tr class="even">
<td align="left">Alternative model:</td>
<td align="left"><code>babble ~ sugar + milk + sugar:milk</code></td>
</tr>
</tbody>
</table>
<p>Running the tests are again straightforward. We use the <code>Anova()</code> function, specifying <code>type=2</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> mod &lt;-<span class="st"> </span><span class="kw">lm</span>( babble <span class="op">~</span><span class="st">  </span>sugar<span class="op">*</span>milk, coffee )
 <span class="kw">Anova</span>( mod, <span class="dt">type =</span> <span class="dv">2</span> )</code></pre></div>
<pre><code>## Anova Table (Type II tests)
## 
## Response: babble
##            Sum Sq Df F value   Pr(&gt;F)   
## sugar      3.0696  2  5.8238 0.017075 * 
## milk       0.9561  1  3.6279 0.081061 . 
## sugar:milk 5.9439  2 11.2769 0.001754 **
## Residuals  3.1625 12                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Type II tests have some clear advantages over Type I and Type III tests. They don’t depend on the order in which you specify factors (unlike Type I), and they don’t depend on the contrasts that you use to specify your factors (unlike Type III). And although opinions may differ on this last point, and it will definitely depend on what you’re trying to do with your data, I do think that the hypothesis tests that they specify are more likely to correspond to something that you actually care about. As a consequence, I find that it’s usually easier to interpret the results of a Type II test than the results of a Type I or Type III test. For this reason, my tentative advice is that, if you can’t think of any obvious model comparisons that directly map onto your research questions but you still want to run an ANOVA in an unbalanced design, Type II tests are probably a better choice than Type I or Type III.<a href="#fn253" class="footnoteRef" id="fnref253"><sup>253</sup></a></p>
</div>
<div id="effect-sizes-and-non-additive-sums-of-squares" class="section level3">
<h3><span class="header-section-number">16.10.6</span> Effect sizes (and non-additive sums of squares)</h3>
<p>The <code>etaSquared()</code> function in the <code>lsr</code> package computes <span class="math inline">\(\eta^2\)</span> and partial <span class="math inline">\(\eta^2\)</span> values for unbalanced designs and for different Types of tests. It’s pretty straightforward. All you have to do is indicate which <code>type</code> of tests you’re doing,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">etaSquared</span>( mod, <span class="dt">type=</span><span class="dv">2</span> )</code></pre></div>
<pre><code>##                eta.sq eta.sq.part
## sugar      0.22537682   0.4925493
## milk       0.07019886   0.2321436
## sugar:milk 0.43640732   0.6527155</code></pre>
<p>and out pops the <span class="math inline">\(\eta^2\)</span> and partial <span class="math inline">\(\eta^2\)</span> values, as requested. However, when you’ve got an unbalanced design, there’s a bit of extra complexity involved. To see why, let’s expand the output from the <code>etaSquared()</code> function so that it displays the full ANOVA table:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> es &lt;-<span class="st"> </span><span class="kw">etaSquared</span>( mod, <span class="dt">type=</span><span class="dv">2</span>, <span class="dt">anova=</span><span class="ot">TRUE</span> )
 es</code></pre></div>
<pre><code>##                eta.sq eta.sq.part        SS df        MS         F
## sugar      0.22537682   0.4925493 3.0696323  2 1.5348161  5.823808
## milk       0.07019886   0.2321436 0.9561085  1 0.9561085  3.627921
## sugar:milk 0.43640732   0.6527155 5.9438677  2 2.9719339 11.276903
## Residuals  0.23219530          NA 3.1625000 12 0.2635417        NA
##                      p
## sugar      0.017075099
## milk       0.081060698
## sugar:milk 0.001754333
## Residuals           NA</code></pre>
<p>Okay, if you remember back to our very early discussions of ANOVA, one of the key ideas behind the sums of squares calculations is that if we add up all the SS terms associated with the effects in the model, and add that to the residual SS, they’re supposed to add up to the total sum of squares. And, on top of that, the whole idea behind <span class="math inline">\(\eta^2\)</span> is that – because you’re dividing one of the SS terms by the total SS value – is that an <span class="math inline">\(\eta^2\)</span> value can be interpreted as the proportion of variance accounted for by a particular term.</p>
<p>Now take a look at the output above. Because I’ve included the <span class="math inline">\(\eta^2\)</span> value associated with the residuals (i.e., proportion of variance in the outcome attributed to the residuals, rather than to one of the effects), you’d expect all the <span class="math inline">\(\eta^2\)</span> values to sum to 1. Because, the whole idea here was that the variance in the outcome variable can be divided up into the variability attributable to the model, and the variability in the residuals. Right? Right? And yet when we add up the <span class="math inline">\(\eta^2\)</span> values for our model…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="kw">sum</span>( es[,<span class="st">&quot;eta.sq&quot;</span>] )</code></pre></div>
<pre><code>## [1] 0.9641783</code></pre>
<p>… we discover that for Type II and Type III tests they generally don’t sum to 1. Some of the variability has gone “missing”. It’s not being attributed to the model, and it’s not being attributed to the residuals either. What’s going on here?</p>
<p>Before giving you the answer, I want to push this idea a little further. From a mathematical perspective, it’s easy enough to see that the missing variance is a consequence of the fact that in Types II and III, the individual SS values are not obliged to the total sum of squares, and will only do so if you have balanced data. I’ll explain why this happens and what it means in a second, but first let’s verify that this is the case using the ANOVA table. First, we can calculate the total sum of squares directly from the raw data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> ss.tot &lt;-<span class="st"> </span><span class="kw">sum</span>( (coffee<span class="op">$</span>babble <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(coffee<span class="op">$</span>babble))<span class="op">^</span><span class="dv">2</span> )
 ss.tot</code></pre></div>
<pre><code>## [1] 13.62</code></pre>
<p>Next, we can read off all the SS values from one of our Type I ANOVA tables, and add them up. As you can see, this gives us the same answer, just like it’s supposed to:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> type.I.sum &lt;-<span class="st"> </span><span class="fl">3.5575</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.9561</span> <span class="op">+</span><span class="st"> </span><span class="fl">5.9439</span> <span class="op">+</span><span class="st"> </span><span class="fl">3.1625</span>
 type.I.sum</code></pre></div>
<pre><code>## [1] 13.62</code></pre>
<p>However, when we do the same thing for the Type II ANOVA table, it turns out that the SS values in the table add up to slightly less than the total SS value:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> type.II.sum &lt;-<span class="st"> </span><span class="fl">0.9561</span> <span class="op">+</span><span class="st"> </span><span class="fl">3.0696</span> <span class="op">+</span><span class="st"> </span><span class="fl">5.9439</span> <span class="op">+</span><span class="st"> </span><span class="fl">3.1625</span>
 type.II.sum</code></pre></div>
<pre><code>## [1] 13.1321</code></pre>
<p>So, once again, we can see that there’s a little bit of variance that has “disappeared” somewhere.</p>
<p>Okay, time to explain what’s happened. The reason why this happens is that, when you have unbalanced designs, your factors become correlated with one another, and it becomes difficult to tell the difference between the effect of Factor A and the effect of Factor B. In the extreme case, suppose that we’d run a <span class="math inline">\(2 \times 2\)</span> design in which the number of participants in each group had been as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
        <span class="op">~</span>V1,     <span class="op">~</span>V2,        <span class="op">~</span>V3,
     <span class="st">&quot;milk&quot;</span>,   <span class="st">&quot;100&quot;</span>,        <span class="st">&quot;0&quot;</span>,
  <span class="st">&quot;no milk&quot;</span>,     <span class="st">&quot;0&quot;</span>,      <span class="st">&quot;100&quot;</span>
  ), <span class="dt">col.names =</span> <span class="kw">c</span>(         <span class="st">&quot;&quot;</span>, <span class="st">&quot;sugar&quot;</span>, <span class="st">&quot;no sugar&quot;</span>))</code></pre></div>
<table>
<thead>
<tr class="header">
<th></th>
<th align="left">sugar</th>
<th align="left">no sugar</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>milk</td>
<td align="left">100</td>
<td align="left">0</td>
</tr>
<tr class="even">
<td>no milk</td>
<td align="left">0</td>
<td align="left">100</td>
</tr>
</tbody>
</table>
<p>Here we have a spectacularly unbalanced design: 100 people have milk and sugar, 100 people have no milk and no sugar, and that’s all. There are 0 people with milk and no sugar, and 0 people with sugar but no milk. Now suppose that, when we collected the data, it turned out there is a large (and statistically significant) difference between the “milk and sugar” group and the “no-milk and no-sugar” group. Is this a main effect of sugar? A main effect of milk? Or an interaction? It’s impossible to tell, because the presence of sugar has a perfect association with the presence of milk. Now suppose the design had been a little more balanced:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(tibble<span class="op">::</span><span class="kw">tribble</span>(
        <span class="op">~</span>V1,     <span class="op">~</span>V2,        <span class="op">~</span>V3,
     <span class="st">&quot;milk&quot;</span>,   <span class="st">&quot;100&quot;</span>,        <span class="st">&quot;5&quot;</span>,
  <span class="st">&quot;no milk&quot;</span>,     <span class="st">&quot;5&quot;</span>,      <span class="st">&quot;100&quot;</span>
  ), <span class="dt">col.names =</span> <span class="kw">c</span>(         <span class="st">&quot;&quot;</span>, <span class="st">&quot;sugar&quot;</span>, <span class="st">&quot;no sugar&quot;</span>))</code></pre></div>
<table>
<thead>
<tr class="header">
<th></th>
<th align="left">sugar</th>
<th align="left">no sugar</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>milk</td>
<td align="left">100</td>
<td align="left">5</td>
</tr>
<tr class="even">
<td>no milk</td>
<td align="left">5</td>
<td align="left">100</td>
</tr>
</tbody>
</table>
<p>This time around, it’s technically possible to distinguish between the effect of milk and the effect of sugar, because we have a few people that have one but not the other. However, it will still be pretty difficult to do so, because the association between sugar and milk is still extremely strong, and there are so few observations in two of the groups. Again, we’re very likely to be in the situation where we <em>know</em> that the predictor variables (milk and sugar) are related to the outcome (babbling), but we don’t know if the <em>nature</em> of that relationship is a main effect of one predictor, or the other predictor or the interaction.</p>
<p>This uncertainty is the reason for the missing variance. The “missing” variance corresponds to variation in the outcome variable that is clearly attributable to the predictors, but we don’t know which of the effects in the model is responsible. When you calculate Type I sum of squares, no variance ever goes missing: the sequentiual nature of Type I sum of squares means that the ANOVA automatically attributes this variance to whichever effects are entered first. However, the Type II and Type III tests are more conservative. Variance that cannot be clearly attributed to a specific effect doesn’t get attributed to any of them, and it goes missing.</p>
</div>
</div>
<div id="summary-14" class="section level2">
<h2><span class="header-section-number">16.11</span> Summary</h2>
<ul>
<li>Factorial ANOVA with balanced designs, without interactions (Section <a href="anova2.html#factorialanovasimple">16.1</a>) and with interactions included (Section <a href="anova2.html#interactions">16.2</a>)</li>
<li>Effect size, estimated means, and confidence intervals in a factorial ANOVA (Section <a href="anova2.html#effectsizefactorialanova">16.3</a>)</li>
<li>Understanding the linear model underling ANOVA (Sections <a href="anova2.html#omnibusF">16.5</a>, <a href="anova2.html#anovalm">16.6</a> and <a href="anova2.html#contrasts">16.7</a>)</li>
<li>Post hoc testing using Tukey’s HSD (Section <a href="anova2.html#posthoc2">16.8</a>), and a brief commentary on planned comparisons (Section <a href="anova2.html#plannedcomparisons">16.9</a>)</li>
<li>Factorial ANOVA with unbalanced designs (Section <a href="anova2.html#unbalancedanova">16.10</a>)</li>
</ul>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Hsu1996">
<p>Hsu, J. C. 1996. <em>Multiple Comparisons: Theory and Methods</em>. London, UK: Chapman; Hall.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="231">
<li id="fn231"><p>The R command we need is <code>xtabs(~ drug+gender, clin.trial)</code>.<a href="anova2.html#fnref231">↩</a></p></li>
<li id="fn232"><p>The nice thing about the subscript notation is that generalises nicely: if our experiment had involved a third factor, then we could just add a third subscript. In principle, the notation extends to as many factors as you might care to include, but in this book we’ll rarely consider analyses involving more than two factors, and never more than three.<a href="anova2.html#fnref232">↩</a></p></li>
<li id="fn233"><p>Technically, marginalising isn’t quite identical to a regular mean: it’s a weighted average, where you take into account the frequency of the different events that you’re averaging over. However, in a balanced design, all of our cell frequencies are equal by definition, so the two are equivalent. We’ll discuss unbalanced designs later, and when we do so you’ll see that all of our calculations become a real headache. But let’s ignore this for now.<a href="anova2.html#fnref233">↩</a></p></li>
<li id="fn234"><p>English translation: “least tedious”.<a href="anova2.html#fnref234">↩</a></p></li>
<li id="fn235"><p>This chapter seems to be setting a new record for the number of different things that the letter R can stand for: so far we have R referring to the software package, the number of rows in our table of means, the residuals in the model, and now the correlation coefficient in a regression. Sorry: we clearly don’t have enough letters in the alphabet. However, I’ve tried pretty hard to be clear on which thing R is referring to in each case.<a href="anova2.html#fnref235">↩</a></p></li>
<li id="fn236"><p>Implausibly large, I would think: the artificiality of this data set is really starting to show!<a href="anova2.html#fnref236">↩</a></p></li>
<li id="fn237"><p>In fact, there’s a function <code>Effect()</code> within the <code>effects</code> package that has slightly different arguments, but computes the same things, and won’t give you this warning message.<a href="anova2.html#fnref237">↩</a></p></li>
<li id="fn238"><p>Due to the way that the <code>leveneTest()</code> function is implemented, however, if you use a formula like <code>mood.gain \~\ drug + therapy + drug:therapy</code>, or input an ANOVA object based on a formula like this, you actually get the error message. That shouldn’t happen, because this actually is a fully crossed model. However, there’s a quirky shortcut in the way that the <code>leveneTest()</code> function checks whether your model is fully crossed that means that it doesn’t recognise this as a fully crossed model. Essentially what the function is doing is checking that you used <code>*</code> (which ensures that the model is fully crossed), and not <code>+</code> or <code>:</code> in your model formula. So if you’ve manually typed out all of the relevant terms for a fully crossed model, the <code>leveneTest()</code> function doesn’t detect it. I think this is a bug.<a href="anova2.html#fnref238">↩</a></p></li>
<li id="fn239"><p>There could be all sorts of reasons for doing this, I would imagine.<a href="anova2.html#fnref239">↩</a></p></li>
<li id="fn240"><p>This is cheating in some respects: because ANOVA and regression are provably the same thing, R is lazy: if you read the help documentation closely, you’ll notice that the <code>aov()</code> function is actually just the <code>lm()</code> function in disguise! But we shan’t let such things get in the way of our story, shall we?<a href="anova2.html#fnref240">↩</a></p></li>
<li id="fn241"><p>In the example given above, I’ve typed <code>summary( regression.model )</code> to get the hypothesis tests. However, the <code>summary()</code> function does produce a lot of output, which is why I’ve used the <code>BLAH BLAH BLAH</code> text to hide the unnecessary parts of the output. But in fact, you can use the <code>coef()</code> function to do the same job. If you the command <code>coef( summary( regression.model ))</code> you’ll get exactly the same output that I’ve shown above (minus the <code>BLAH BLAH BLAH</code>). Compare and contrast this to the output of <code>coef( regression.model )</code>.<a href="anova2.html#fnref241">↩</a></p></li>
<li id="fn242"><p>Advanced users may want to look into the <code>model.matrix()</code> function, which produces similar output. Alternatively, you can use a command like <code>contr.treatment(3)[clin.trial\$drug,]</code>. I’ll talk about the <code>contr.treatment()</code> function later.<a href="anova2.html#fnref242">↩</a></p></li>
<li id="fn243"><p>Future versions of this book will try to be a bit more consistent with the naming scheme for variables. One of the many problems with having to write a lengthy text very quickly to meet a teaching deadline is that you lose some internal consistency.<a href="anova2.html#fnref243">↩</a></p></li>
<li id="fn244"><p>The <code>lsr</code> package contains a more general function called <code>permuteLevels()</code> that can shuffle them in any way you like.<a href="anova2.html#fnref244">↩</a></p></li>
<li id="fn245"><p>Technically, this list actually stores the functions themselves. R allows lists to contain functions, which is really neat for advanced purposes, but not something that matters for this book.<a href="anova2.html#fnref245">↩</a></p></li>
<li id="fn246"><p>If, for instance, you actually would find yourself interested to know if Group A is significantly different from the mean of Group B and Group C, then you need to use a different tool (e.g., Scheffe’s method, which is more conservative, and beyond the scope this book). However, in most cases you probably are interested in pairwise group differences, so Tukey’s HSD is a pretty useful thing to know about.<a href="anova2.html#fnref246">↩</a></p></li>
<li id="fn247"><p>This discrepancy in standard deviations might (and should) make you wonder if we have a violation of the homogeneity of variance assumption. I’ll leave it as an exercise for the reader to check this using the <code>leveneTest()</code> function.<a href="anova2.html#fnref247">↩</a></p></li>
<li id="fn248"><p>Actually, this is a bit of a lie. ANOVAs can vary in other ways besides the ones I’ve discussed in this book. For instance, I’ve completely ignored the difference between fixed-effect models, in which the levels of a factor are “fixed” by the experimenter or the world, and random-effect models, in which the levels are random samples from a larger population of possible levels (this book only covers fixed-effect models). Don’t make the mistake of thinking that this book – or any other one – will tell you “everything you need to know” about statistics, any more than a single book could possibly tell you everything you need to know about psychology, physics or philosophy. Life is too complicated for that to <em>ever</em> be true. This isn’t a cause for despair, though. Most researchers get by with a basic working knowledge of ANOVA that doesn’t go any further than this book does. I just want you to keep in mind that this book is only the beginning of a very long story, not the whole story.<a href="anova2.html#fnref248">↩</a></p></li>
<li id="fn249"><p>The one thing that might seem a little opaque to some people is why the residual degrees of freedom in this output look different from one another (i.e., ranging from 12 to 17) whereas in the original one the residual degrees of freedom is fixed at 12. It’s actually the case that R uses a residual df of 12 in all cases (that’s why the <span class="math inline">\(p\)</span> values are the same in the two outputs, and it’s enough to verify that <code>pf(6.7495, 2,12, lower.tail=FALSE))</code> gives the correct answer of <span class="math inline">\(p=.010863\)</span>, for instance, whereas <code>pf(6.7495, 2,15, lower.tail=FALSE))</code> would have given a <span class="math inline">\(p\)</span>-value of about <span class="math inline">\(.00812\)</span>. It’s the residual degrees of freedom in the full model (i.e., the last one) that matters here.<a href="anova2.html#fnref249">↩</a></p></li>
<li id="fn250"><p>Or, at the very least, rarely of interest.<a href="anova2.html#fnref250">↩</a></p></li>
<li id="fn251"><p>Yes, I’m actually a big enough nerd that I’ve written my own functions implementing Type II tests and Type III tests. I only did it to convince myself that I knew how the different Types of test worked, but it did turn out to be a handy exercise: the <code>etaSquared()</code> function in the <code>lsr</code> package relies on it. There’s actually even an argument in the <code>etaSquared()</code> function called <code>anova</code>. By default, <code>anova=FALSE</code> and the function just prints out the effect sizes. However, if you set <code>anova=TRUE</code> it will spit out the full ANOVA table as well. This works for Types I, II and III. Just set the <code>types</code> argument to select which type of test you want.<a href="anova2.html#fnref251">↩</a></p></li>
<li id="fn252"><p>Note, of course, that this does depend on the model that the user specified. If original ANOVA model doesn’t contain an interaction term for <code>B:C</code>, then obviously it won’t appear in either the null or the alternative. But that’s true for Types I, II and III. They never include any terms that you <em>didn’t</em> include, but they make different choices about how to construct tests for the ones that you did include.<a href="anova2.html#fnref252">↩</a></p></li>
<li id="fn253"><p>I find it amusing to note that the default in R is Type I and the default in SPSS is Type III (with Helmert contrasts). Neither of these appeals to me all that much. Relatedly, I find it depressing that almost nobody in the psychological literature ever bothers to report which Type of tests they ran, much less the order of variables (for Type I) or the contrasts used (for Type III). Often they don’t report what software they used either. The only way I can ever make any sense of what people typically report is to try to guess from auxiliary cues which software they were using, and to assume that they never changed the default settings. Please don’t do this… now that you know about these issues, make sure you indicate what software you used, and if you’re reporting ANOVA results for unbalanced data, then specify what Type of tests you ran, specify order information if you’ve done Type I tests and specify contrasts if you’ve done Type III tests. Or, even better, do hypotheses tests that correspond to things you really care about, and then report those!<a href="anova2.html#fnref253">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="part-vi-endings-alternatives-and-prospects.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
